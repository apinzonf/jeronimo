<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<b:Sources xmlns:b="http://schemas.openxmlformats.org/officeDocument/2006/bibliography" xmlns="http://schemas.openxmlformats.org/officeDocument/2006/bibliography" SelectedStyle="">
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Huang2008</b:Tag>
<b:Title>Automatic 3D Video Summarization: Key Frame Extraction from Self-Similarity</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Huang</b:Last>
<b:First>Peng</b:First>
</b:Person>
<b:Person>
<b:Last>Hilton</b:Last>
<b:First>Adrian</b:First>
</b:Person>
<b:Person>
<b:Last>Starck</b:Last>
<b:First>Jonathan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>3DPVT '08: Proceedings of the Fourth International Symposium on 3D Data Processing, Visualization and Transmission</b:BookTitle>
<b:ConferenceName>3DPVT '08: Proceedings of the Fourth International Symposium on 3D Data Processing, Visualization and Transmission</b:ConferenceName>
<b:URL>http://info.ee.surrey.ac.uk/Personal/P.Huang/Peng-web/Publications_files/huang_3dpvt08.pdf</b:URL>
<b:BIBTEX_Abstract>In this paper we present an automatic key frame selection method to summarise 3D video sequences. Key-frame selection is based on optimisation for the set of frames which give the best representation of the sequence according to
a rate-distortion trade-off. Distortion of the summarization from the original sequence is based on measurement of self-similarity using volume histograms. The method evaluates the globally optimal set of key-frames to represent the entire sequence without requiring pre-segmentation of the sequence into shots or temporal correspondence. Results demonstrate that for 3D video sequences of people wearing a variety of clothing the summarization automatically selects a set of key-frames which represent the dynamics. Comparative evaluation of rate-distortion characteristics with previous 3D video summarization demonstrates improved performance.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>3d-shape-similarity, 3d-video, 3d-video-summarization</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Dey2006</b:Tag>
<b:Title>Defining and computing curve-skeletons with medial geodesic function</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Dey</b:Last>
<b:Middle>K.</b:Middle>
<b:First>Tamal</b:First>
</b:Person>
<b:Person>
<b:Last>Sun</b:Last>
<b:First>Jian</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>143-152</b:Pages>
<b:StandardNumber> ISBN: 30905673-36-3</b:StandardNumber>
<b:Publisher>Eurographics Association</b:Publisher>
<b:City>Aire-la-Ville, Switzerland, Switzerland</b:City>
<b:BookTitle>SGP '06: Proceedings of the fourth Eurographics symposium on Geometry processing</b:BookTitle>
<b:ConferenceName>SGP '06: Proceedings of the fourth Eurographics symposium on Geometry processing</b:ConferenceName>
<b:BIBTEX_Abstract>Many applications in geometric modeling, computer graphics, visualization and computer vision benet from a reduced representation called curve-skeletons of a shape. These are curves possibly with branches which compactly represent the shape geometry and topology. The lack of a proper mathematical denition has been a bottleneck in developing and applying the the curve-skeletons. A set of desirable properties of these skeletons has been identied and the existing algorithms try to satisfy these properties mainly through a procedural denition. We dene a function called medial geodesic on the medial axis which leads to a methematical denition and an approximation algorithm for curve-skeletons. Empirical study shows that the algorithm is robust against noise, operates well with a single user parameter , and produces curve-skeletons with the desirable properties. Moreover , the curve-skeletons can be associated with additional attributes that follow naturally from the denition. These attributes capture shape eccentricity, a local measure of how far a shape is away from a tubular one</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Qin2010</b:Tag>
<b:Title>Line-Skeleton Extraction of 3D Meshes Based on Geometry Segmentation</b:Title>
<b:Year>2010</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Qin</b:Last>
<b:First>Xujia</b:First>
</b:Person>
<b:Person>
<b:Last>Sang</b:Last>
<b:First>Xiansheng</b:First>
</b:Person>
<b:Person>
<b:Last>Zhu</b:Last>
<b:First>Sida</b:First>
</b:Person>
<b:Person>
<b:Last>Cheng</b:Last>
<b:First>Shiwei</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>354-357</b:Pages>
<b:StandardNumber> DOI: 10.1109/CDEE.2010.73</b:StandardNumber>
<b:BookTitle>Cryptography and Network Security, Data Mining and Knowledge Discovery, E-Commerce Its Applications and Embedded Systems (CDEE), 2010 First ACIS International Symposium on</b:BookTitle>
<b:ConferenceName>Cryptography and Network Security, Data Mining and Knowledge Discovery, E-Commerce Its Applications and Embedded Systems (CDEE), 2010 First ACIS International Symposium on</b:ConferenceName>
<b:Month>oct.</b:Month>
<b:BIBTEX_Abstract>Skeleton is a fundamental shape feature of 3D mesh, and it can be used in many areas, such as model search, shape analysis, and mesh deformation. This paper presents a novel skeleton extraction method based on mesh segmentation. Firstly, the mesh is cut off by Dijkstras Algorithm and the number of segments N, then the relevant sub-meshes centers are connected to constitute the skeleton. At last, the noise of the skeleton is removed to get the final result. The algorithm is proved robust and fast through the many model demonstrations.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>3D meshes;Dijkstra's algorithm;geometry segmentation;line-skeleton extraction;mesh segmentation;sub-meshes centers;bone;computational geometry;solid modelling;</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Chen2008a</b:Tag>
<b:Title>Shape Manipulation on GPU</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>Hongqian</b:First>
</b:Person>
<b:Person>
<b:Last>Huang</b:Last>
<b:First>Tianyu</b:First>
</b:Person>
<b:Person>
<b:Last>Li</b:Last>
<b:First>Fengxia</b:First>
</b:Person>
<b:Person>
<b:Last>Zhan</b:Last>
<b:First>Shouyi</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>518-522</b:Pages>
<b:Volume>3</b:Volume>
<b:StandardNumber> DOI: 10.1109/CISP.2008.443</b:StandardNumber>
<b:BookTitle>Image and Signal Processing, 2008. CISP '08. Congress on</b:BookTitle>
<b:ConferenceName>Image and Signal Processing, 2008. CISP '08. Congress on</b:ConferenceName>
<b:Month>May</b:Month>
<b:BIBTEX_Abstract>This paper proposes a novel hardware-accelerating deformation algorithm based on curve-skeleton model for 2D shape manipulation. The deformation algorithm can achieve real-time interactive shape manipulation without any pre-computing step. The deforming regions of shapes are demarcated with a simple skeleton frame and are simulated by a curve-skeleton model consisting of triangle-strips. The algorithm obtains two properties that smooth flexion and preservation of area. Smooth flexion is guaranteed due to the continuous derivative of the curve function, and preservation of area is achieved via adjusting the parameters of the control curves. GPGPU technique is adopted to reduce the workload on CPU and to accelerate the rendering. Our algorithm can be used to 2D shape manipulation, character animation and cartoon-like objects deformation. It has been proved feasible and valid by our experiments.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Fujiwara1995</b:Tag>
<b:Title>Eigenvalues of Laplacians on a closed riemannian manifold and its nets</b:Title>
<b:Year>1995</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Fujiwara</b:Last>
<b:First>Koji</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>2585-2594</b:Pages>
<b:Volume>123</b:Volume>
<b:BookTitle>AMS</b:BookTitle>
<b:Issue>8</b:Issue>
<b:ConferenceName>AMS</b:ConferenceName>
<b:BIBTEX_Abstract>We study the relation betwen the eigenvalues of the Laplacian of a Riemannian manifold and the combinatorial Laplacians of an approximating sequence of nets in the manifold.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Bajramovic2009</b:Tag>
<b:Title>Experimental Comparison of Wide Baseline Correspondence Algorithms for Multi Camera Calibration</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Bajramovic</b:Last>
<b:First>Ferid</b:First>
</b:Person>
<b:Person>
<b:Last>Koch</b:Last>
<b:First>Michael</b:First>
</b:Person>
<b:Person>
<b:Last>Denzler</b:Last>
<b:First>Joachim</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>458-463</b:Pages>
<b:BookTitle>VISAPP (2)</b:BookTitle>
<b:ConferenceName>VISAPP (2)</b:ConferenceName>
<b:BIBTEX_Abstract>The quality of point correspondences is crucial for the successful application of multi camera self-calibration
procedures. There are several interest point detectors, local descriptors and matching algorithms, which can
be combined almost arbitrarily. In this paper, we compare the point correspondences produced by several such
combinations. In contrast to previous comparisons, we evaluate the correspondences based on the accuracy of
relative pose estimation and multi camera calibration</b:BIBTEX_Abstract>
<b:BIBTEX_CrossRef>DBLP:conf/visapp/2009-2</b:BIBTEX_CrossRef>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Laszlo2005</b:Tag>
<b:Title>Predictive feedback for interactive control of physics-based characters</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Laszlo</b:Last>
<b:First>Joe</b:First>
</b:Person>
<b:Person>
<b:Last>Neff</b:Last>
<b:First>Michael</b:First>
</b:Person>
<b:Person>
<b:Last>Singh</b:Last>
<b:First>Karan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>In Eurographics</b:BookTitle>
<b:ConferenceName>In Eurographics</b:ConferenceName>
<b:BIBTEX_Abstract>Interactive control of a physically simulated character is a challenging problem, due both to the complexity of controlling multiple degrees of freedom with lower dimensional input and because many interesting motions lie on the fringes of character stability. This paper addresses these problems using a novel technique called predictive feedback, where a glimpse into the near future for a few sample inputs is continuously presented to the animator. We discuss issues related to the spatio-temporal distribution of predictions so that they provide meaningful and timely feedback to an animator interactively controlling a physics-based character with simple input devices, like a mouse or keyboard. We propose a visual presentation of this predictive feedback in which control input samples are chosen in the proximity of the user’s current input and the predicted results are co-located with the position of the input necessary to achieve them. We further show how the predictive samples may be automatically interpolated to control aspects of the character’s motion, such as balance, thereby freeing the animator to focus on other details. The paper thus contributes a technique for physically simulated characters that simplifies interactive character control and increases the range of motion that can be performed by both novices and experts. Many of the presented concepts extend beyond our specific input device and dynamic character control setting to more general input tasks. Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Interaction, Physical simulation, Character animation</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Park2006</b:Tag>
<b:Title>Capturing and animating skin deformation in human motion</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Park</b:Last>
<b:Middle>Il</b:Middle>
<b:First>Sang</b:First>
</b:Person>
<b:Person>
<b:Last>Hodgins</b:Last>
<b:Middle>K.</b:Middle>
<b:First>Jessica</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>881-889</b:Pages>
<b:Volume>25</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/1141911.1141970</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>During dynamic activities, the surface of the human body moves in many subtle but visually significant ways: bending, bulging, jiggling, and stretching. We present a technique for capturing and animating those motions using a commercial motion capture system and approximately 350 markers. Although the number of markers is significantly larger than that used in conventional motion capture, it is only a sparse representation of the true shape of the body. We supplement this sparse sample with a detailed, actor-specific surface model. The motion of the skin can then be computed by segmenting the markers into the motion of a set of rigid parts and a residual deformation (approximated first as a quadratic transformation and then with radial basis functions). We demonstrate the power of this approach by capturing flexing muscles, high frequency motions, and abrupt decelerations on several actors. We compare these results both to conventional motion capture and skinning and to synchronized video of the actors.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Hassouna2007</b:Tag>
<b:Title>On the Extraction of Curve Skeletons using Gradient Vector Flow</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hassouna</b:Last>
<b:First>M.S.</b:First>
</b:Person>
<b:Person>
<b:Last>Farag</b:Last>
<b:First>A.A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:StandardNumber> ISSN: 1550-5499 DOI: 10.1109/ICCV.2007.4409112</b:StandardNumber>
<b:BookTitle>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:BookTitle>
<b:ConferenceName>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:ConferenceName>
<b:Month>Oct.</b:Month>
<b:BIBTEX_Abstract>In this paper, we propose a new variational framework for computing continuous curve skeletons from discrete objects that are suitable for structural shape representation. We have derived a new energy function, which is proportional to some medialness function, such that the minimum cost path between any two medial voxels in the shape is a curve skeleton. We have employed two different medialness functions; the Euclidean distance field and a variant of the magnitude of the gradient vector flow (GVF), resulting in two different energy functions. The first energy controls the identification of the shape topological nodes from which curve skeletons start, while the second one controls the extraction of curve skeletons. The accuracy and robustness of the proposed framework are validated both quantitatively and qualitatively against competing techniques as well as several 3D shapes of different complexity.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational complexity, feature extraction, image processingEuclidean distance field, curve skeletons extraction, discrete objects, energy function, energy functions, gradient vector flow, medialness function, shape topological nodes</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Sumner2007</b:Tag>
<b:Title>Embedded deformation for shape manipulation</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Sumner</b:Last>
<b:Middle>W.</b:Middle>
<b:First>Robert</b:First>
</b:Person>
<b:Person>
<b:Last>Schmid</b:Last>
<b:First>Johannes</b:First>
</b:Person>
<b:Person>
<b:Last>Pauly</b:Last>
<b:First>Mark</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://dx.doi.org/10.1145/1275808.1276478</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '07: ACM SIGGRAPH 2007 papers</b:BookTitle>
<b:ConferenceName>SIGGRAPH '07: ACM SIGGRAPH 2007 papers</b:ConferenceName>
<b:URL>http://dx.doi.org/10.1145/1275808.1276478</b:URL>
<b:BIBTEX_Abstract>We present an algorithm that generates natural and intuitive deformations via direct manipulation for a wide range of shape representations and editing scenarios. Our method builds a space deformation represented by a collection of affine transformations organized in a graph structure. One transformation is associated with each graph node and applies a deformation to the nearby space. Positional constraints are specified on the points of an embedded object. As the user manipulates the constraints, a nonlinear minimization problem is solved to find optimal values for the affine transformations. Feature preservation is encoded directly in the objective function by measuring the deviation of each transformation from a true rotation. This algorithm addresses the problem of "embedded deformation" since it deforms space through direct manipulation of objects embedded within it, while preserving the embedded objects' features. We demonstrate our method by editing meshes, polygon soups, mesh animations, and animated particle systems.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>registration</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Mikhail2006</b:Tag>
<b:Title>An Online System for Synchronized Processing of Video and Audio Signals</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Mikhail</b:Last>
<b:First>Mary</b:First>
</b:Person>
<b:Person>
<b:Last>Palumbo</b:Last>
<b:First>Giovanni</b:First>
</b:Person>
<b:Person>
<b:Last>Mohammad</b:Last>
<b:First>Jinane</b:First>
</b:Person>
<b:Person>
<b:Last>El-Helaly</b:Last>
<b:First>Mohamed</b:First>
</b:Person>
<b:Person>
<b:Last>Amer</b:Last>
<b:First>Aishy</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>2065-2068</b:Pages>
<b:StandardNumber> DOI: 10.1109/CCECE.2006.277564</b:StandardNumber>
<b:BookTitle>Electrical and Computer Engineering, 2006. CCECE '06. Canadian Conference on</b:BookTitle>
<b:ConferenceName>Electrical and Computer Engineering, 2006. CCECE '06. Canadian Conference on</b:ConferenceName>
<b:Month>May </b:Month>
<b:BIBTEX_Abstract>For many audio-visual applications, the integration and synchronization of audio and video signals is essential. The objective of this paper is to develop a system that displays the active objects in the captured video signal, integrated with their respective audio signals in the form of text. The video and audio signals are captured and processed separately. The signals are buffered and integrated and synchronized using a time-stamping technique. Time-stamps provide the timing information for each of the audio and video processes, the speech recognition and the object detection, respectively. This information is necessary to correlate the audio packets to the video frames. Hence, integration is achieved without the use of video information, such as lip movements. The results obtained are based on a specific implementation of the speech recognition module, which is determined to be the bottleneck process in the proposed system</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>audio signal processing, synchronisation, video signal processingaudio signal processing, audio-visual applications, online system, speech recognition, synchronized video signal processing, time-stamping technique, video frames, video information</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Miller2007</b:Tag>
<b:Title>Safe hulls</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Miller</b:Last>
<b:First>G.</b:First>
</b:Person>
<b:Person>
<b:Last>Hilton</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:BookTitle>Visual Media Production</b:BookTitle>
<b:JournalName>Visual Media Production, 2007. IETCVMP. 4th European Conference on</b:JournalName>
<b:ConferenceName>Visual Media Production</b:ConferenceName>
<b:Month>Nov.</b:Month>
<b:BIBTEX_Abstract>The visual hull is widely used as a proxy for novel view synthesis in computer vision. This paper introduces the safe hull, the first visual hull reconstruction technique to produce a surface containing only foreground parts. A theoretical basis underlies this novel approach which, unlike any previous work, can also identify phantom volumes attached to real objects. Using an image-based method, the visual hull is constructed with respect to each real view and used to identify safe zones in the original silhouettes. The safe zones define volumes known to only contain surface corresponding to a real object. The zones are used in a second reconstruction step to produce a surface without phantom volumes. Results demonstrate the effectiveness of this method for improving surface shape and scene realism, and its advantages over heuristic techniques.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computer vision, image reconstructioncomputer vision, image-based method, phantom volumes identification, safe hull, view synthesis, visual hull reconstruction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Menier2006</b:Tag>
<b:Title>3D Skeleton-Based Body Pose Recovery</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Menier</b:Last>
<b:First>C.</b:First>
</b:Person>
<b:Person>
<b:Last>Boyer</b:Last>
<b:First>E.</b:First>
</b:Person>
<b:Person>
<b:Last>Raffin</b:Last>
<b:First>B.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>389-396</b:Pages>
<b:StandardNumber> DOI: 10.1109/3DPVT.2006.7</b:StandardNumber>
<b:BookTitle>3D Data Processing, Visualization, and Transmission, Third International Symposium on</b:BookTitle>
<b:ConferenceName>3D Data Processing, Visualization, and Transmission, Third International Symposium on</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>This paper presents an approach to recover body motions from multiple views using a 3D skeletal model. It takes, as input, foreground silhouette sequences from multiple viewpoints, and computes, for each frame, the skeleton pose which best fit the body pose. Skeletal models encode mostly motion information and allows therefore to separate motion estimation from shape estimation for which solutions exist; And focusing on motion parameters significantly reduces the dependancy on specific body shapes, yielding thus more flexible solutions for body motion capture. However, a problem generally faced with skeletal models is to find adequate measurements with which to fit the model. In this paper, we propose to use the medial axis of the body shape to this purpose. Such medial axis can be estimated from the visual hull, a shape approximation which is easily obtained from the silhouette information. Experiments show that this approach is robust to several perturbations in the model or in the input data, and also allows fast body motions or, equivalently, important motions between consecutive frames.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image motion analysis, image sequences3D skeleton-based body pose recovery, body motions, foreground silhouette sequences, shape estimation</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Yue2008</b:Tag>
<b:Title>Synthesis of Silhouettes and Visual Hull Reconstruction for Articulated Humans</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Yue</b:Last>
<b:First>Zhanfeng</b:First>
</b:Person>
<b:Person>
<b:Last>Chellappa</b:Last>
<b:First>R.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1565-1577</b:Pages>
<b:Volume>10</b:Volume>
<b:StandardNumber> ISSN: 1520-9210 DOI: 10.1109/TMM.2008.2007321</b:StandardNumber>
<b:JournalName>Multimedia, IEEE Transactions on</b:JournalName>
<b:Issue>8</b:Issue>
<b:Month>Dec. </b:Month>
<b:BIBTEX_Abstract>In this paper, we propose a complete framework for improved synthesis and understanding of the human pose from a limited number of silhouette images. It combines the active image-based visual hull (IBVH) algorithm and a contour-based body part segmentation technique. We derive a simple, approximate algorithm to decide the extrinsic parameters of a virtual camera, and synthesize the turntable image collection of the person using the IBVH algorithm by actively moving the virtual camera on a properly computed circular trajectory around the person. Using the turning function distance as the silhouette similarity measurement, this approach can be used to generate the desired pose-normalized images for recognition applications. In order to overcome the inability of the visual hull (VH) method to reconstruct concave regions, we propose a contour-based human body part localization algorithm to segment the silhouette images into convex body parts. The body parts observed from the virtual view are generated separately from the corresponding body parts observed from the input views and then assembled together for a more accurate VH reconstruction. Furthermore, the obtained turntable image collection helps to improve the body part segmentation and identification process. By using the inner distance shape context (IDSC) measurement, we are able to estimate the body part locations more accurately from a synthesized view where we can localize the body part more precisely. Experiments show that the proposed algorithm can greatly improve body part segmentation and hence shape reconstruction results.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>approximation theory, cameras, edge detection, image reconstruction, image segmentation, pose estimation, shape recognition, virtual realityactive image, approximate algorithm, articulated human pose, circular trajectory computation, contour-based body part segmentation technique, human body part localization algorithm, inner distance shape context measurement, silhouette image synthesis, silhouette similarity measurement, turning function distance, turntable image collection, virtual camera, visual hull reconstruction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Campos2006a</b:Tag>
<b:Title>Regression-based Hand Pose Estimation from Multiple Cameras</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>de Campos</b:Last>
<b:Middle>E.</b:Middle>
<b:First>Teofilo</b:First>
</b:Person>
<b:Person>
<b:Last>Murray</b:Last>
<b:Middle>W.</b:Middle>
<b:First>David</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>782-789</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1063-6919 DOI: http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.252</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Los Alamitos, CA, USA</b:City>
<b:JournalName>Computer Vision and Pattern Recognition, IEEE Computer Society Conference on</b:JournalName>
<b:BIBTEX_Abstract>The RVM-based learning method for whole body pose estimation proposed by Agarwal and Triggs is adapted to hand pose recovery. To help overcome the difficulties presented by the greater degree of self-occlusion and the wider range of poses exhibited in hand imagery, the adaptation proposes a method for combining multiple views. Comparisons of performance using single versus multiple views are reported for both synthesized and real imagery, and the effects of the number of image measurements and the number of training samples on performance are explored.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Daubney2008</b:Tag>
<b:Title>Real-time pose estimation of articulated objects using low-level motion</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Daubney</b:Last>
<b:First>B.</b:First>
</b:Person>
<b:Person>
<b:Last>Gibson</b:Last>
<b:First>D.</b:First>
</b:Person>
<b:Person>
<b:Last>Campbell</b:Last>
<b:First>N.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:BookTitle>#CVPR08#</b:BookTitle>
<b:ConferenceName>#CVPR08#</b:ConferenceName>
<b:BIBTEX_Abstract>We present a method that is capable of tracking and estimating pose of articulated objects in real-time. This is achieved by using a bottom-up approach to detect instances of the object in each frame, these detections are then linked together using a high-level a priori motion model. Unlike other approaches that rely on appearance, our method is entirely dependent on motion; initial low-level part detection is based on how a region moves as opposed to its appearance. This work is best described as pictorial structures using motion. A sparse cloud of points extracted using a standard feature tracker are used as observational data, this data contains noise that is not Gaussian in nature but systematic due to tracking errors. Using a probabilistic framework we are able to overcome both corrupt and missing data whilst still inferring new poses from a generative model. Our approach requires no manual initialisation and we show results for a number of complex scenes and different classes of articulated object, this demonstrates both the robustness and versatility of the presented technique.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Aouada2009</b:Tag>
<b:Title>Novel similarity invariant for space curves using turning angles and its application to object recognition</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Aouada</b:Last>
<b:First>D.</b:First>
</b:Person>
<b:Person>
<b:Last>Krim</b:Last>
<b:First>H.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1277-1280</b:Pages>
<b:StandardNumber> ISSN: 1520-6149 DOI: 10.1109/ICASSP.2009.4959824</b:StandardNumber>
<b:BookTitle>Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on</b:BookTitle>
<b:ConferenceName>Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on</b:ConferenceName>
<b:Month>April</b:Month>
<b:BIBTEX_Abstract>We present a new similarity invariant signature for space curves. This signature is based on the information contained in the turning angles of both the tangent and the binormal vectors at each point on the curve. For an accurate comparison of these signatures, we define a Riemannian metric on the space of the invariant. We show through relevant examples that, unlike classical invariants, the one we define in this paper enjoys multiple important properties at the same time, namely, a high discrimination level, independence of any reference point, uniqueness property, as well as a good preservation of the correspondence between curves. Moreover, we illustrate how to match 3D objects by extracting and comparing the invariant signatures of their curved skeletons.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>curve fitting, object recognitionbinormal vector, object recognition, similarity invariant signature, space curve, tangent vector, turning angle</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Amenta2001</b:Tag>
<b:Title>The power crust</b:Title>
<b:Year>2001</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Amenta</b:Last>
<b:First>Nina</b:First>
</b:Person>
<b:Person>
<b:Last>Choi</b:Last>
<b:First>Sunghee</b:First>
</b:Person>
<b:Person>
<b:Last>Kolluri</b:Last>
<b:Middle>Krishna</b:Middle>
<b:First>Ravi</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>249-266</b:Pages>
<b:StandardNumber> ISBN: 1-58113-366-9 DOI: http://doi.acm.org/10.1145/376957.376986</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SMA '01: Proceedings of the sixth ACM symposium on Solid modeling and applications</b:BookTitle>
<b:ConferenceName>SMA '01: Proceedings of the sixth ACM symposium on Solid modeling and applications</b:ConferenceName>
<b:BIBTEX_Abstract>The medial axis transform (or MAT) is a representation of an object as an infinite union of balls. We consider approximating the MAT of a three-dimensional object, and its complement, with a finite union of balls. Using this approximate MAT we define a new piecewise-linear approximation to the object surface, which we call the power crust. We assume that we are given as input a suficiently dense sample of points from the object surface. We select a subset of the Voronoi balls of the sample, the polar balls, as the union of balls representation. We bound the geometric error of the union, and of the corresponding power crust, and show that both representations are topologically correct as well. Thus, our results provide a new algorithm for surface reconstruction from sample points. By construction, the power crust is always the boundary of a solid, so we avoid the hole-filling or manifold extraction steps used in previous algorithms. The union of balls representation and the power crust have corresponding piecewise-linear dual representations, which in some sense approximate the medial axis. We show a geometric relationship between these duals and the medial axis by proving that, as the sampling density goes to infinity, the set of poles, the centers of the polar balls, converge to the medial axis</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Huang2008a</b:Tag>
<b:Title>Non-Rigid Registration Under Isometric Deformations.</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Huang</b:Last>
<b:First>Qi-Xing</b:First>
</b:Person>
<b:Person>
<b:Last>Adams</b:Last>
<b:First>Bart</b:First>
</b:Person>
<b:Person>
<b:Last>Wicke</b:Last>
<b:First>Martin</b:First>
</b:Person>
<b:Person>
<b:Last>Guibas</b:Last>
<b:Middle>J.</b:Middle>
<b:First>Leonidas</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1449-1457</b:Pages>
<b:Volume>27</b:Volume>
<b:JournalName>Comput. Graph. Forum</b:JournalName>
<b:Issue>5</b:Issue>
<b:URL>http://dblp.uni-trier.de/db/journals/cgf/cgf27.html#HuangAWG08</b:URL>
<b:BIBTEX_Abstract>We present a robust and ef?cient algorithm for the pairwise non-rigid registration of partially overlapped 3D sur-
faces. Our approach treats non-rigid registration as an optimization problem and solves it by alternating between
correspondence and deformation optimization. Assuming approximately isometric deformations, robust corre-
spondences are generated using a pruning mechanism based on geodesic consistency. We iteratively learn an
appropriate deformation discretization from the current set of correspondences and use it to update the corre-
spondences in the next iteration. Our algorithm is able to register partially similar point clouds that undergo large
deformations, in just a few seconds. We demonstrate the potential of our algorithm in various applications such
as example based articulated segmentation, and shape interpolation.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Tagliasacchi2012</b:Tag>
<b:Title>Mean Curvature Skeletons</b:Title>
<b:Year>2012</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tagliasacchi</b:Last>
<b:First>Andrea</b:First>
</b:Person>
<b:Person>
<b:Last>Alhashim</b:Last>
<b:First>Ibraheem</b:First>
</b:Person>
<b:Person>
<b:Last>Olson</b:Last>
<b:First>Matt</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Hao</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1735-1744</b:Pages>
<b:Volume>31</b:Volume>
<b:StandardNumber> ISSN: 0167-7055 DOI: 10.1111/j.1467-8659.2012.03178.x</b:StandardNumber>
<b:Publisher>John Wiley \&amp; Sons, Inc.</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>Comp. Graph. Forum</b:JournalName>
<b:Issue>5</b:Issue>
<b:Month>#aug#</b:Month>
<b:URL>http://dx.doi.org/10.1111/j.1467-8659.2012.03178.x</b:URL>
<b:BIBTEX_Abstract>Inspired by recent developments in contraction-based curve skeleton extraction, we formulate the skeletonization problem via mean curvature flow (MCF). While the classical application of MCF is surface fairing, we take advantage of its area-minimizing characteristic to drive the curvature flow towards the extreme so as to collapse the input mesh geometry and obtain a skeletal structure. By analyzing the differential characteristics of the flow, we reveal that MCF locally increases shape anisotropy. This justifies the use of curvature motion for skeleton computation, and leads to the generation of what we call “mean curvature skeletons”. To obtain a stable and efficient discretization, we regularize the surface mesh by performing local remeshing via edge splits and collapses. Simplifying mesh connectivity throughout the motion leads to more efficient computation and avoids numerical instability arising from degeneracies in the triangulation. In addition, the detection of collapsed geometry is facilitated by working with simplified mesh connectivity and monitoring potential non-manifold edge collapses. With topology simplified throughout the flow, minimal post-processing is required to convert the collapsed geometry to a curve. Formulating skeletonization via MCF allows us to incorporate external energy terms easily, resulting in a constrained flow. We define one such energy term using the Voronoi medial skeleton and obtain a medially centred curve skeleton. We call the intermediate results of our skeletonization motion meso-skeletons; these consist of a mixture of curves and surface sheets as appropriate to the local 3D geometry they capture.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Miller2006</b:Tag>
<b:Title>Exact View-Dependent Visual Hulls</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Miller</b:Last>
<b:First>G.</b:First>
</b:Person>
<b:Person>
<b:Last>Hilton</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>107-111</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1051-4651 DOI: 10.1109/ICPR.2006.515</b:StandardNumber>
<b:BookTitle>Pattern Recognition</b:BookTitle>
<b:JournalName>Pattern Recognition, 2006. ICPR 2006. 18th International Conference on</b:JournalName>
<b:ConferenceName>Pattern Recognition</b:ConferenceName>
<b:Month>0-0 </b:Month>
<b:BIBTEX_Abstract>The visual hull is widely used to produce three dimensional models from multiple views, due to the reliability of the resulting surface. This paper presents a novel method for efficiently evaluating the exact view-dependent visual hull without using approximations. Methods for selecting intersections and ordering them via the cross ratio are presented. Results show the high quality of the surfaces produced using this method</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image reconstruction, stereo image processing3D models, shape based reconstruction, surface reconstruction, view-dependent visual hulls</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>Misc</b:SourceType>
<b:Tag>cgal</b:Tag>
<b:Title>{Cgal}, {C}omputational {G}eometry {A}lgorithms {L}ibrary</b:Title>
<b:Comments>http://www.cgal.org</b:Comments>
<b:Author/>
<b:PublicationTitle>{Cgal}, {C}omputational {G}eometry {A}lgorithms {L}ibrary</b:PublicationTitle>
</b:Source>
<b:Source>
<b:SourceType>Book</b:SourceType>
<b:Tag>Taddei2007</b:Tag>
<b:Title>Leonardo da Vinci's robots: New mechanics and new automata found in codices</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Taddei</b:Last>
<b:First>Mario</b:First>
</b:Person>
</b:NameList>
</b:Author>
<b:Editor>
<b:NameList>
<b:Person>
<b:Last>editoriali</b:Last>
<b:First>Prodotti</b:First>
</b:Person>
</b:NameList>
</b:Editor>
</b:Author>
<b:Publisher>Leonardo3</b:Publisher>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Erol2005</b:Tag>
<b:Title>Visual Hull Construction Using Adaptive Sampling</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Erol</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Bebis</b:Last>
<b:First>G.</b:First>
</b:Person>
<b:Person>
<b:Last>Boyle</b:Last>
<b:First>R.D.</b:First>
</b:Person>
<b:Person>
<b:Last>Nicolescu</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>234-241</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> DOI: 10.1109/ACVMOT.2005.123</b:StandardNumber>
<b:BookTitle>computer vision</b:BookTitle>
<b:JournalName>Application of Computer Vision, 2005. WACV/MOTIONS '05 Volume 1. Seventh IEEE Workshops on</b:JournalName>
<b:ConferenceName>computer vision</b:ConferenceName>
<b:Month>Jan.</b:Month>
<b:BIBTEX_Abstract>Volumetric visual hulls have become very popular in many computer vision applications including human body pose estimation and virtualized reality. In these applications, the visual hull is used to approximate the 3D geometry of an object. Existing volumetric visual hull construction techniques, however, produce a 3-color volume data that merely serves as a bounding volume. In other words it lacks an accurate surface representation. Polygonization can produce satisfactory results only at high resolutions. In this study we extend the binary visual hull to an implicit surface in order to capture the geometry of the visual hull itself. In particular, we introduce an octree-based visual hull specific adaptive sampling algorithm to obtain a volumetric representation that provides accuracy proportional to the level of detail. Moreover, we propose a method to process the resulting octree to extract a crack-free polygonal visual hull surface. Experimental results illustrate the performance of the algorithm.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computer vision, image representation, image sampling, image sequences, octrees, pose estimation, virtual realityadaptive sampling, computer vision, crack-free polygonal surface, human body pose estimation, octree-based visual hull, polygonization, surface representation, virtualized reality, visual hull construction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Shen2009</b:Tag>
<b:Title>Human pose estimation from corrupted silhouettes using a sub-manifold voting strategy in latent variable space</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Shen</b:Last>
<b:First>Chunfeng</b:First>
</b:Person>
<b:Person>
<b:Last>Lin</b:Last>
<b:First>Xueyin</b:First>
</b:Person>
<b:Person>
<b:Last>Shi</b:Last>
<b:First>Yuanchun</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>421-431</b:Pages>
<b:Volume>30</b:Volume>
<b:StandardNumber> ISSN: 0167-8655 DOI: http://dx.doi.org/10.1016/j.patrec.2008.10.009</b:StandardNumber>
<b:Publisher>Elsevier Science Inc.</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>Pattern Recogn. Lett.</b:JournalName>
<b:Issue>4</b:Issue>
<b:BIBTEX_Abstract>In this paper, a learning-based framework is proposed for human pose estimation in complicated environments. Human silhouettes extracted from input images are always incomplete and corrupted due to shadows, occlusions, motion blur, or foreground/background color similarity. Given a corrupted body silhouette, our goal is to infer the corresponding pose structure robustly, and to reconstruct the input silhouette as well. The basic assumption of our method is that the body pose (and configuration) can be indicated by some parts (components) of the silhouette given a training data set. Based on this assumption, a robust statistical method is applied to gather the information from uncorrupted components, and to ignore the effects from the outliers. In this method, Gaussian Process is used to learn the low-dimensional manifold of visual input data, and to create the sub-manifold corresponding to each component of the silhouette. Different from traditional methods, the likelihood probability is computed by means of a sub-manifold voting strategy based on the learned sub-manifolds. By fusing the likelihood and the prior of human poses, the proposed learning-based framework can specify the location of the input human pose in the latent space. The intrinsic pose and configuration can then be deduced from this location, or be refined after outlier rejection. Experiments show that our approach has a great ability to estimate human poses from corrupted silhouettes with small computational burden. Therefore, it can be applied for tracking initialization, 3D pose estimation, 2D configuration reconstruction in occluded, shadowed and noisy environments.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Misc</b:SourceType>
<b:Tag>Forbes2006</b:Tag>
<b:Title>Shape-from-Silhouette with Two Mirrors and an Uncalibrated Camera</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Forbes</b:Last>
<b:First>Keith</b:First>
</b:Person>
<b:Person>
<b:Last>Nicolls</b:Last>
<b:First>Fred</b:First>
</b:Person>
<b:Person>
<b:Last>de Jager</b:Last>
<b:First>Gerhard</b:First>
</b:Person>
<b:Person>
<b:Last>Voigt</b:Last>
<b:First>Anthon</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>165-178</b:Pages>
<b:JournalName>Computer Vision â€“ ECCV 2006</b:JournalName>
<b:URL>http://dx.doi.org/10.1007/11744047_13</b:URL>
<b:PublicationTitle>Shape-from-Silhouette with Two Mirrors and an Uncalibrated Camera</b:PublicationTitle>
<b:BIBTEX_Abstract>Two planar mirrors are positioned to show five views of an object, and snapshots are captured from different viewpoints. We present closed form solutions for calculating the focal length, principal point, mirror and camera poses directly from the silhouette outlines of the object and its reflections. In the noisy case, these equations are used to form initial parameter estimates that are refined using iterative minimisation. The self-calibration allows the visual cones from each silhouette to be specified in a common reference frame so that the visual hull can be constructed. The proposed setup provides a simple method for creating 3D multimedia content that does not rely on specialised equipment. Experimental results demonstrate the reconstruction of a toy horse and a locust from real images. Synthetic images are used to quantify the sensitivity of the self-calibration to quantisation noise. In terms of the silhouette calibration ratio, degradation in silhouette quality has a greater effect on silhouette set consistency than computed calibration parameters.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Theobalt2004</b:Tag>
<b:Title>Marker-free Kinematic Skeleton Estimation from Sequences of Volume Data</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Theobalt</b:Last>
<b:First>Christian</b:First>
</b:Person>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>Edilson</b:First>
</b:Person>
<b:Person>
<b:Last>Magnor</b:Last>
<b:First>Marcus</b:First>
</b:Person>
<b:Person>
<b:Last>Theisel</b:Last>
<b:First>Holger</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>Hans-Peter</b:First>
</b:Person>
</b:NameList>
</b:Author>
<b:Editor>
<b:NameList>
<b:Person>
<b:Last>Lau</b:Last>
<b:First>Rynson</b:First>
</b:Person>
<b:Person>
<b:Last>Baciu</b:Last>
<b:First>George</b:First>
</b:Person>
</b:NameList>
</b:Editor>
</b:Author>
<b:Pages>57-64</b:Pages>
<b:StandardNumber> ISBN: 1-58113-907-1</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>Hong Kong, China</b:City>
<b:BookTitle>ACM Symposium on Virtual Reality Software and Technology (VRST 2004)</b:BookTitle>
<b:ConferenceName>ACM Symposium on Virtual Reality Software and Technology (VRST 2004)</b:ConferenceName>
<b:Month>November</b:Month>
<b:BIBTEX_Abstract>For realistic animation of an artificial character a body model that represents the character's kinematic structure is required. Hierarchical skeleton models are widely used which represent bodies as chains of bones with interconnecting joints. In video motion capture, animation parameters are derived from the performance of a subject in the real world. For this acquisition procedure too, a kinematic body model is required. Typically, the generation of such a model for tracking and animation is, at best, a semi-automatic process. We present a novel approach that estimates a hierarchical skeleton model of an arbitrary moving subject from sequences of voxel data that were reconstructed from multi-view video footage. Our method does not require a-priori information about the body structure. We demonstrate its performance using synthetic and real data.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Misc</b:SourceType>
<b:Tag>graphite</b:Tag>
<b:Title>Graphite</b:Title>
<b:Comments>Research platform for computer graphics, 3D modeling and numerical geometry. http://alice.loria.fr/WIKI/index.php/Graphite</b:Comments>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>in INRIA Nancy Grand-Est / Loria</b:Last>
<b:Middle>Team</b:Middle>
<b:First>ALICE</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:PublicationTitle>Graphite</b:PublicationTitle>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Xu2009</b:Tag>
<b:Title>Partial Intrinsic Reflectional Symmetry of 3D Shapes</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Xu</b:Last>
<b:First>Kai</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Hao</b:First>
</b:Person>
<b:Person>
<b:Last>Tagliasacchi</b:Last>
<b:First>Andrea</b:First>
</b:Person>
<b:Person>
<b:Last>Liu</b:Last>
<b:First>Ligang</b:First>
</b:Person>
<b:Person>
<b:Last>Li</b:Last>
<b:First>Guo</b:First>
</b:Person>
<b:Person>
<b:Last>Meng</b:Last>
<b:First>Min</b:First>
</b:Person>
<b:Person>
<b:Last>Xiong</b:Last>
<b:First>Yueshan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>15</b:Pages>
<b:Volume>28</b:Volume>
<b:JournalName>ACM Transactions on Graphics, (Proceedings SIGGRAPH Asia 2009)</b:JournalName>
<b:Issue>5</b:Issue>
<b:BIBTEX_Abstract>While many 3D objects exhibit various forms of global symmetries, prominent intrinsic symmetries which exist only on parts of an object are also well recognized. Such partial symmetries are often seen as more natural compared to a global one, especially on a composite shape. We introduce algorithms to extract partial intrinsic reflectional symmetries (PIRS) of a 3D shape. Given a closed 2-manifold mesh, we develop a voting scheme to obtain an intrinsic reflectional symmetry axis (IRSA) transform, which computes a scalar field over the mesh so as to accentuate prominent IRSAs of the shape. We then extract a set of explicit IRSA curves on the shape based on a refined measure of local reflectional symmetry support along a curve. The iterative refinement procedure combines IRSA-induced region growing and region-constrained symmetry support refinement to improve accuracy and address potential issues due to rotational symmetries in the shape. We show how the extracted IRSA curves can be incorporated into a conventional mesh segmentation scheme so that the implied symmetry cues can be utilized to obtain more meaningful results. We also demonstrate the use of IRSA curves for symmetry-driven part repair.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Hachet2005</b:Tag>
<b:Title>A Camera-Based Interface for Interaction with Mobile Handheld Computers</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hachet</b:Last>
<b:First>Martin</b:First>
</b:Person>
<b:Person>
<b:Last>Pouderoux</b:Last>
<b:First>Joachim</b:First>
</b:Person>
<b:Person>
<b:Last>Guitton</b:Last>
<b:First>Pascal</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>65-71</b:Pages>
<b:Publisher>ACM Press</b:Publisher>
<b:BookTitle>Proceedings of I3D'05 - ACM SIGGRAPH 2005 Symposium on Interactive 3D Graphics and Games</b:BookTitle>
<b:ConferenceName>Proceedings of I3D'05 - ACM SIGGRAPH 2005 Symposium on Interactive 3D Graphics and Games</b:ConferenceName>
<b:URL>http://iparla.labri.fr/publications/2005/HPG05</b:URL>
<b:BIBTEX_Abstract>Recent advances in mobile computing allow the users to deal with 3D interactive graphics on handheld computers. Although the computing resources and screen resolutions grow steadily, user interfaces for handheld computers do not change significantly. Consequently, we designed a new 3-DOF interface adapted to the characteristics of handheld computers. This interface tracks the movement of a target that the user holds behind the screen by analyzing the video stream of the handheld computer camera. The position of the target is directly inferred from the color-codes that are printed on it using an efficient algorithm. The users can easily interact in real-time in a mobile setting. The visualization of the data is good as the target does not occlude the screen and the interaction techniques are not dependent on the orientation of the handheld computer. We used the interface in several test applications for the visualization of large images such as maps, the manipulation of 3D models, and the navigation in 3D scenes. This new interface favors the development of 2D and 3D interactive applications on handheld computers.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>User interfaces, Interaction, PDA</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Guan2006</b:Tag>
<b:Title>Visual Hull Construction in the Presence of Partial Occlusion</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Guan</b:Last>
<b:First>Li</b:First>
</b:Person>
<b:Person>
<b:Last>Sinha</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Franco</b:Last>
<b:First>J.-S.</b:First>
</b:Person>
<b:Person>
<b:Last>Pollefeys</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>413-420</b:Pages>
<b:StandardNumber> DOI: 10.1109/3DPVT.2006.147</b:StandardNumber>
<b:BookTitle>computational complexity</b:BookTitle>
<b:JournalName>3D Data Processing, Visualization, and Transmission, Third International Symposium on</b:JournalName>
<b:ConferenceName>computational complexity</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>In this paper, we propose a visual hull algorithm, which guarantees a correct construction even in the presence of partial occlusion, while "correct" here means that the real shape is located inside the visual hull. The algorithm is based on a new idea of the "extended silhouette", which requires the silhouette from background subtraction and the "occlusion mask" of the same view. In order to prepare the occlusion mask, we also propose a novel concept of "effective boundary" of moving foreground objects in a video obtained from a static camera. The accumulation of the effective boundary through time automatically gives robust occluder boundaries. We theoretically prove that our algorithm deterministically computes the tightest, correct visual hull in the presence of occlusion. Both synthetic and real examples are given as a demonstration of the correctness of the algorithm. Finally we analyze that this new algorithm is still within the time complexity of the traditional method.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational complexity, image denoisingbackground subtraction, extended silhouette, occlusion mask, partial occlusion, time complexity, visual hull construction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Taubin1995</b:Tag>
<b:Title>A signal processing approach to fair surface design</b:Title>
<b:Year>1995</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Taubin</b:Last>
<b:First>Gabriel</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>351-358</b:Pages>
<b:StandardNumber> ISBN: 0-89791-701-4 DOI: http://doi.acm.org/10.1145/218380.218473</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>Proceedings of the 22nd annual conference on Computer graphics and interactive techniques</b:BookTitle>
<b:ConferenceName>Proceedings of the 22nd annual conference on Computer graphics and interactive techniques</b:ConferenceName>
<b:URL>http://doi.acm.org/10.1145/218380.218473</b:URL>
<b:BIBTEX_Series>SIGGRAPH '95</b:BIBTEX_Series>
<b:BIBTEX_Abstract>In this paper we describe a new tool for interactive free-form fair surface design. By generalizing classical discrete Fourier analysis to two-dimensional discrete surface signals -- functions defined on polyhedral surfaces of arbitrary topology --, we reduce the problem of surface smoothing, or fairing, to low-pass filtering. We describe a very simple surface signal low-pass filter algorithm that applies to surfaces of arbitrary topology. As opposed to other existing optimization-based fairing methods, which are computationally more expensive, this is a linear time and space complexity algorithm. With this algorithm, fairing very large surfaces, such as those obtained from volumetric medical data, becomes affordable. By combining this algorithm with surface subdivision methods we obtain a very effective fair surface design technique. We then extend the analysis, and modify the algorithm accordingly, to accommodate different types of constraints. Some constraints can be imposed without any modification of the algorithm, while others require the solution of a small associated linear system of equations. In particular, vertex location constraints, vertex normal constraints, and surface normal discontinuities across curves embedded in the surface, can be imposed with this technique. CR Categories and Subject Descriptors: I.3.3 [Computer Graphics]: Picture/image generation - display algorithms; I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling - curve, surface, solid, and object representations;J.6[Com- puter Applications]: Computer-Aided Engineering - computeraided design General Terms: Algorithms, Graphics. 1</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>graphics</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Attali2003</b:Tag>
<b:Title>Complexity of the delaunay triangulation of points on surfaces the smooth case</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Attali</b:Last>
<b:First>Dominique</b:First>
</b:Person>
<b:Person>
<b:Last>Boissonnat</b:Last>
<b:First>Jean-Daniel</b:First>
</b:Person>
<b:Person>
<b:Last>Lieutier</b:Last>
<b:First>Andr\'{e}</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>201-210</b:Pages>
<b:StandardNumber> ISBN: 1-58113-663-3 DOI: http://doi.acm.org/10.1145/777792.777823</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SCG '03: Proceedings of the nineteenth annual symposium on Computational geometry</b:BookTitle>
<b:ConferenceName>SCG '03: Proceedings of the nineteenth annual symposium on Computational geometry</b:ConferenceName>
<b:BIBTEX_Abstract>It is well known that the complexity of the Delaunay triangulation of N points in R 3, i.e. the number of its faces, can be O (N2). The case of points distributed on a surface is of great practical importance in reverse engineering since most surface reconstruction algorithms first construct the Delaunay triangulation of a set of points measured on a surface.In this paper, we bound the complexity of the Delaunay triangulation of points distributed on generic smooth surfaces of R 3. Under a mild uniform sampling condition, we show that the complexity of the 3D Delaunay triangulation of the points is O(N log N).</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Jiang2012</b:Tag>
<b:Title>Curve skeleton extraction by coupled graph contraction and surface clustering</b:Title>
<b:Year>2012</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Jiang</b:Last>
<b:First>Wei</b:First>
</b:Person>
<b:Person>
<b:Last>Xu</b:Last>
<b:First>Kai</b:First>
</b:Person>
<b:Person>
<b:Last>Cheng</b:Last>
<b:First>Zhi-Quan</b:First>
</b:Person>
<b:Person>
<b:Last>Martin</b:Last>
<b:Middle>R.</b:Middle>
<b:First>Ralph</b:First>
</b:Person>
<b:Person>
<b:Last>Dang</b:Last>
<b:First>Gang</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>-</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1524-0703 DOI: 10.1016/j.gmod.2012.10.005</b:StandardNumber>
<b:JournalName>Graphical Models</b:JournalName>
<b:Issue>0</b:Issue>
<b:URL>http://www.sciencedirect.com/science/article/pii/S1524070312000732</b:URL>
<b:BIBTEX_Abstract>In this paper, we present a practical algorithm to extract a curve skeleton of a 3D shape. The core of our algorithm comprises coupled processes of graph contraction and surface clustering. Given a 3D shape represented by a triangular mesh, we first construct an initial skeleton graph by directly copying the connectivity and geometry information from the input mesh. Graph contraction and surface clustering are then performed iteratively. The former merges certain graph nodes based on computation of an approximate centroidal Voronoi diagram, seeded by subsampling the graph nodes from the previous iteration. Meanwhile, a coupled surface clustering process serves to regularize the graph contraction. Constraints are used to ensure that extremities of the graph are not shortened undesirably, to ensure that skeleton has the correct topological structure, and that surface clustering leads to an approximately-centered skeleton of the input shape. These properties lead to a stable and reliable skeleton graph construction algorithm.
Experiments demonstrate that our skeleton extraction algorithm satisfies various desirable criteria. Firstly, it produces a skeleton homotopic with the input (the genus of both shapes agree) which is both robust (results are stable with respect to noise and remeshing of the input shape) and reliable (every boundary point is visible from at least one curve-skeleton location). It can also handle point cloud data if we first build an initial skeleton graph based on k-nearest neighbors. In addition, a secondary output of our algorithm is a skeleton-to-surface mapping, which can e.g. be used directly for skinning animation. Highlights (1) An algorithm for curve skeleton extraction from 3D shapes based on coupled graph contraction and surface clustering. (2) The algorithm meets various desirable criteria and can be extended to work for incomplete point clouds.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Curve skeleton</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Tasdizen2002</b:Tag>
<b:Title>Geometric surface smoothing via anisotropic diffusion of normals</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tasdizen</b:Last>
<b:First>Tolga</b:First>
</b:Person>
<b:Person>
<b:Last>Whitaker</b:Last>
<b:First>Ross</b:First>
</b:Person>
<b:Person>
<b:Last>Burchard</b:Last>
<b:First>Paul</b:First>
</b:Person>
<b:Person>
<b:Last>Osher</b:Last>
<b:First>Stanley</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>125-132</b:Pages>
<b:StandardNumber> ISBN: 0-7803-7498-3</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>Proceedings of the conference on Visualization '02</b:BookTitle>
<b:ConferenceName>Proceedings of the conference on Visualization '02</b:ConferenceName>
<b:URL>http://dl.acm.org/citation.cfm?id=602099.602117</b:URL>
<b:BIBTEX_Series>VIS '02</b:BIBTEX_Series>
<b:BIBTEX_Abstract>This paper introduces a method for smoothing complex, noisy surfaces, while preserving (and enhancing) sharp, geometric features. It has two main advantages over previous approaches to feature preserving surface smoothing. First is the use of level set surface models, which allows us to process very complex shapes of arbitrary and changing topology. This generality makes it well suited for processing surfaces that are derived directly from measured data. The second advantage is that the proposed method derives from a well-founded formulation, which is a natural generalization of anisotropic diffusion, as used in image processing. This formulation is based on the proposition that the generalization of image filtering entails filtering the normals of the surface, rather than processing the positions of points on a mesh.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>anisotropic diffusion, geometric surface processing, intrinsic Laplacian of curvature, level sets, surface fairing</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Bottino2003</b:Tag>
<b:Title>Introducing a new problem: shape-from-silhouette when the relative positions of the viewpoints is unknown</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Bottino</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Laurentini</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1484-1493</b:Pages>
<b:Volume>25</b:Volume>
<b:StandardNumber> ISSN: 0162-8828 DOI: 10.1109/TPAMI.2003.1240121</b:StandardNumber>
<b:JournalName>Pattern Analysis and Machine Intelligence, IEEE Transactions on</b:JournalName>
<b:Issue>11</b:Issue>
<b:Month>Nov.</b:Month>
<b:BIBTEX_Abstract> 3D shapes can be reconstructed from 2D silhouettes by back-projecting them from the corresponding viewpoints and intersecting the resulting solid cones. However, in many practical cases as observing an aircraft or an asteroid, the positions of the viewpoints with respect to the object are not known. In these cases, the relative position of the solid cones is not known and the intersection cannot be performed. The purpose of this paper is introducing and stating in a theoretical framework the problem of understanding 3D shapes from silhouettes when the relative positions of the viewpoints are unknown. The results presented provide a first insight into the problem. In particular, the case of orthographic viewing directions parallel to the same plane is thoroughly discussed, and sets of inequalities are presented which allow determining objects compatible with the silhouettes.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> computer vision, image reconstruction computer vision, object reconstruction, shape-from-silhouette, viewpoints, visual hull, volume intersection</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Lanman2008</b:Tag>
<b:Title>Shield Fields: Modeling and Capturing 3D Occluders</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Lanman</b:Last>
<b:First>Douglas</b:First>
</b:Person>
<b:Person>
<b:Last>Raskar</b:Last>
<b:First>Ramesh</b:First>
</b:Person>
<b:Person>
<b:Last>Agrawal</b:Last>
<b:First>Amit</b:First>
</b:Person>
<b:Person>
<b:Last>Taubin</b:Last>
<b:First>Gabriel</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>10</b:Pages>
<b:Volume>27</b:Volume>
<b:JournalName>ACM Transactions on Graphics (Proc. SIGGRAPH Asia)</b:JournalName>
<b:Issue>5</b:Issue>
<b:BIBTEX_Abstract>We describe a unified representation of occluders in light transport and photography using shield fields: the 4D attenuation function which acts on any light field incident on an occluder. Our key theoretical result is that shield fields can be used to decouple the effects of occluders from the incident illumination. We first describe the properties of shield fields in the frequency-domain and briefly analyze the “forward” problem of efficiently computing cast shadows. Afterwards, we apply the shield field signal-processing framework to make several new observations regarding the “inverse” problem of reconstructing 3D occluders from cast shadows – extending previous work on shape-from-silhouette and visual hull methods. From this analysis we develop the first single-camera, single-shot approach to capture visual hulls without requiring moving or programmable illumination. We analyze several competing camera designs – ultimately leading to the development of a new large-format, mask-based light field camera that exploits optimal tiled-broadband codes for light-efficient shield field capture. We conclude by presenting a detailed experimental analysis of shield field capture and 3D occluder reconstruction.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Liu2008</b:Tag>
<b:Title>Surface Reconstruction From Non-parallel Curve Networks</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Liu</b:Last>
</b:Person>
<b:Person>
<b:Last>L.</b:Last>
</b:Person>
<b:Person>
<b:Last>Bajaj</b:Last>
</b:Person>
<b:Person>
<b:Last>C.</b:Last>
</b:Person>
<b:Person>
<b:Last>Deasy</b:Last>
</b:Person>
<b:Person>
<b:Last>O.</b:Last>
<b:First>J.</b:First>
</b:Person>
<b:Person>
<b:Last>Low</b:Last>
</b:Person>
<b:Person>
<b:Last>A.</b:Last>
<b:First>D.</b:First>
</b:Person>
<b:Person>
<b:Last>Ju</b:Last>
</b:Person>
<b:Person>
<b:Last>T.</b:Last>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>155-163</b:Pages>
<b:Volume>27</b:Volume>
<b:StandardNumber> ISSN: 0167-7055 DOI: http://dx.doi.org/10.1111/j.1467-8659.2008.01112.x</b:StandardNumber>
<b:Publisher>Blackwell Publishing</b:Publisher>
<b:JournalName>Computer Graphics Forum</b:JournalName>
<b:Issue>2</b:Issue>
<b:Month>April</b:Month>
<b:URL>http://dx.doi.org/10.1111/j.1467-8659.2008.01112.x</b:URL>
<b:BIBTEX_Abstract>Building surfaces from cross-section curves has wide applications including bio-medical modeling. Previous work in this area has mostly focused on connecting simple closed curves on parallel cross-sections. Here we consider the more general problem where input data may lie on non-parallel cross-sections and consist of curve networks that represent the segmentation of the underlying object by different material or tissue types (e.g., skin, muscle, bone, etc.) on each cross-section. The desired output is a surface network that models both the exterior surface and the internal partitioning of the object. We introduce an algorithm that is capable of handling curve networks of arbitrary shape and topology on cross-section planes with arbitrary orientations. Our algorithm is simple to implement and is guaranteed to produce a closed surface network that interpolates the curve network on each cross-section. Our method is demonstrated on both synthetic and bio-medical examples.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Niem1996</b:Tag>
<b:Title>Camera viewpoint control for the automatic reconstruction of 3D objects</b:Title>
<b:Year>1996</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Niem</b:Last>
<b:First>W.</b:First>
</b:Person>
<b:Person>
<b:Last>Steinmetz</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>655-658 vol.3</b:Pages>
<b:Volume>3</b:Volume>
<b:StandardNumber> DOI: 10.1109/ICIP.1996.560580</b:StandardNumber>
<b:BookTitle>Image Processing</b:BookTitle>
<b:JournalName>Image Processing, 1996. Proceedings., International Conference on</b:JournalName>
<b:ConferenceName>Image Processing</b:ConferenceName>
<b:Month>Sep</b:Month>
<b:BIBTEX_Abstract>An algorithm for the image dependent control of the camera viewpoint is presented, which is applied to the automatic reconstruction of 3D objects. For computer animation applications, “shape from silhouettes” using equally distributed viewpoints is an often used reconstruction technique. With respect to the local reconstruction errors, the use of equally distributed camera views is unfavourable for arbitrary shaped objects. For that reason, a camera viewpoint control is introduced, which purposefully rotates a turntable with the 3D object depending on the trace of the silhouette contour points over the rotation angle. This trace provides information about the location of object planes and gives a measure for the expected local 3D reconstruction errors. It turns out, that the new algorithm reduces the remaining 3D reconstruction errors up to 70% compared to algorithms without viewpoint control using the same number of viewpoints</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>cameras, computer animation, image reconstruction, image segmentation, motion estimation, telecommunication control3D objects, 3D reconstruction error reduction, algorithm, automatic reconstruction, camera viewpoint control, computer animation applications, image dependent control, local 3D reconstruction errors, local reconstruction errors, object planes location, rotation angle, shape from silhouettes, silhouette contour points, turntable rotation</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Tierny2006</b:Tag>
<b:Title>3D Mesh Skeleton Extraction Using Topological and Geometrical Analyses</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tierny</b:Last>
<b:First>Julien</b:First>
</b:Person>
<b:Person>
<b:Last>Vandeborre</b:Last>
<b:First>Jean-Philippe</b:First>
</b:Person>
<b:Person>
<b:Last>Daoudi</b:Last>
<b:First>Mohamed</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>85-94</b:Pages>
<b:City>Taipei, Taiwan</b:City>
<b:BookTitle>14th Pacific Conference on Computer Graphics and Applications (Pacific Graphics 2006)</b:BookTitle>
<b:ConferenceName>14th Pacific Conference on Computer Graphics and Applications (Pacific Graphics 2006)</b:ConferenceName>
<b:BIBTEX_Abstract>This paper describes a novel and unified approach for Reeb graph construction and simplification as well as constriction approximation on 3D polygonal meshes. The key idea of our algorithm is that discrete contours - curves carried by the edges of the mesh and approximating the continuous contours of a mapping function - encode both topological and geometrical shape characteristics.
Firstly, mesh feature points are computed. Then they are used as geodesic origins for the computation of an invariant mapping function that reveals the shape most significant features. Secondly, for each vertex in the mesh, its discrete contour is computed. As the set of discrete contours recovers the whole surface, each of them can be analyzed, both to detect topological changes or constrictions. Constriction approximations enable Reeb graphs refinement into more visually meaningful skeletons, that we refer as enhanced topological skeletons.
Without pre-processing stages and without input parameters, our method provides nice-looking and affine-invariant skeletons, with satisfactory execution times. This makes enhanced topological skeletons good candidates for applications needing high level shape representations, such as mesh deformation (experimented in this paper), retrieval, compression, metamorphosis, etc.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Jin2007</b:Tag>
<b:Title>Image-based shape model for view-invariant human motion recognition</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Jin</b:Last>
<b:First>Ning</b:First>
</b:Person>
<b:Person>
<b:Last>Mokhtarian</b:Last>
<b:First>F.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>336-341</b:Pages>
<b:StandardNumber> DOI: 10.1109/AVSS.2007.4425333</b:StandardNumber>
<b:BookTitle>Advanced Video and Signal Based Surveillance</b:BookTitle>
<b:JournalName>Advanced Video and Signal Based Surveillance, 2007. AVSS 2007. IEEE Conference on</b:JournalName>
<b:ConferenceName>Advanced Video and Signal Based Surveillance</b:ConferenceName>
<b:Month>Sept.</b:Month>
<b:BIBTEX_Abstract>We propose an image-based shape model for view-invariant human motion recognition. Image-based visual hull explicitly represents the 3D shape of an object, which is computed from a set of silhouettes. We then use the set of silhouettes to implicitly represent the visual hull. Due to the fact that a silhouette is the 2D projection of an object in the 3D world with respect to a certain camera, which is sensitive to the point of view, our multi-silhouette representation for the visual hull entails the correspondence between views. To guarantee the correspondence, we define a canonical multi-camera system and a canonical human body orientation in motions. We then "normalize" all the constructed visual hulls into the canonical multi-camera system, align them to follow the canonical orientation, and finally render them. The rendered views thereby satisfy the requirement of the correspondence. In our visual hull's representation, each silhouette is represented as a fixed number of sampled points on its closed contour, therefore, the 3D shape information is implicitly encoded into the concatenation of multiple 2D contours. Each motion class is then learned by a Hidden Markov Model (HMM) with mixture of Gaussians outputs. Experiments using our algorithm over some data sets give encouraging results.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Gaussian processes, cameras, hidden Markov models, image motion analysis, image representation, rendering (computer graphics)3D shape information, Gaussian process, canonical human body orientation, canonical multi camera system, hidden Markov model, image-based shape model, image-based visual hull representation, multi silhouette representation, view-invariant human motion recognition</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Magnor2003</b:Tag>
<b:Title>Capturing the shape of a dynamic world - fast!</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Magnor</b:Last>
<b:First>M.</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>H.-P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>3-9</b:Pages>
<b:StandardNumber> ISSN:   DOI: 10.1109/SMI.2003.1199589</b:StandardNumber>
<b:BookTitle>Shape Modeling International</b:BookTitle>
<b:JournalName>Shape Modeling International, 2003</b:JournalName>
<b:ConferenceName>Shape Modeling International</b:ConferenceName>
<b:Month>May</b:Month>
<b:BIBTEX_Abstract>Acquiring online the evolving shape of a dynamic scene from a handful of video streams may be considered one of the most challenging, but at the same time also most auspicious tasks in contemporary computer graphics and computer vision research. The anticipation of revolutionary new applications such as interactive 3D television broadcasts motivates the ongoing work on free-viewpoint video rendering. The paper aims at giving a state-of-progress report on this lively research endeavor. Different acquisition setups and online reconstruction approaches are exemplified. Yielding interactive frame rates, depth map-based techniques, polyhedral as well as volumetric visual hull reconstruction approaches, and combined methods employing visual hull-guided depth map estimation are presented. The experience gained with these approaches allows us to identify future research directions towards real-time analysis and high-quality synthesis of dynamic, real-world scenes.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> computational geometry, image reconstruction, rendering (computer graphics), video signal processing acquisition setup, computer graphics, computer vision, depth map estimation, depth map-based technique, dynamic scene, dynamic world, evolving shape, free-viewpoint video rendering, high-quality synthesis, interactive 3D television broadcast, interactive frame rate, online reconstruction, polyhedral visual hull reconstruction, real-time analysis, shape capture, state-of-progress report, video stream, volumetric visual hull reconstruction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Aguiar2004</b:Tag>
<b:Title>M3 : Marker-free Model Reconstruction and Motion Tracking from 3D Voxel Data</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>Edilson</b:First>
</b:Person>
<b:Person>
<b:Last>Theobalt</b:Last>
<b:First>Christian</b:First>
</b:Person>
<b:Person>
<b:Last>Magnor</b:Last>
<b:First>Marcus</b:First>
</b:Person>
<b:Person>
<b:Last>Theisel</b:Last>
<b:First>Holger</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>Hans-Peter</b:First>
</b:Person>
</b:NameList>
</b:Author>
<b:Editor>
<b:NameList>
<b:Person>
<b:Last>Cohen-Or</b:Last>
<b:First>Daniel</b:First>
</b:Person>
<b:Person>
<b:Last>Ko</b:Last>
<b:First>Hyeong-Seok</b:First>
</b:Person>
<b:Person>
<b:Last>Terzopoulos</b:Last>
<b:First>Demetri</b:First>
</b:Person>
<b:Person>
<b:Last>Warren</b:Last>
<b:First>Joe</b:First>
</b:Person>
</b:NameList>
</b:Editor>
</b:Author>
<b:Pages>101-110</b:Pages>
<b:StandardNumber> ISBN: 0-7695-2234-3</b:StandardNumber>
<b:Publisher>IEEE</b:Publisher>
<b:City>Seoul, Korea</b:City>
<b:BookTitle>12th Pacific Conference on Computer Graphics and Applications, PG 2004</b:BookTitle>
<b:ConferenceName>12th Pacific Conference on Computer Graphics and Applications, PG 2004</b:ConferenceName>
<b:Month>October</b:Month>
<b:BIBTEX_Abstract>In computer animation, human motion capture from video is a widely used technique to acquire motion parameters. The acquisition process typically requires an intrusion into the scene in the form of optical markers which are used to estimate the parameters of motion as well as the kinematic structure of the performer. Marker-free optical motion capture approaches exist, but due to their dependence on a specific type of a-priori model they can hardly be used to track other subjects, e.g. animals. To bridge the gap between the generality of marker-based methods and the applicability of marker-free methods we study a flexible nonintrusive approach that estimates both, a kinematic model and its parameters of motion from a sequence of voxel-volumes. The volume sequences are reconstructed from multi-view video data by means of a shape from-silhouette technique. The method [1] is well-suited for but not limited to motion capture of human subjects, as presented in [2].</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Madaras2010</b:Tag>
<b:Title>Skeleton extraction from a mesh for easy skinning animation</b:Title>
<b:Year>2010</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Madaras</b:Last>
<b:First>Martin</b:First>
</b:Person>
<b:Person>
<b:Last>\v{D}urikovi\v{c}</b:Last>
<b:First>Roman</b:First>
</b:Person>
<b:Person>
<b:Last>\'{A}go\v{s}ton</b:Last>
<b:First>Tom\'{a}\v{s}</b:First>
</b:Person>
<b:Person>
<b:Last>Nishita</b:Last>
<b:First>Tomoyuki</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>37-41</b:Pages>
<b:Publisher>University of Aizu Press</b:Publisher>
<b:City>Fukushima-ken, Japan, Japan</b:City>
<b:BookTitle>Proceedings of the 13th International Conference on Humans and Computers</b:BookTitle>
<b:ConferenceName>Proceedings of the 13th International Conference on Humans and Computers</b:ConferenceName>
<b:URL>http://dl.acm.org/citation.cfm?id=1994486.1994499</b:URL>
<b:BIBTEX_Series>HC '10</b:BIBTEX_Series>
<b:BIBTEX_Abstract>This paper proposes the extraction of a skeleton and skinning weights from a given mesh, describes how to store computed data in Collada 1.5 and use it for an animation. Firstly, the mesh is contracted using constrained Laplacian smoothing in a few iterations. Few vertices from the contracted mesh are chosen as control points. Multiple edges are removed and vertices that are very close to each other are merged using a greedy algorithm minimizing the energy. The greedy selection is applied repeatable until we have the tree structure with edges corresponding to bones. We also propose the automatic assignment of the skinning weights that determine the rigid or soft mesh deformations. In the postprocessing stage the user can inspect the skeleton by previewing skinning deformations, make desired changes and export the skeleton to Collada 1.5. Transformation matrices used in a hierarchical skeleton tree are not transformed to joint's local transformation frame, so they are immediately compatible with majority of animation software and libraries.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Collada 1.5, mesh contraction, mesh skinning, skeleton extraction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Wand2007</b:Tag>
<b:Title>Reconstruction of Deforming Geometry from Time-Varying Point Clouds</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Wand</b:Last>
<b:First>Michael</b:First>
</b:Person>
<b:Person>
<b:Last>Jenke</b:Last>
<b:First>Philipp</b:First>
</b:Person>
<b:Person>
<b:Last>Huang</b:Last>
<b:First>Qi-Xing</b:First>
</b:Person>
<b:Person>
<b:Last>Bokeloh</b:Last>
<b:First>Martin</b:First>
</b:Person>
<b:Person>
<b:Last>Guibas</b:Last>
<b:First>Leonidas</b:First>
</b:Person>
<b:Person>
<b:Last>Schilling</b:Last>
<b:First>Andreas</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>49-58</b:Pages>
<b:BookTitle>Proc. Eurographis Symp. on Geometry Processing (SGP) 2007</b:BookTitle>
<b:ConferenceName>Proc. Eurographis Symp. on Geometry Processing (SGP) 2007</b:ConferenceName>
<b:BIBTEX_Abstract>In this paper, we describe a system for the reconstruction of deforming geometry from a time sequence of unstructured, noisy point clouds, as produced by recent real-time range scanning devices. Our technique reconstructs both the geometry and dense correspondences over time. Using the correspondences, holes due to occlusion are filled in from other frames. Our reconstruction technique is based on a statistical framework: The reconstruction should both match the measured data points and maximize prior probability densities that prefer smoothness, rigid deformation and smooth movements over time. The optimization procedure consists of an inner loop that optimizes the 4D shape using continuous numerical optimization and an outer loop that infers the discrete 4D topology of the data set using an iterative model assembly algorithm. We apply the technique to a variety of data sets, demonstrating that the new approach is capable of robustly retrieving animated models with correspondences from data sets suffering from significant noise, outliers and acquisition holes.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Xue2009</b:Tag>
<b:Title>Feature fusion for basic behavior unit segmentation from video sequences</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Xue</b:Last>
<b:First>Xinwei</b:First>
</b:Person>
<b:Person>
<b:Last>Henderson</b:Last>
<b:Middle>C.</b:Middle>
<b:First>Thomas</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>239-248</b:Pages>
<b:Volume>57</b:Volume>
<b:StandardNumber> ISSN: 0921-8890 DOI: http://dx.doi.org/10.1016/j.robot.2008.10.018</b:StandardNumber>
<b:Publisher>North-Holland Publishing Co.</b:Publisher>
<b:City>Amsterdam, The Netherlands, The Netherlands</b:City>
<b:JournalName>Robot. Auton. Syst.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>It has become increasingly popular to study animal behaviors with the assistance of video recordings. An automated video processing and behavior analysis system is desired to replace the traditional manual annotation. We propose a framework for automatic video based behavior analysis systems, which consists of four major modules: behavior modeling, feature extraction from video sequences, basic behavior unit (BBU) discovery and complex behavior recognition. BBU discovery is performed based on features extracted from video sequences, hence the fusion of multiple dimensional features is very important. In this paper, we explore the application of feature fusion techniques to BBU discovery with one and multiple cameras. We applied the vector fusion (SBP) method, a multi-variate vector visualization technique, in fusing the features obtained from a single camera. This technique reduces the multiple dimensional data into two dimensional (SBP) space, and the spatial and temporal analysis in SBP space can help discover the underlying data groups. Then we present a simple feature fusion technique for BBU discovery from multiple cameras with the affinity graph method. Finally, we present encouraging results on a physical system and a synthetic mouse-in-a-cage scenario from one, two, and three cameras. The feature fusion methods in this paper are simple yet effective.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Report</b:SourceType>
<b:BIBTEX_Entry>techreport</b:BIBTEX_Entry>
<b:Tag>Theobalt2005</b:Tag>
<b:Title>Joint Motion and Reflectance Capture for Creating Relightable 3D Videos</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Theobalt</b:Last>
<b:First>Christian</b:First>
</b:Person>
<b:Person>
<b:Last>Ahmed</b:Last>
<b:First>Naveed</b:First>
</b:Person>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>Edilson</b:First>
</b:Person>
<b:Person>
<b:Last>Ziegler</b:Last>
<b:First>Gernot</b:First>
</b:Person>
<b:Person>
<b:Last>Lensch</b:Last>
<b:Middle>P. A.</b:Middle>
<b:First>Hendrik</b:First>
</b:Person>
<b:Person>
<b:Last>Magnor</b:Last>
<b:First>Marcus</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>Hans-Peter</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>17</b:Pages>
<b:City>Saarbruecken, Germany</b:City>
<b:Issue>MPI-I-2005-4-004</b:Issue>
<b:Institution>Max-Planck-Institut fuer Informatik</b:Institution>
<b:ThesisType>Research Report</b:ThesisType>
<b:Month>April</b:Month>
<b:BIBTEX_Abstract>3D Videos of Human Actors can be faithfully reconstructed from multiple synchronized video streams by means of a model-based analysis-by-synthesis approach. The reconstructed videos play back in real-time and the virtual viewpoint onto the scene can be arbitrarily changed. By this means authentically animated, photo-realistically and view-dependently textured models of real people can be created that look real under fixed illumination conditions. To import real-world characters into virtual environments, however, also surface reflectance properties must be known. We have thus developed a video-based modeling approach that captures human motion as well as reflectance characteristics from a handful of synchronized video recordings. The presented method [1][2][3] is able to recover spatially varying reflectance properties of clothes by exploiting the time-varying orientation of each surface point with respect to camera and light direction. The resulting model description enables us to match animated subject appearance to different lighting conditions, as well as to interchange surface attributes among different people, e.g. for virtual dressing.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Caillette2008</b:Tag>
<b:Title>Real-time 3-D human body tracking using learnt models of behaviour</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Caillette</b:Last>
<b:First>Fabrice</b:First>
</b:Person>
<b:Person>
<b:Last>Galata</b:Last>
<b:First>Aphrodite</b:First>
</b:Person>
<b:Person>
<b:Last>Howard</b:Last>
<b:First>Toby</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>112-125</b:Pages>
<b:Volume>109</b:Volume>
<b:StandardNumber> ISSN: 1077-3142 DOI: http://dx.doi.org/10.1016/j.cviu.2007.05.005</b:StandardNumber>
<b:Publisher>Elsevier Science Inc.</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>Comput. Vis. Image Underst.</b:JournalName>
<b:Issue>2</b:Issue>
<b:BIBTEX_Abstract>In this paper, we introduce a 3-D human-body tracker capable of handling fast and complex motions in real-time. We build upon the Monte–Carlo Bayesian framework, and propose novel prediction and evaluation methods improving the robustness and efficiency of the tracker. The parameter space, augmented with first order derivatives, is automatically partitioned into Gaussian clusters each representing an elementary motion: hypothesis propagation inside each cluster is therefore accurate and efficient. The transitions between clusters use the predictions of a variable length Markov model which can explain high-level behaviours over a long history. Using Monte–Carlo methods, evaluation of model candidates is critical for both speed and robustness. We present a new evaluation scheme based on hierarchical 3-D reconstruction and blob-fitting, where appearance models and image evidences are represented by mixtures of Gaussian blobs. Our tracker is also capable of automatic-initialisation and self-recovery. We demonstrate the application of our tracker to long video sequences exhibiting rapid and diverse movements.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Styner2003</b:Tag>
<b:Title>Automatic and Robust Computation of 3D Medial Models Incorporating Object Variability</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Styner</b:Last>
<b:First>Martin</b:First>
</b:Person>
<b:Person>
<b:Last>Gerig</b:Last>
<b:First>Guido</b:First>
</b:Person>
<b:Person>
<b:Last>Joshi</b:Last>
<b:First>Sarang</b:First>
</b:Person>
<b:Person>
<b:Last>Pizer</b:Last>
<b:First>Stephen</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>107-122</b:Pages>
<b:Volume>55</b:Volume>
<b:StandardNumber> ISSN: 0920-5691</b:StandardNumber>
<b:Publisher>Springer Netherlands</b:Publisher>
<b:JournalName>International Journal of Computer Vision</b:JournalName>
<b:URL>http://dx.doi.org/10.1023/A:1026378916288</b:URL>
<b:BIBTEX_Abstract>This paper presents a novel processing scheme for the automatic and robust computation of a medial shape model, which represents an object population with shape variability. The sensitivity of medial descriptions to object variations and small boundary perturbations are fundamental problems of any skeletonization technique. These problems are approached with the computation of a model with common medial branching topology and grid sampling. This model is then used for a medial shape description of individual objects via a constrained model fit.</b:BIBTEX_Abstract>
<b:BIBTEX_Affiliation>Duke Image Analysis Lab, Department of Radiology Duke University Medical Center USA</b:BIBTEX_Affiliation>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Chen2009</b:Tag>
<b:Title>A Benchmark for {3D} Mesh Segmentation</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>Xiaobai</b:First>
</b:Person>
<b:Person>
<b:Last>Golovinskiy</b:Last>
<b:First>Aleksey</b:First>
</b:Person>
<b:Person>
<b:Last>Funkhouser</b:Last>
<b:First>Thomas</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1</b:Pages>
<b:Volume>28</b:Volume>
<b:JournalName>ACM Transactions on Graphics (Proc. SIGGRAPH)</b:JournalName>
<b:Issue>3</b:Issue>
<b:Month>#aug#</b:Month>
<b:BIBTEX_Abstract>This paper describes a benchmark for evaluation of 3D mesh segmentation algorithms. The benchmark comprises a data set with 4,300 manually generated segmentations for 380 surface meshes of 19 different object categories, and it includes software for analyzing 11 geometric properties of segmentations and producing 4 quantitative metrics for comparison of segmentations. The paper investigates the design decisions made in building the benchmark, analyzes properties of human-generated and computer-generated segmentations, and provides quantitative comparisons of 7 recently published mesh segmentation algorithms. Our results suggest that people are remarkably consistent in the way that they segment most 3D surface meshes, that no one automatic segmentation algorithm is better than the others for all types of objects, and that algorithms based on non-local shape features seem to produce segmentations that most closely resemble ones made by humans.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Nedevschi2006</b:Tag>
<b:Title>Real-Time 3D Environment Reconstruction Using High Precision Trinocular Stereovision</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Nedevschi</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Bota</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Marita</b:Last>
<b:First>T.</b:First>
</b:Person>
<b:Person>
<b:Last>Oniga</b:Last>
<b:First>F.</b:First>
</b:Person>
<b:Person>
<b:Last>Pocol</b:Last>
<b:First>C.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>333-338</b:Pages>
<b:Volume>2</b:Volume>
<b:StandardNumber> ISBN: 1-4244-0360-X DOI: http://doi.ieeecomputersociety.org/10.1109/AQTR.2006.254655</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Los Alamitos, CA, USA</b:City>
<b:JournalName>International Conference on Automation, Quality and Testing, Robotics</b:JournalName>
<b:BIBTEX_Abstract>This paper presents an implementation of a 3D environment reconstruction system, using trinocular (3 camera) stereovision. The system does not use rectification, in order to improve precision. Sub-pixel accuracy correlation is used. Feature extraction and correlation use MMX and SSE2 optimizations. Reconstruction correctitude tests were conducted using both synthetically generated images and camera acquired images</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Wei2010</b:Tag>
<b:Title>VideoMocap: modeling physically realistic human motion from monocular video sequences</b:Title>
<b:Year>2010</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Wei</b:Last>
<b:First>Xiaolin</b:First>
</b:Person>
<b:Person>
<b:Last>Chai</b:Last>
<b:First>Jinxiang</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>42:1--42:10</b:Pages>
<b:Volume>29</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/1778765.1778779</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Month>July</b:Month>
<b:URL>http://doi.acm.org/10.1145/1778765.1778779</b:URL>
<b:BIBTEX_Abstract>This paper presents a video-based motion modeling technique for capturing physically realistic human motion from monocular video sequences. We formulate the video-based motion modeling process in an image-based keyframe animation framework. The system first computes camera parameters, human skeletal size, and a small number of 3D key poses from video and then uses 2D image measurements at intermediate frames to automatically calculate the "in between" poses. During reconstruction, we leverage Newtonian physics, contact constraints, and 2D image measurements to simultaneously reconstruct full-body poses, joint torques, and contact forces. We have demonstrated the power and effectiveness of our system by generating a wide variety of physically realistic human actions from uncalibrated monocular video sequences such as sports video footage.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>data-driven animation, interactive 3D visual tracking, performance animation, physics-based animation, video-based motion capture, vision for graphics</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Shu2008</b:Tag>
<b:Title>Hardware-based camera calibration and 3D modelling under circular motion</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Shu</b:Last>
<b:First>Bo</b:First>
</b:Person>
<b:Person>
<b:Last>Qiu</b:Last>
<b:First>Xianjie</b:First>
</b:Person>
<b:Person>
<b:Last>Wang</b:Last>
<b:First>Zhaoqi</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-6</b:Pages>
<b:StandardNumber> DOI: 10.1109/CVPRW.2008.4563093</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition Workshops</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition Workshops, 2008. CVPRW '08. IEEE Computer Society Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition Workshops</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>In this paper, we present a combined camera calibration and image based modeling method using an iterative optimization of shape from silhouette under circular motion. By minimizing the difference between the projections of reconstructed visual hull and the silhouette images using graphics hardware, the optimization can finally converge to accurate camera parameters and realistic visual hull efficiently and robustly. Using this method, we can automatically create photorealistic 3D models directly from images.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image motion analysis, image reconstruction, image sensors, optimisation, realistic images, solid modellingcircular motion, graphics hardware, hardware-based camera calibration, image based modeling method, iterative optimization, photorealistic 3D modelling, reconstructed visual hull, silhouette image</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Sundar2003</b:Tag>
<b:Title>Skeleton Based Shape Matching and Retrieval</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Sundar</b:Last>
<b:First>H.</b:First>
</b:Person>
<b:Person>
<b:Last>Silver</b:Last>
<b:First>D.</b:First>
</b:Person>
<b:Person>
<b:Last>Gagvani</b:Last>
<b:First>N.</b:First>
</b:Person>
<b:Person>
<b:Last>Dickinson</b:Last>
<b:First>S.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>130--</b:Pages>
<b:StandardNumber> ISBN: 0-7695-1909-1</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>Proceedings of the Shape Modeling International 2003</b:BookTitle>
<b:ConferenceName>Proceedings of the Shape Modeling International 2003</b:ConferenceName>
<b:URL>http://portal.acm.org/citation.cfm?id=829510.830339</b:URL>
<b:BIBTEX_Abstract>In this paper, we describe a novel method for searchingand comparing 3D objects. The method encodes the geometricand topological information in the form of a skeletalgraph and uses graph matching techniques to match theskeletons and to compare them. The skeletal graphs canbe manually annotated to refine or restructure the search.This helps in choosing between a topological similarity anda geometric (shape) similarity. A feature of skeletal matchingis the ability to perform part-matching, and its inherentintuitiveness, which helps in defining the search and invisualizing the results. Also, the matching results, whichare presented in a per-node basis can be used for driving anumber of registration algorithms, most of which require agood initial guess to perform registration. In this paper, wealso describe a visualization tool to aid in the selection andspecification of the matched objects.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>citeulike:582023</b:Tag>
<b:Title>Spherical Matching for Temporal Correspondence of Non-Rigid Surfaces</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Starck</b:Last>
<b:First>J.</b:First>
</b:Person>
<b:Person>
<b:Last>Hilton</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1387-1394</b:Pages>
<b:BookTitle>IEEE International Conference on Computer Vision (ICCV)</b:BookTitle>
<b:JournalName>IEEE International Conference on Computer Vision (ICCV)</b:JournalName>
<b:ConferenceName>IEEE International Conference on Computer Vision (ICCV)</b:ConferenceName>
<b:BIBTEX_Abstract>This paper introduces spherical matching to estimate dense temporal correspondence of non-rigid surfaces with genus-zero topology. The spherical domain gives a consistent 2D parameterisation of non-rigid surfaces for matching. Non-rigid 3D surface correspondence is formulated as the recovery of a bijective mapping between two surfaces in the 2D domain. Formulating matching as a 2D bijection guarantees a continuous one-to-one surface correspondence without overfolding. This overcomes limitations of direct estimation of non-rigid surface correspondence in the 3D domain. A multiple resolution coarse-to-?ne algorithm is introduced to robustly estimate the dense correspondence which minimises the disparity in shape and appearance between two surfaces. 
Spherical matching is applied to derive the temporal correspondence between non-rigid surfaces reconstructed at successive frames from multiple view video sequences of people. Dense surface correspondence is recovered across complete motion sequences for both textured and uniform regions, without the requirement for a prior model of hu man shape or kinematic structure for tracking.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>starck</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Mundermann2007</b:Tag>
<b:Title>Accurately measuring human movement using articulated ICP with soft-joint constraints and a repository of articulated models</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Mundermann</b:Last>
<b:First>L.</b:First>
</b:Person>
<b:Person>
<b:Last>Corazza</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Andriacchi</b:Last>
<b:First>T.P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-6</b:Pages>
<b:StandardNumber> DOI: 10.1109/CVPR.2007.383302</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>A novel approach for accurate markerless motion capture combining a precise tracking algorithm with a database of articulated models is presented. The tracking approach employs an articulated iterative closest point algorithm with soft-joint constraints for tracking body segments in visual hull sequences. The database of articulated models is derived from a combination of human shapes and anthropometric data, contains a large variety of models and closely mimics variations found in the human population. The database provides articulated models that closely match the outer appearance of the visual hulls, e.g. matches overall height and volume. This information is paired with a kinematic chain enhanced through anthropometric regression equations. Deviations in the kinematic chain from true joint center locations are compensated by the soft-joint constraints approach. As a result accurate and a more anatomical correct outcome is obtained suitable for biomechanical and clinical applications. Joint kinematics obtained using this approach closely matched joint kinematics obtained from a marker based motion capture system.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image motion analysis, image segmentation, iterative methods, regression analysisanthropometric regression equations, articulated ICP, articulated model repository, body segment tracking, human movement, iterative closest point algorithm, joint center locations, joint kinematics, motion capture system, soft-joint constraints, soft-joint constraints approach, tracking algorithm</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Barr1989</b:Tag>
<b:Title>The Einstein Summation Notation: Introduction to Cartesian Tensors and Extensions to the Notation</b:Title>
<b:Year>1989</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Barr</b:Last>
<b:Middle>H.</b:Middle>
<b:First>Alan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>J1-J12</b:Pages>
<b:Volume>30</b:Volume>
<b:JournalName>SIGGRAPH 89</b:JournalName>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>AndreiSharf2007</b:Tag>
<b:Title>On-the-fly Curve-skeleton Computation for 3D Shapes</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Andrei Sharf</b:Last>
<b:Middle>Lewiner, Ariel Shamir Leif Kobbelt</b:Middle>
<b:First>Thomas</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Volume>26</b:Volume>
<b:StandardNumber> DOI: 10.1111/j.1467-8659.2007.01054.x</b:StandardNumber>
<b:City>School of Computer Science, Tel Aviv University; Departament of Mathematics, PUCRio de Janiero; Efi Arazi School of Computer Science, The Interdisciplinary Center, Herzliya; Computer Graphics Group, RWTH Aachen</b:City>
<b:BookTitle>Computer Graphics Forum</b:BookTitle>
<b:Issue>3</b:Issue>
<b:ConferenceName>Computer Graphics Forum</b:ConferenceName>
<b:URL>http://dx.doi.org/10.1111/j.1467-8659.2007.01054.x</b:URL>
<b:BIBTEX_Series>323-328</b:BIBTEX_Series>
<b:BIBTEX_Abstract>The curve-skeleton of a 3D object is an abstract geometrical and topological representation of its 3D shape. It maps the spatial relation of geometrically meaningful parts to a graph structure. Each arc of this graph represents a part of the object with roughly constant diameter or thickness, and approximates its centerline. This makes the curve-skeleton suitable to describe and handle articulated objects such as characters for animation. We present an algorithm to extract such a skeleton on-the-fly, both from point clouds and polygonal meshes. The algorithm is based on a deformable model evolution that captures the object's volumetric shape. The deformable model involves multiple competing fronts which evolve inside the object in a coarse-to-fine manner. We first track these fronts' centers, and then merge and filter the resulting arcs to obtain a curve-skeleton of the object. The process inherits the robustness of the reconstruction technique, being able to cope with noisy input, intricate geometry and complex topology. It creates a natural segmentation of the object and computes a center curve for each segment while maintaining a full correspondence between the skeleton and the boundary of the object.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Zhang2009</b:Tag>
<b:Title>Laplacian lines for real-time shape illustration</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Long</b:First>
</b:Person>
<b:Person>
<b:Last>He</b:Last>
<b:First>Ying</b:First>
</b:Person>
<b:Person>
<b:Last>Xie</b:Last>
<b:First>Xuexiang</b:First>
</b:Person>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>Wei</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>129-136</b:Pages>
<b:StandardNumber> ISBN: 978-1-60558-429-4 DOI: http://doi.acm.org/10.1145/1507149.1507170</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>I3D '09: Proceedings of the 2009 symposium on Interactive 3D graphics and games</b:BookTitle>
<b:ConferenceName>I3D '09: Proceedings of the 2009 symposium on Interactive 3D graphics and games</b:ConferenceName>
<b:BIBTEX_Abstract>This paper presents a novel object-space line drawing algorithm that can depict shape with view dependent feature lines in real-time. Strongly inspired by the Laplacian-of-Gaussian (LoG) edge detector in image processing, we define Laplacian Lines as the zero-crossing points of the Laplacian of the surface illumination. Compared to other view dependent features, Laplacian lines are computationally efficient because most expensive computations can be pre-processed. Thus, Laplacian lines are very promising for interactively illustrating large-scale models.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Chen2008</b:Tag>
<b:Title>Connection skeleton extraction based on contour connectedness</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>Mang</b:First>
</b:Person>
<b:Person>
<b:Last>Liu</b:Last>
<b:First>Yun-cai</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>521-527</b:Pages>
<b:Volume>13</b:Volume>
<b:JournalName>Journal of Shanghai Jiaotong University (Science)</b:JournalName>
<b:Issue>5</b:Issue>
<b:Month>#oct#</b:Month>
<b:URL>http://dx.doi.org/10.1007/s12204-008-0521-x</b:URL>
<b:BIBTEX_Abstract>Abstract&amp;nbsp;&amp;nbsp;A stable skeleton is very important to some applications such as vehicle navigation, object represent and pattern recognition. The connection skeleton is just one that not only can be computed stably but also can figure the connectivity structure of contour. A new method named continuous connectivity detection and a new model named approximate regular polygon (ARP) were proposed for connection skeleton extraction. Both the method and the model were tested by the real maps of road network including flyovers, interchanges and other common object contours. Satisfactory results were obtained.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Remondino2004</b:Tag>
<b:Title>3-D Reconstruction of Static Human Body Shape from Image Sequence</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Remondino</b:Last>
<b:First>Fabio</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>65-85</b:Pages>
<b:Volume>93</b:Volume>
<b:JournalName>Computer Vision and Image Understanding</b:JournalName>
<b:BIBTEX_Abstract>The generation of 3-D models from uncalibrated image sequences is a challenging problem that has been investigated in many research activities in the last decade. In particular, a topic of great interest is the modeling of realistic humans, for animation, manufacture or medicine purposes. Nowadays the common approaches try to reconstruct the human body using specialized hardware (laser scanners) resulting in high costs. In this contribution a different method for the three-dimensional reconstruction of static human body shape from monocular image sequence is presented. The core of the presented work describes the calibration and orientation of the images, mostly based on photogrammetric techniques. Then the process includes also the extraction of correspondences on the body using a least squares matching algorithm and the reconstruction of the 3-D body model in point cloud form.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Verroust1999</b:Tag>
<b:Title>Extracting skeletal curves from 3D scattered data</b:Title>
<b:Year>1999</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Verroust</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Lazarus</b:Last>
<b:First>F.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>194-201</b:Pages>
<b:StandardNumber> DOI: 10.1109/SMA.1999.749340</b:StandardNumber>
<b:BookTitle>International Conference on Shape Modeling and Applications, 1999.</b:BookTitle>
<b:JournalName>Shape Modeling and Applications, 1999. Proceedings. Shape Modeling International '99. International Conference on</b:JournalName>
<b:ConferenceName>International Conference on Shape Modeling and Applications, 1999.</b:ConferenceName>
<b:Month>Mar</b:Month>
<b:BIBTEX_Abstract>We introduce a method for extracting skeletal curves from an unorganized collection of scattered data points lying on a surface. These curves may have a tree like structure to capture branching shapes such as blood vessels. The skeletal curves can be used for different applications ranging from surface reconstruction to object recognition</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>curve fitting, image reconstruction, surface fitting3D scattered data, object recognition, scattered data points, skeletal curves, surface reconstruction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Visutsak2009</b:Tag>
<b:Title>Knowledge-based approach for 3D skeleton extraction</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Visutsak</b:Last>
<b:First>Porawat</b:First>
</b:Person>
<b:Person>
<b:Last>Boonjing</b:Last>
<b:First>Veera</b:First>
</b:Person>
<b:Person>
<b:Last>Prachumrak</b:Last>
<b:First>Korakot</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>796-801</b:Pages>
<b:StandardNumber> ISBN: 978-1-60558-710-3 DOI: http://doi.acm.org/10.1145/1655925.1656070</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human</b:BookTitle>
<b:ConferenceName>Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human</b:ConferenceName>
<b:URL>http://doi.acm.org/10.1145/1655925.1656070</b:URL>
<b:BIBTEX_Series>ICIS '09</b:BIBTEX_Series>
<b:BIBTEX_Abstract>A 3D skeleton is a one-voxel thick, graph-like structure, widely used in the area of a character animation. In this paper, we propose a novel method for the 3D skeleton extraction of the polyhedral models based on a priori knowledge of the learned skeleton. The method has several steps. First, the octree of the input model is calculated and used to compare with the octree of the 3D models stored in the octrees database. By comparing the octree similarities, if the searched results exactly match with the input octree, the corresponding skeleton will be retrieved from the skeletons database. Otherwise, the method finds the list of the close match (the octree similarity ratio which the value is greater than 0.8) in order to use to estimate the new skeleton. In the worst case, if the input octree does not match with any case in the octrees database, the method computes the new skeleton and stores it in the skeletons database. The method is fast and efficient because it is not necessary to extract the skeleton from every input model. Thus, the computational time of our method depends only on the time of the octree similarity calculation, and the time for searching the similar octree in the octrees database. Several examples show the results obtained with our approach.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computer animation, octree, skeleleton extraction, skeleton</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Ruggeri2008</b:Tag>
<b:Title>Spectral-Driven Isometry-Invariant Matching of 3D Shapes</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Ruggeri</b:Last>
<b:First>Mauro</b:First>
</b:Person>
<b:Person>
<b:Last>PatanÃ¨</b:Last>
<b:First>Giuseppe</b:First>
</b:Person>
<b:Person>
<b:Last>Spagnuolo</b:Last>
<b:First>Michela</b:First>
</b:Person>
<b:Person>
<b:Last>Saupe</b:Last>
<b:First>Dietmar</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1</b:Pages>
<b:Volume>1</b:Volume>
<b:JournalName>International Journal of Computer Vision</b:JournalName>
<b:URL>http://dx.doi.org/10.1007/s11263-009-0250-0</b:URL>
<b:BIBTEX_Abstract>Abstract&amp;nbsp;&amp;nbsp;This paper presents a matching method for 3D shapes, which comprises a new technique for surface sampling and two algorithms for matching 3D shapes based on point-based statistical shape descriptors. Our sampling technique is based on critical points of the eigenfunctions related to the smaller eigenvalues of the Laplace-Beltrami operator. These critical points are invariant to isometries and are used as anchor points of a sampling technique, which extends the farthest point sampling by using statistical criteria for controlling the density and number of reference points. Once a set of reference points has been computed, for each of them we construct a point-based statistical descriptor (PSSD, for short) of the input surface. This descriptor incorporates an approximation of the geodesic shape distribution and other geometric information describing the surface at that point. Then, the dissimilarity between two surfaces is computed by comparing the corresponding sets of PSSDs with bipartite graph matching or measuring the L 1-distance between the reordered feature vectors of a proximity graph. Here, the reordering is given by the Fiedler vector of a Laplacian matrix associated to the proximity graph. Our tests have shown that both approaches are suitable for online retrieval of deformed objects and our sampling strategy improves the retrieval performances of isometry-invariant matching methods. Finally, the approach based on the Fiedler vector is faster than using the bipartite graph matching and it has a similar retrieval effectiveness.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Laurentini1994</b:Tag>
<b:Title>The visual hull concept for silhouette-based image understanding </b:Title>
<b:Year>1994</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Laurentini</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>150-162</b:Pages>
<b:Volume>16</b:Volume>
<b:StandardNumber> ISSN: 0162-8828 DOI: 10.1109/34.273735</b:StandardNumber>
<b:JournalName>Pattern Analysis and Machine Intelligence, IEEE Transactions on</b:JournalName>
<b:Issue>2</b:Issue>
<b:Month>Feb</b:Month>
<b:BIBTEX_Abstract>Many algorithms for both identifying and reconstructing a 3-D object are based on the 2-D silhouettes of the object. In general, identifying a nonconvex object using a silhouette-based approach implies neglecting some features of its surface as identification clues. The same features cannot be reconstructed by volume intersection techniques using multiple silhouettes of the object. This paper addresses the problem of finding which parts of a nonconvex object are relevant for silhouette-based image understanding. For this purpose, the geometric concept of visual hull of a 3-D object is introduced. This is the closest approximation of object S that can be obtained with the volume intersection approach; it is the maximal object silhouette-equivalent to S, i.e., which can be substituted for S without affecting any silhouette. Only the parts of the surface of S that also lie on the surface of the visual hull can be reconstructed or identified using silhouette-based algorithms. The visual hull depends not only on the object but also on the region allowed to the viewpoint. Two main viewing regions result in the external and internal visual hull. In the former case the viewing region is related to the convex hull of S, in the latter it is bounded by S. The internal visual hull also admits an interpretation not related to silhouettes. Algorithms for computing visual hulls are presented and their complexity analyzed. In general, the visual hull of a 3-D planar face object turns out to be bounded by planar and curved patches</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image reconstructionexternal visual hull, internal visual hull, nonconvex object, object identification, object reconstruction, silhouette-based image understanding</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>Report</b:SourceType>
<b:BIBTEX_Entry>phdthesis</b:BIBTEX_Entry>
<b:Tag>Cheung2003b</b:Tag>
<b:Title>Visual Hull Construction, Alignment and Refinement for Human Kinematic Modeling, Motion Tracking and Rendering</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cheung</b:Last>
<b:Middle>Man</b:Middle>
<b:First>Kong</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:City>Pittsburgh, PA</b:City>
<b:Issue>CMU-RI-TR-03-44</b:Issue>
<b:Department>Robotics Institute, Carnegie Mellon University</b:Department>
<b:ThesisType>Ph.D. dissertation</b:ThesisType>
<b:Month>October</b:Month>
<b:BIBTEX_Abstract>The abilities to build precise human kinematic models and to perform accurate human motion tracking are essential in a wide variety of applications. Due to the complexity of the human bodies and the problem of self-occlusion, modeling and tracking humans using cameras are challenging tasks. In this thesis, we develop algorithms to perform these two tasks based on the shape estimation method Shape-From-Silhouette (SFS) which constructs a shape estimate (known as Visual Hull) of an object using its silhouettes images.

In the first half of this thesis we extend the traditional SFS algorithm so that it can be used effectively for the human related applications. To perform SFS in real-time, we propose a fast testing/projection algorithm for voxel-based SFS algorithms. Moreover, we combine silhouette information over time to effectively increase the number of cameras (and hence reconstruction details) for SFS without physically adding new cameras. We first propose a new Visual Hull representation called Bounding Edges. We then analyze the ambiguity problem of aligning two Visual Hulls. Based on the analysis, we develop an algorithm to align Visual Hulls over time using stereo and an important property of the Shape-From-Silhouette principle. This temporal SFS algorithm combines both geometric constraints and photometric consistency to align Colored Surface Points of the object extracted from the silhouette and color images. Once the Visual Hulls are aligned, they are refined by compensating for the motion of the object. The algorithm is developed for both rigid and articulated objects.

In the second half of this thesis we show how the improved SFS algorithms are used to perform the tasks of human modeling and motion tracking. First we build a system to acquire human kinematic models consisting of precise shape and joint locations. Once the kinematic models are built, they are used to track the motion of the person in new video sequences. The tracking algorithm is based on the Visual Hull alignment idea used in the temporal SFS algorithms. Finally we demonstrate how the kinematic model and the tracked motion data can be used for image-based rendering and motion transfer between two people.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Grauman2003</b:Tag>
<b:Title>A Bayesian approach to image-based visual hull reconstruction</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Grauman</b:Last>
<b:First>K.</b:First>
</b:Person>
<b:Person>
<b:Last>Shakhnarovich</b:Last>
<b:First>G.</b:First>
</b:Person>
<b:Person>
<b:Last>Darrell</b:Last>
<b:First>T.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> I-187-I-194 vol.1</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1063-6919  DOI: 10.1109/CVPR.2003.1211353</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract> We present a Bayesian approach to image-based visual hull reconstruction. The 3D (three-dimensional) shape of an object of a known class is represented by sets of silhouette views simultaneously observed from multiple cameras. We show how the use of a class-specific prior in a visual hull reconstruction can reduce the effect of segmentation errors from the silhouette extraction process. In our representation, 3D information is implicit in the joint observations of multiple contours from known viewpoints. We model the prior density using a probabilistic principal components analysis-based technique and estimate a maximum a posteriori reconstruction of multi-view contours. The proposed method is applied to a dataset of pedestrian images, and improvements in the approximate 3D models under various noise conditions are shown.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> Bayes methods, computer vision, edge detection, image denoising, image reconstruction, image representation, image segmentation, principal component analysis, stereo image processing 3D model, 3D object shape, Bayesian approach, image reconstruction, image representation, image segmentation, image-based visual hull reconstruction, maximum a posteriori reconstruction, multiple cameras, multiple contours, multiview contour, pedestrian image, probabilistic principal component analysis, silhouette extraction, silhouette view</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Desbrun1999</b:Tag>
<b:Title>Implicit fairing of irregular meshes using diffusion and curvature flow</b:Title>
<b:Year>1999</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Desbrun</b:Last>
<b:First>Mathieu</b:First>
</b:Person>
<b:Person>
<b:Last>Meyer</b:Last>
<b:First>Mark</b:First>
</b:Person>
<b:Person>
<b:Last>Schr\"{o}der</b:Last>
<b:First>Peter</b:First>
</b:Person>
<b:Person>
<b:Last>Barr</b:Last>
<b:Middle>H.</b:Middle>
<b:First>Alan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>317-324</b:Pages>
<b:StandardNumber> ISBN: 0-201-48560-5 DOI: http://doi.acm.org/10.1145/311535.311576</b:StandardNumber>
<b:Publisher>ACM Press/Addison-Wesley Publishing Co.</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '99: Proceedings of the 26th annual conference on Computer graphics and interactive techniques</b:BookTitle>
<b:ConferenceName>SIGGRAPH '99: Proceedings of the 26th annual conference on Computer graphics and interactive techniques</b:ConferenceName>
<b:BIBTEX_Abstract>In this paper, we develop methods to rapidly remove rough features from irregularly triangulated data intended to portray a smooth surface. The main task is to remove undesirable noise and uneven edges while retaining desirable geometric features. The problem arises mainly when creating high-?delity computer graphics objects using imperfectly-measured data from the real world. Our approach contains three novel features: an implicit integration method to achieve ef?ciency, stability, and large time-steps; a scale-dependent Laplacian operator to improve the diffusion process; and ?nally, a robust curvature ?ow operator that achieves a smoothing of the shape itself, distinct from any parameterization. Additional features of the algorithm include automatic exact volume preservation, and hard and soft constraints on the positions of the points in the mesh. We compare our method to previous operators and related algorithms, and prove that our curvature and Laplacian operators have several mathematically-desirable qualities that improve the appearance of the resulting surface. In consequence, the user can easily select the appropriate operator according to the desired type of fairing. Finally, we provide a series of examples to graphically and numerically demonstrate the quality of our results</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Khan2008</b:Tag>
<b:Title>Reconstructing non-stationary articulated objects in monocular video using silhouette information</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Khan</b:Last>
<b:First>S.M.</b:First>
</b:Person>
<b:Person>
<b:Last>Shah</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:StandardNumber> ISSN: 1063-6919 DOI: 10.1109/CVPR.2008.4587700</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>This paper presents an approach to reconstruct non-stationary, articulated objects from silhouettes obtained with a monocular video sequence. We introduce the concept of motion blurred scene occupancies, a direct analogy of motion blurred images but in a 3D object scene occupancy space resulting from the motion/deformation of the object. Our approach starts with an image based fusion step that combines color and silhouette information from multiple views. To this end we propose to use a novel construct: the temporal occupancy point (TOP), which is the estimated 3D scene location of a silhouette pixel and contains information about duration of time it is occupied. Instead of explicitly computing the TOP in 3D space we directly obtain itpsilas imaged(projected) locations in each view. This enables us to handle monocular video and arbitrary camera motion in scenarios where complete camera calibration information may not be available. The result is a set of blurred scene occupancy images in the corresponding views, where the values at each pixel correspond to the fraction of total time duration that the pixel observed an occupied scene location. We then use a motion de-blurring approach to de-blur the occupancy images. The de-blurred occupancy images correspond to a silhouettes of the mean/motion compensated object shape and are used to obtain a visual hull reconstruction of the object. We show promising results on challenging monocular datasets of deforming objects where traditional visual hull intersection approaches fail to reconstruct the object correctly.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image motion analysis, image restoration, image sequences3D object scene occupancy space, 3D scene location, camera motion, image based fusion step, monocular video sequence, motion blurred images, motion blurred scene occupancies, motion deblurring, nonstationary articulated object reconstruction, silhouette information, silhouette pixel, temporal occupancy point</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Lipman2009</b:Tag>
<b:Title>M\"{o}bius voting for surface correspondence</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Lipman</b:Last>
<b:First>Yaron</b:First>
</b:Person>
<b:Person>
<b:Last>Funkhouser</b:Last>
<b:First>Thomas</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-12</b:Pages>
<b:StandardNumber> ISBN: 978-1-60558-726-4 DOI: http://doi.acm.org/10.1145/1576246.1531378</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '09: ACM SIGGRAPH 2009 papers</b:BookTitle>
<b:ConferenceName>SIGGRAPH '09: ACM SIGGRAPH 2009 papers</b:ConferenceName>
<b:BIBTEX_Abstract>The goal of our work is to develop an efficient, automatic algorithm for discovering point correspondences between surfaces th at are approximately and/or partially isometric.

Our approach is based on three observations. First, isometries are a subset of the Mobius group, which has low-dimensionality -- six degrees of freedom for topological spheres, and three for topological discs. Second, computing the Mobius transformat ion that interpolates any three points can be computed in closed-form after a zero-error mid-edge flattening to the complex pl ane. Third, deviations from isometry can be modeled by a transportation distance between corresponding points in that plane.

Motivated by these observations, we have developed a Mobius Voting algorithm that iteratively: 1) samples a triplet of three r andom points from each of two point sets, 2) uses the Mobius transformations defined by those triplets to map both point sets into a canonical coordinate frame on the complex plane, and 3) produces ``votes'' for predicted correspondences between the mu tually closest points with magnitude representing their estimated deviation from isometry. The result of this process is a fuz zy correspondence matrix, which is converted to a permutation matrix with simple matrix operations and output as a discrete se t of point correspondences with confidence values.

The main advantage of this algorithm is that it can find intrinsic point correspondences in cases of extreme deformation. Dur ing experiments with a variety of data sets, we find that it is able to find dozens of point correspondences between different object types in different poses fully automatically.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Bottino2004</b:Tag>
<b:Title>The visual hull of smooth curved objects</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Bottino</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Laurentini</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1622-1632</b:Pages>
<b:Volume>26</b:Volume>
<b:StandardNumber> ISSN: 0162-8828 DOI: 10.1109/TPAMI.2004.130</b:StandardNumber>
<b:JournalName>Pattern Analysis and Machine Intelligence, IEEE Transactions on</b:JournalName>
<b:Issue>12</b:Issue>
<b:Month>Dec.</b:Month>
<b:BIBTEX_Abstract> The visual hull is a geometric entity that relates the shape of an object to its silhouettes or shadows. This paper develops the theory of the visual hull of generic smooth objects. We show that the visual hull can be constructed using surfaces which partition the viewpoint space of the aspect graph of the object. The surfaces are those generated by the visual events tangent crossing and triple point. An analysis based on the shape of the object at the tangency points of these surfaces allows pruning away many surfaces and patches not relevant to the construction. An algorithm for computing the visual hull is outlined.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> computer vision, geometry, graph theory, image reconstruction computer vision, generic smooth objects, geometric entity, graph theory, image reconstruction, object silhouettes, smooth curved objects, visual events, visual hull computing</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Lee2002</b:Tag>
<b:Title>Interactive control of avatars animated with human motion data</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Lee</b:Last>
<b:First>Jehee</b:First>
</b:Person>
<b:Person>
<b:Last>Chai</b:Last>
<b:First>Jinxiang</b:First>
</b:Person>
<b:Person>
<b:Last>Reitsma</b:Last>
<b:Middle>S. A.</b:Middle>
<b:First>Paul</b:First>
</b:Person>
<b:Person>
<b:Last>Hodgins</b:Last>
<b:Middle>K.</b:Middle>
<b:First>Jessica</b:First>
</b:Person>
<b:Person>
<b:Last>Pollard</b:Last>
<b:Middle>S.</b:Middle>
<b:First>Nancy</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>491-500</b:Pages>
<b:Volume>21</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/566654.566607</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>Real-time control of three-dimensional avatars is an important problem in the context of computer games and virtual environments. Avatar animation and control is difficult, however, because a large repertoire of avatar behaviors must be made available, and the user must be able to select from this set of behaviors, possibly with a low-dimensional input device. One appealing approach to obtaining a rich set of avatar behaviors is to collect an extended, unlabeled sequence of motion data appropriate to the application. In this paper, we show that such a motion database can be preprocessed for flexibility in behavior and efficient search and exploited for real-time avatar control. Flexibility is created by identifying plausible transitions between motion segments, and efficient search through the resulting graph structure is obtained through clustering. Three interface techniques are demonstrated for controlling avatar motion using this data structure: the user selects from a set of available choices, sketches a path through an environment, or acts out a desired motion in front of a video camera. We demonstrate the flexibility of the approach through four different applications and compare the avatar motion to directly recorded human motion.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Tuytelaars2004</b:Tag>
<b:Title>Synchronizing video sequences</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tuytelaars</b:Last>
<b:First>T.</b:First>
</b:Person>
<b:Person>
<b:Last>Van Gool</b:Last>
<b:First>L.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> I-762-I-768 Vol.1</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1063-6919  DOI: 10.1109/CVPR.2004.1315108</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on</b:BookTitle>
<b:ConferenceName>Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on</b:ConferenceName>
<b:Month>June-2 July</b:Month>
<b:BIBTEX_Abstract> We present a novel method for automatically synchronizing two video sequences of the same event. Unlike previously proposed methods, we do not put any restrictive constraints on the scene nor on the camera motions: our method can deal with independently moving cameras, wide baseline conditions, and general 3D scenes. It starts from five point correspondences throughout the video sequences, that are provided using wide baseline matching and tracking techniques. It is efficient, in that it can be implemented in a non-combinatorial way. The feasibility of the method is demonstrated by preliminary experimental results.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> image matching, image sequences, synchronisation, tracking, video signal processing 3D scenes, camera motions, moving cameras, restrictive constraints, tracking techniques, video sequence synchronization, wide baseline conditions, wide baseline matching</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Zhang2008</b:Tag>
<b:Title>Capturing Images with Sparse Informational Pixels using Projected 3D Tags</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>L.</b:First>
</b:Person>
<b:Person>
<b:Last>Subramaniam</b:Last>
<b:First>N.</b:First>
</b:Person>
<b:Person>
<b:Last>Lin</b:Last>
<b:First>R.</b:First>
</b:Person>
<b:Person>
<b:Last>Nayar</b:Last>
<b:Middle>K.</b:Middle>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Raskar</b:Last>
<b:First>R.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>Proceedings of IEEE Virtual Reality</b:BookTitle>
<b:ConferenceName>Proceedings of IEEE Virtual Reality</b:ConferenceName>
<b:Month>Mar</b:Month>
<b:BIBTEX_Abstract>In this paper, we propose a novel imaging system that enables the capture of photos and videos with sparse informational pixels. Our system is based on the projection and detection of 3D optical tags. We use an infrared (IR) projector to project temporally-coded (blinking) dots onto selected points in a scene. These tags are invisible to the human eye, but appear as clearly visible time-varying codes to an IR photosensor. As a proof of concept, we have built a prototype camera system (consisting of co-located visible and IR sensors) to simultaneously capture visible and IR images. When a user takes an image of a tagged scene using such a camera system, all the scene tags that are visible from the system's viewpoint are detected. In addition, tags that lie in the field of view but are occluded, and ones that lie just outside the field of view, are also automatically generated for the image. Associated with each tagged pixel is its 3D location and the identity of the object that the tag falls on. Our system can interface with conventional image recognition methods for efficient scene authoring, enabling objects in an image to be robustly identified using cheap cameras, minimal computations, and no domain knowledge. We demonstrate several applications of our system, including, photo-browsing, e-commerce, augmented reality, and objection localization.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Hasler2010</b:Tag>
<b:Title>Learning skeletons for shape and pose</b:Title>
<b:Year>2010</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hasler</b:Last>
<b:First>Nils</b:First>
</b:Person>
<b:Person>
<b:Last>Thorm\"{a}hlen</b:Last>
<b:First>Thorsten</b:First>
</b:Person>
<b:Person>
<b:Last>Rosenhahn</b:Last>
<b:First>Bodo</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>Hans-Peter</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>23-30</b:Pages>
<b:StandardNumber> ISBN: 978-1-60558-939-8 DOI: 10.1145/1730804.1730809</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>Proceedings of the 2010 ACM SIGGRAPH symposium on Interactive 3D Graphics and Games</b:BookTitle>
<b:ConferenceName>Proceedings of the 2010 ACM SIGGRAPH symposium on Interactive 3D Graphics and Games</b:ConferenceName>
<b:URL>http://doi.acm.org/10.1145/1730804.1730809</b:URL>
<b:BIBTEX_Series>I3D '10</b:BIBTEX_Series>
<b:BIBTEX_Abstract>In this paper a method for estimating a rigid skeleton, including skinning weights, skeleton connectivity, and joint positions, given a sparse set of example poses is presented. In contrast to other methods, we are able to simultaneously take examples of different subjects into account, which improves the robustness of the estimation. It is additionally possible to generate a skeleton that primarily describes variations in body shape instead of pose. The shape skeleton can then be combined with a regular pose varying skeleton. That way pose and body shape can be controlled simultaneously but separately. As this skeleton is technically still just a skinned rigid skeleton, compatibility with major modelling packages and game engines is retained. We further present an approach for synthesizing a suitable bind shape that additionally improves the accuracy of the generated model.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>linear blend skinning, skeleton estimation</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Lei2009</b:Tag>
<b:Title>Efficient Geometric, Photometric, and Temporal Calibration of an Array of Unsynchronized Video Cameras</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Lei</b:Last>
<b:First>Cheng</b:First>
</b:Person>
<b:Person>
<b:Last>Yang</b:Last>
<b:First>Yee-Hong</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>162-169</b:Pages>
<b:StandardNumber> DOI: 10.1109/CRV.2009.17</b:StandardNumber>
<b:BookTitle>Computer and Robot Vision, 2009. CRV '09. Canadian Conference on</b:BookTitle>
<b:ConferenceName>Computer and Robot Vision, 2009. CRV '09. Canadian Conference on</b:ConferenceName>
<b:Month>May</b:Month>
<b:BIBTEX_Abstract>Camera-arrays have become popular in many computer vision and computer graphics applications. Among all preprocessing steps, an efficient method to calibrate a large number of cameras is very much desired. The required calibration includes both the geometric and photometric calibration, which are the most common and also well studied for single camera. However, few existing efforts are devoted to camera arrays or to integrate both methods in a fully automatic way. Additionally, most existing camera array systems require or assume implicitly that all the cameras in the array are hardware-synchronized to simplify subsequent application-specific processing such as the calibration of all the cameras. While this constraint is useful, it greatly restricts the use of heterogeneous types of cameras and the configuration of cameras that could be used. In this paper, we propose a novel integrated and fully automatic solution for performing geometric, photometric and temporal calibration (synchronization) of an array of unsynchronized video cameras. In particular, our new method is based on the classic plane based calibration approach. By using a redesigned calibration pattern, the geometric, photometric and temporal calibrations are done in an integrated and extensible framework automatically. Extensive experimental results show that the new method is very easy to use and can achieve high accuracy in the calibrated parameters.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>calibration, cameras, computer vision, synchronisationcomputer vision, geometric calibration, photometric calibration, temporal calibration, unsynchronized video camera array</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>Misc</b:SourceType>
<b:Tag>Remondino2003</b:Tag>
<b:Title>3D Reconstruction of Human Skeleton from Single Images or Monocular Video Sequences</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Remondino</b:Last>
<b:First>Fabio</b:First>
</b:Person>
<b:Person>
<b:Last>Roditakis</b:Last>
<b:First>Andreas</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>100-107</b:Pages>
<b:JournalName>Pattern Recognition</b:JournalName>
<b:URL>http://www.springerlink.com/content/bbvmju2h5uwjfw6n</b:URL>
<b:PublicationTitle>3D Reconstruction of Human Skeleton from Single Images or Monocular Video Sequences</b:PublicationTitle>
<b:BIBTEX_Abstract>In this paper, we first review the approaches to recover 3D shape and related movements of a human and then we present an easy and reliable approach to recover a 3D model using just one image or monocular video sequence. A simplification of the perspective camera model is required, due to the absence of stereo view. The human figure is reconstructed in a skeleton form and to improve the visual quality, a pre-defined human model is also fitted to the recovered 3D data.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Xu2006</b:Tag>
<b:Title>Accurate Camera Calibration with New Minimizing Function</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Xu</b:Last>
<b:First>Qiaoyu</b:First>
</b:Person>
<b:Person>
<b:Last>Ye</b:Last>
<b:First>Dong</b:First>
</b:Person>
<b:Person>
<b:Last>Che</b:Last>
<b:First>Rensheng</b:First>
</b:Person>
<b:Person>
<b:Last>Huang</b:Last>
<b:First>Yan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>779-784</b:Pages>
<b:StandardNumber> DOI: 10.1109/ROBIO.2006.340312</b:StandardNumber>
<b:BookTitle>Robotics and Biomimetics, 2006. ROBIO '06. IEEE International Conference on</b:BookTitle>
<b:ConferenceName>Robotics and Biomimetics, 2006. ROBIO '06. IEEE International Conference on</b:ConferenceName>
<b:Month>Dec.</b:Month>
<b:BIBTEX_Abstract>Camera calibration has been studied extensively in computer vision and photogrammetry. But almost all the camera calibration techniques iterate with the general minimizing function by minimizing the discrepancy between the real position in pixels of a 2D image point and the calculated projection of the 3D object point on the image plane. Though the imaging distance errors are equal, the spatial anti-projection distance errors are not identical at different distance before the camera. As far as vision measurement system, its final object is to obtain the accurate space coordinate of the measured point. Theoretically, the space point should on the optical ray generated by its projection image point and the center of camera. To satisfy the special request of vision measurement system for camera calibration parameters, we present a valid camera calibration method based on new minimizing function using high precision virtual stereo calibration pattern, which is formed by moving an infrared light-emitting diode (IR LED) feature point with CMM on pre-defined paths. Radial distortion and decentering distortion are molded. The proposed technique consists of linear optimization parameter estimation and nonlinear refinement, which is carried out by minimizing the distance of all the 3D space points from the corresponding optical ray generated by their projections image points and the center of camera. Simulated data and real data are both shown that the calibration precision of the proposed method is better than that of the general minimizing the distance between the imaged points and the modeled projections. This method considerable reduces the distance of all the 3D space points from the corresponding optical ray generated from their projections image points and the center of camera, enhances the precision of camera calibration parameters, and improves the precision of the vision measurement system.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>calibration, cameras, computer vision, stereo image processing3D space points, camera calibration parameters, computer vision, decentering distortion, image points, infrared light-emitting diode feature point, linear optimization parameter estimation, minimizing function, nonlinear refinement, optical ray, photogrammetry, radial distortion, virtual stereo calibration pattern, vision measurement system</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Cheng2006</b:Tag>
<b:Title>Tree Skeleton Extraction from a Single Range Image</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cheng</b:Last>
<b:First>Zhanglin</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Xiaopeng</b:First>
</b:Person>
<b:Person>
<b:Last>Fourcaud</b:Last>
<b:First>Thierry</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>274-281</b:Pages>
<b:StandardNumber> ISBN: 978-0-7695-2851-9 DOI: http://dx.doi.org/10.1109/PMA.2006.28</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>PMA '06: Proceedings of the 2006 International Symposium on Plant Growth Modeling, Simulation, Visualization and Applications</b:BookTitle>
<b:ConferenceName>PMA '06: Proceedings of the 2006 International Symposium on Plant Growth Modeling, Simulation, Visualization and Applications</b:ConferenceName>
<b:BIBTEX_Abstract>Tree skeleton computation is of significance in the ge- ometric modeling of botanic trees and in the application of forestry. This paper describes an approach to extract branch skeletons from a single range image of a tree. A ba- sis of this approach is that the trunk and branches are mod- eled by generalized circular cylinders, and the tree skeleton is defined as the connected curve-axes of these cylinders. In the proposed system, the range image is partitioned into patches at first based on the discontinuity of depth and axis direction, where each patch only contains points from the same branch. Then each patch is fitted with a series of cir- cular cylinders. Finally the tree skeleton is generated by se- quentially connecting the skeleton points of fitted cylinders. This work shows that cylinder fitting can be used to han- dle the incompleteness of input data, and generate accurate skeleton points and corresponding radii. The main contri- bution of this paper is that we proposed a new definition and computation of tree skeletons and introduced an effi- cient and robust cylinder fitting method. Experiment shows the effectiveness of this approach.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Tierny2008a</b:Tag>
<b:Title>Enhancing 3D mesh topological skeletons with discrete contour constrictions</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tierny</b:Last>
<b:First>Julien</b:First>
</b:Person>
<b:Person>
<b:Last>Vandeborre</b:Last>
<b:First>Jean-Philippe</b:First>
</b:Person>
<b:Person>
<b:Last>Daoudi</b:Last>
<b:First>Mohamed</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>155-172</b:Pages>
<b:Volume>24</b:Volume>
<b:JournalName>The Visual Computer</b:JournalName>
<b:Issue>3</b:Issue>
<b:Month>#mar#</b:Month>
<b:URL>http://dx.doi.org/10.1007/s00371-007-0181-0</b:URL>
<b:BIBTEX_Abstract>Abstract&amp;nbsp;&amp;nbsp;This paper describes a unified and fully automatic algorithm for Reeb graph construction and simplification as well as constriction approximation on triangulated surfaces.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Report</b:SourceType>
<b:BIBTEX_Entry>phdthesis</b:BIBTEX_Entry>
<b:Tag>Campos2006</b:Tag>
<b:Title>3D Visual Tracking of Articulated Objects and Hands</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>de Campos</b:Last>
<b:Middle>Em?dio</b:Middle>
<b:First>Teo?lo</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Department>Department of Engineering Science - University of Oxford</b:Department>
<b:ThesisType>Ph.D. dissertation</b:ThesisType>
<b:BIBTEX_Abstract>The ability to track multiple and articulated objects is an important one, not least in the areas of autonomous and teleoperated robotics, visual surveillance and human motion analysis. This thesis is concerned with marker-free real-time detection and tracking of articulated objects, targeting human hands with the aim to study methods that can be applied to enhance the interaction between humans and 3D (real or virtual) objects.

A survey summarises methods used to approach this and related problems in the literature. It indicates that, despite the large body of research in this field over twenty or so years, the area still proves challenging. Two main approaches have been identified. The first, known as generative tracking, uses an explicit kinematical representation of linkages or constraints between object parts and tracks by minimising error of projected control points. The second, known as discriminative approach, little is specified beforehand, but training data is used in order to create a map between image observations and 3D poses. This thesis describes novel work in both areas.

In the generative area, a method for tracking of articulated objects is described. It is a new extension of a method for tracking rigid objects in which the motion constraints between parts of the object are imposed up-front within the tracking process. The inter-frame pose update is derived as the solution of a linear system. This method has been applied to track articulated objects, including hands and multiple objects with motion constraints.

An alternative method is that based on estimating the motion of each subpart independently, thereby introducing redundant degrees of freedom, and imposing constraints later in a lower dimensional subspace. This method is reviewed and a comparison between this and the aforementioned method is presented in terms of accuracy, efficiency and robustness.

In the discriminative area, an inference-based approach is adopted in which a non-parametric relation between global image measurements and 3D poses is learnt using a multivariate regressor based on Relevance Vector Machine. This relation is a continuous map that allows fast and efficient pose estimation from static images. This method can detect and estimate the 3D pose of hands from static images, so it can be applied to (re-)initialise the generative tracker.

In this thesis, the use of multiple view is adopted as a solution to reduce the ambiguities for both generative and discriminative methods. Experiments with single and multiple views are described and a novel extension of the discriminative method for multiple views is proposed and evaluated.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Book</b:SourceType>
<b:Tag>Rosenberg1997</b:Tag>
<b:Title>The Laplacian on a Riemannian manifold: an introduction to analysis on manifolds</b:Title>
<b:Year>1997</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Rosenberg</b:Last>
<b:First>Steven</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Publisher>Cambridge University Press</b:Publisher>
<b:Issue>31</b:Issue>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Yamazaki2009</b:Tag>
<b:Title>The Theory and Practice of Coplanar Shadowgram Imaging for Acquiring Visual Hulls of Intricate Objects</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Yamazaki</b:Last>
<b:First>Shuntaro</b:First>
</b:Person>
<b:Person>
<b:Last>Narasimhan</b:Last>
<b:Middle>G.</b:Middle>
<b:First>Srinivasa</b:First>
</b:Person>
<b:Person>
<b:Last>Baker</b:Last>
<b:First>Simon</b:First>
</b:Person>
<b:Person>
<b:Last>Kanade</b:Last>
<b:First>Takeo</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>259-280</b:Pages>
<b:Volume>81</b:Volume>
<b:StandardNumber> ISSN: 0920-5691 DOI: http://dx.doi.org/10.1007/s11263-008-0170-4</b:StandardNumber>
<b:Publisher>Kluwer Academic Publishers</b:Publisher>
<b:City>Hingham, MA, USA</b:City>
<b:JournalName>Int. J. Comput. Vision</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>Acquiring 3D models of intricate objects (like tree branches, bicycles and insects) is a challenging task due to severe self-occlusions, repeated thin structures, and surface discontinuities. In theory, a shape-from-silhouettes (SFS) approach can overcome these difficulties and reconstruct visual hulls that are close to the actual shapes, regardless of the complexity of the object. In practice, however, SFS is highly sensitive to errors in silhouette contours and the calibration of the imaging system, and has therefore not been used for obtaining accurate shapes with a large number of views. In this work, we present a practical approach to SFS using a novel technique called coplanar shadowgram imaging that allows us to use dozens to even hundreds of views for visual hull reconstruction. A point light source is moved around an object and the shadows (silhouettes) cast onto a single background plane are imaged. We characterize this imaging system in terms of image projection, reconstruction ambiguity, epipolar geometry, and shape and source recovery. The coplanarity of the shadowgrams yields unique geometric properties that are not possible in traditional multi-view camera-based imaging systems. These properties allow us to derive a robust and automatic algorithm to recover the visual hull of an object and the 3D positions of the light source simultaneously, regardless of the complexity of the object. We demonstrate the acquisition of several intricate shapes with severe occlusions and thin structures, using 50 to 120 views.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Flagg2009</b:Tag>
<b:Title>Human video textures</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Flagg</b:Last>
<b:First>Matthew</b:First>
</b:Person>
<b:Person>
<b:Last>Nakazawa</b:Last>
<b:First>Atsushi</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Qiushuang</b:First>
</b:Person>
<b:Person>
<b:Last>Kang</b:Last>
<b:Middle>Bing</b:Middle>
<b:First>Sing</b:First>
</b:Person>
<b:Person>
<b:Last>Ryu</b:Last>
<b:Middle>Kee</b:Middle>
<b:First>Young</b:First>
</b:Person>
<b:Person>
<b:Last>Essa</b:Last>
<b:First>Irfan</b:First>
</b:Person>
<b:Person>
<b:Last>Rehg</b:Last>
<b:Middle>M.</b:Middle>
<b:First>James</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>199-206</b:Pages>
<b:StandardNumber> ISBN: 978-1-60558-429-4 DOI: http://doi.acm.org/10.1145/1507149.1507182</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>I3D '09: Proceedings of the 2009 symposium on Interactive 3D graphics and games</b:BookTitle>
<b:ConferenceName>I3D '09: Proceedings of the 2009 symposium on Interactive 3D graphics and games</b:ConferenceName>
<b:BIBTEX_Abstract>This paper describes a data-driven approach for generating photorealistic animations of human motion. Each animation sequence follows a user-choreographed path and plays continuously by seamlessly transitioning between different segments of the captured data. To produce these animations, we capitalize on the complementary characteristics of motion capture data and video. We customize our capture system to record motion capture data that are synchronized with our video source. Candidate transition points in video clips are identified using a new similarity metric based on 3-D marker trajectories and their 2-D projections into video. Once the transitions have been identified, a video-based motion graph is constructed. We further exploit hybrid motion and video data to ensure that the transitions are seamless when generating animations. Motion capture marker projections serve as control points for segmentation of layers and nonrigid transformation of regions. This allows warping and blending to generate seamless in-between frames for animation. We show a series of choreographed animations of walks and martial arts scenes as validation of our approach.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Zhang1999</b:Tag>
<b:Title>Shape from Shading: A survey</b:Title>
<b:Year>1999</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Ruo</b:First>
</b:Person>
<b:Person>
<b:Last>sing Tsai</b:Last>
<b:First>Ping</b:First>
</b:Person>
<b:Person>
<b:Last>Cryer</b:Last>
<b:Middle>Edwin</b:Middle>
<b:First>James</b:First>
</b:Person>
<b:Person>
<b:Last>Shah</b:Last>
<b:First>Mubarak</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>690-706</b:Pages>
<b:Volume>21</b:Volume>
<b:JournalName>IEEE Transactions on Pattern Analysis and Machine Intelligence</b:JournalName>
<b:BIBTEX_Abstract>AbstractÐSince the first shape-from-shading (SFS) technique was developed by Horn in the early 1970s, many different approaches have emerged. In this paper, six well-known SFS algorithms are implemented and compared. The performance of the algorithms was analyzed on synthetic images using mean and standard deviation of depth (Z) error, mean of surface gradient (p, q) error, and CPU timing. Each algorithm works well for certain images, but performs poorly for others. In general, minimization approaches are more robust, while the other approaches are faster. The implementation of these algorithms in C and images used in this paper are available by anonymous ftp under the pub/tech_paper/survey directory at eustis.cs.ucf.edu (132.170.108.42). These are also part of the electronic version of paper. Index TermsÐ Shape from shading, analysis of algorithms, Lambertian model, survey of shape from shading algorithms. 1</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Michel2000</b:Tag>
<b:Title>Automatic extraction of time-frequency skeletons with minimal spanning trees</b:Title>
<b:Year>2000</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Michel</b:Last>
<b:First>O.</b:First>
</b:Person>
<b:Person>
<b:Last>Flandrin</b:Last>
<b:First>P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>89-92</b:Pages>
<b:StandardNumber> ISBN: 0-7803-6293-4 DOI: http://dx.doi.org/10.1109/ICASSP.2000.861871</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>ICASSP '00: Proceedings of the Acoustics, Speech, and Signal Processing, 2000. on IEEE International Conference</b:BookTitle>
<b:ConferenceName>ICASSP '00: Proceedings of the Acoustics, Speech, and Signal Processing, 2000. on IEEE International Conference</b:ConferenceName>
<b:BIBTEX_Abstract>Theoretical results have been established in non-parametric entropy estimation, based on asymptotic properties of minimal spanning trees (MST). A new application is proposed for the automatic extraction of time-frequency skeletons in the case of multicomponent chirp-like signals. The proposed method makes use of local maxima of a time-frequency distribution (considered as realizations of a 2D or 3D process), and exploits the efficiency of MSTs for density discrimination and clustering.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Natali2011</b:Tag>
<b:Title>Graph-based representations of point clouds</b:Title>
<b:Year>2011</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Natali</b:Last>
<b:First>Mattia</b:First>
</b:Person>
<b:Person>
<b:Last>Biasotti</b:Last>
<b:First>Silvia</b:First>
</b:Person>
<b:Person>
<b:Last>Patan\`{e}</b:Last>
<b:First>Giuseppe</b:First>
</b:Person>
<b:Person>
<b:Last>Falcidieno</b:Last>
<b:First>Bianca</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>151-164</b:Pages>
<b:Volume>73</b:Volume>
<b:StandardNumber> ISSN: 1524-0703 DOI: http://dx.doi.org/10.1016/j.gmod.2011.03.002</b:StandardNumber>
<b:Publisher>Academic Press Professional, Inc.</b:Publisher>
<b:City>San Diego, CA, USA</b:City>
<b:JournalName>Graph. Models</b:JournalName>
<b:Month>September</b:Month>
<b:URL>http://dx.doi.org/10.1016/j.gmod.2011.03.002</b:URL>
<b:BIBTEX_Abstract>This paper introduces a skeletal representation, called Point Cloud Graph, that generalizes the definition of the Reeb graph to arbitrary point clouds sampled from m-dimensional manifolds embedded in the d-dimensional space. The proposed algorithm is easy to implement and the graph representation yields to an effective abstraction of the data. Finally, we present experimental results on point-sampled surfaces and volumetric data that show the robustness of the Point Cloud Graph to non-uniform point distributions and its usefulness for shape comparison.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Graph-based representations, Point clouds, Shape abstraction, Shape comparison</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>conference</b:BIBTEX_Entry>
<b:Tag>Cao2010</b:Tag>
<b:Title>Point Cloud Skeletons via Laplacian-Based Contraction</b:Title>
<b:Year>2010</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cao</b:Last>
<b:First>Junjie</b:First>
</b:Person>
<b:Person>
<b:Last>Tagliasacchi</b:Last>
<b:First>Andrea</b:First>
</b:Person>
<b:Person>
<b:Last>Olson</b:Last>
<b:First>Matt</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Hao</b:First>
</b:Person>
<b:Person>
<b:Last>Su</b:Last>
<b:First>Zhixun</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>187{\textendash}197</b:Pages>
<b:BookTitle>Proc. of IEEE Conf. on Shape Modeling and Applications</b:BookTitle>
<b:ConferenceName>Proc. of IEEE Conf. on Shape Modeling and Applications</b:ConferenceName>
<b:Month>June 2010</b:Month>
<b:BIBTEX_Abstract>We present an algorithm for curve skeleton extraction via Laplacian-based contraction. Our algorithm can be applied to surfaces with boundaries, polygon soups, and point clouds. We develop a contraction operation that is designed to work on generalized discrete geometry data, particularly point clouds, via local Delaunay triangulation and topological thinning. Our approach is robust to noise and can handle moderate amounts of missing data, allowing skeleton-based manipulation of point clouds without explicit surface reconstruction. By avoiding explicit reconstruction, we are able to perform skeleton-driven topology repair of acquired point clouds in the presence of large amounts of missing data. In such cases, automatic surface reconstruction schemes tend to produce incorrect surface topology. We show that the curve skeletons we extract provide an intuitive and easy-to-manipulate structure for effective topology modification, leading to more faithful surface reconstruction.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Attali2007</b:Tag>
<b:Title>Stability and Computation of the Medial Axis --- a State-of-the-Art Report</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Attali</b:Last>
<b:First>D.</b:First>
</b:Person>
<b:Person>
<b:Last>Boissonnat</b:Last>
<b:First>J.-D.</b:First>
</b:Person>
<b:Person>
<b:Last>Edelsbrunner</b:Last>
<b:First>H.</b:First>
</b:Person>
</b:NameList>
</b:Author>
<b:Editor>
<b:NameList>
<b:Person>
<b:Last>Springer-Verlag</b:Last>
</b:Person>
</b:NameList>
</b:Editor>
</b:Author>
<b:Pages>-</b:Pages>
<b:Volume>1</b:Volume>
<b:JournalName>Mathematical Foundations of Scientific Visualization, Computer Graphics, and Massive Data Exploration</b:JournalName>
<b:BIBTEX_Abstract>The medial axis of a geometric shape captures its connectivity. In spite of its inherent instability, it has found applications in a number of areas that deal with shapes. In this survey paper, we focus on results that shed light on this in-
stability and use the new insights to generate simplied and stable versions of the medial axis</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Kampel2002</b:Tag>
<b:Title>Octree-based fusion of shape from silhouette and shape from structured light</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Kampel</b:Last>
<b:First>M.</b:First>
</b:Person>
<b:Person>
<b:Last>Tosovic</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Sablatnig</b:Last>
<b:First>R.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>754-757</b:Pages>
<b:StandardNumber> DOI: 10.1109/TDPVT.2002.1024154</b:StandardNumber>
<b:BookTitle>3D Data Processing Visualization and Transmission, 2002. Proceedings. First International Symposium on</b:BookTitle>
<b:JournalName>3D Data Processing Visualization and Transmission, 2002. Proceedings. First International Symposium on</b:JournalName>
<b:ConferenceName>3D Data Processing Visualization and Transmission, 2002. Proceedings. First International Symposium on</b:ConferenceName>
<b:BIBTEX_Abstract> An algorithm for the automatic construction of a 3d model of archaeological vessels using two different 3d algorithms is presented. In archeology the determination of the exact volume of arbitrary vessels is of importance since this provides information about the manufacturer and the usage of the vessel. To acquire the 3d shape of objects with handles is complicated, since occlusions of the object's surface are introduced by the handle and can only be resolved by taking multiple views. Therefore, the 3d reconstruction is based on a sequence of images of the object taken from different viewpoints with different algorithms; shape from silhouette and shape from structured light. The output of both algorithms are then used to construct a single 3d model. Results of the algorithm developed are presented for both synthetic and real input images.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> archaeology, octrees, sensor fusion, virtual reality arbitrary vessels, archaeological vessels, automatic construction, images sequences, octree-based fusion, real input images, shape from silhouette, shape from structured light, synthetic images</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Liu2006</b:Tag>
<b:Title>A Novel Volumetric Shape from Silhouette Algorithm Based on a Centripetal Pentahedron Model</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Liu</b:Last>
<b:First>Xin</b:First>
</b:Person>
<b:Person>
<b:Last>Yao</b:Last>
<b:First>Hongxun</b:First>
</b:Person>
<b:Person>
<b:Last>Yao</b:Last>
<b:First>Guilin</b:First>
</b:Person>
<b:Person>
<b:Last>Gao</b:Last>
<b:First>Wen</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>9-9</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1051-4651 DOI: 10.1109/ICPR.2006.146</b:StandardNumber>
<b:BookTitle>Pattern Recognition</b:BookTitle>
<b:JournalName>Pattern Recognition, 2006. ICPR 2006. 18th International Conference on</b:JournalName>
<b:ConferenceName>Pattern Recognition</b:ConferenceName>
<b:Month>0-0 </b:Month>
<b:BIBTEX_Abstract>In this paper we present a novel volumetric shape from silhouette algorithm based on a centripetal pentahedron model. The algorithm first partitions the space with a set of infinite triangular pyramids derived from a geodesic sphere. Then the pyramids are cut by silhouettes into a set of pentahedrons, which together constitute the centripetal pentahedron model of the visual hull. This process is accelerated by pre-computed polar silhouette graphs (PSGs) and reduced PSGs. Finally a mesh surface model is extracted by marching pentahedrons. Our algorithm has the advantages of robustness, speediness and preciseness</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational geometry, feature extraction, graph theory, image resolution, stereo image processingcentripetal pentahedron model, geodesic sphere, infinite triangular pyramids, marching pentahedrons, mesh surface model extraction, polar silhouette graphs, silhouette algorithm, space partitioning, visual hull, volumetric shape</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Hassouna2005</b:Tag>
<b:Title>Robust skeletonization using the fast marching method</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hassouna</b:Last>
<b:First>M.S.</b:First>
</b:Person>
<b:Person>
<b:Last>Farag</b:Last>
<b:First>A.A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> I-437-40</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> DOI: 10.1109/ICIP.2005.1529781</b:StandardNumber>
<b:BookTitle>Image Processing, 2005. ICIP 2005. IEEE International Conference on</b:BookTitle>
<b:ConferenceName>Image Processing, 2005. ICIP 2005. IEEE International Conference on</b:ConferenceName>
<b:Month>Sept.</b:Month>
<b:BIBTEX_Abstract> We have recently developed a level set based-framework for computing medial curves or curve skeletons CS for arbitrary 2D shapes as well as tubular and articulated 3D objects. The proposed framework is robust, fully automatic, computationally efficient, and produces curve skeletons that are connected, centered, thin, and less sensitive to boundary noise. In this paper, we introduce two improvements to the framework in order to enhance its performance in terms of stability and topology preserving.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> signal processing curve skeletons, fast marching method, skeletonization</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Vlasic2008</b:Tag>
<b:Title>Articulated mesh animation from multi-view silhouettes</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Vlasic</b:Last>
<b:First>Daniel</b:First>
</b:Person>
<b:Person>
<b:Last>Baran</b:Last>
<b:First>Ilya</b:First>
</b:Person>
<b:Person>
<b:Last>Matusik</b:Last>
<b:First>Wojciech</b:First>
</b:Person>
<b:Person>
<b:Last>Popovi\'{c}</b:Last>
<b:First>Jovan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-9</b:Pages>
<b:Volume>27</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/1360612.1360696</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>Details in mesh animations are difficult to generate but they have great impact on visual quality. In this work, we demonstrate a practical software system for capturing such details from multi-view video recordings. Given a stream of synchronized video images that record a human performance from multiple viewpoints and an articulated template of the performer, our system captures the motion of both the skeleton and the shape. The output mesh animation is enhanced with the details observed in the image silhouettes. For example, a performance in casual loose-fitting clothes will generate mesh animations with flowing garment motions. We accomplish this with a fast pose tracking method followed by nonrigid deformation of the template to fit the silhouettes. The entire process takes less than sixteen seconds per frame and requires no markers or texture cues. Captured meshes are in full correspondence making them readily usable for editing operations including texturing, deformation transfer, and deformation model learning.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Gagvani1999</b:Tag>
<b:Title>Parameter-Controlled Volume Thinning</b:Title>
<b:Year>1999</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Gagvani</b:Last>
<b:First>Nikhil</b:First>
</b:Person>
<b:Person>
<b:Last>Silver</b:Last>
<b:First>Deborah</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>149-164</b:Pages>
<b:Volume>61</b:Volume>
<b:StandardNumber> ISSN: 1077-3169 DOI: DOI: 10.1006/gmip.1999.0495</b:StandardNumber>
<b:JournalName>Graphical Models and Image Processing</b:JournalName>
<b:Issue>3</b:Issue>
<b:URL>http://www.sciencedirect.com/science/article/B6WG4-45GMD54-B/2/7dd0819187eafc80d84ce0cc9d880a28</b:URL>
<b:BIBTEX_Abstract>The availability of large 3D datasets has made volume thinning essential for compact representation of shapes. The density of the skeletal structure resulting from the thinning process depends on the application. Current thinning techniques do not allow control over the density and can therefore address only specific applications. In this paper, we describe an algorithm which uses a thinness parameter to control the thinning process and thus the density of the skeletal structure. We present applications from CFD and medical visualization and show how the skeletal structure can be used in these domains. We also illustrate a technique for constructing a centerline for surgical navigation.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Report</b:SourceType>
<b:BIBTEX_Entry>phdthesis</b:BIBTEX_Entry>
<b:Tag>Ranjan2012</b:Tag>
<b:Title>Discrete Laplace Operator: Theory and Applications</b:Title>
<b:Year>2012</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Ranjan</b:Last>
<b:First>Pawas</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:StandardNumber> ISBN: 978-1-267-68282-6</b:StandardNumber>
<b:Publisher>Ohio State University</b:Publisher>
<b:City>Columbus, OH, USA</b:City>
<b:Department>The Ohio State University</b:Department>
<b:ThesisType>Ph.D. dissertation</b:ThesisType>
<b:BIBTEX_Abstract>The eigen-structures (eigenvalues and eigenfunctions) of the Laplace-Beltrami operator have been widely used in a broad range of application fields that include mesh smoothing, compression, editing, shape segmentation, matching, and parametrization, among others. While the Laplace operator is defined (mathematically) for a smooth domain, the underlying manifold is often approximated by a discrete mesh. Hence, the spectral structure of the manifold Laplacian is estimated from some discrete Laplace operator constructed from this mesh.
Recently, several different discretizations have been proposed, each with its own advantages and limitations. Although the eigen-structures have been found to be useful in graphics, not much is known about their behavior when a surface is deformed or modified. The objective of my thesis is two-fold. One is to study, and to develop theory for, changes in the eigen-structures of the discrete Laplace operator as the underlying mesh is changed. The other is to explore applications for the spectral theory of shape perturbations in areas like shape matching and deformation.

In particular, our work shows that the discrete Laplace is stable against noise and sampling. We also show that both the discrete and continuous Laplace change continuously as the underlying mesh or surface is deformed continuously, without introducing changes to the topology. Not only do these results help in providing a better theoretical understanding of the discrete Laplace operator, they also give us a solid base for developing applications. Indeed, we present two such applications: one that deals with shape matching and another that performs fast mesh deformations.

Specifically, combining our theoretical results with concepts from persistent homology, we create a concise global shape signature that can be used for matching different shapes. Given our results regarding similarity of eigen-structures of similar shapes, our matching algorithm allows us to match even partially scanned or incomplete models, regardless of their pose or orientation. We also present a framework that uses eigenvectors to create an implicit skeleton of a shape and use it to deform the shape, producing smooth and natural looking deformations. By using the eigenvectors, we are able to reduce the problem size from the number of mesh vertices (hundreds to millions) to the number of eigenvectors used (tens to hundreds).</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Zhang2004</b:Tag>
<b:Title>Spacetime Faces: High-Resolution Capture for Modeling and Animation</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Li</b:First>
</b:Person>
<b:Person>
<b:Last>Snavely</b:Last>
<b:First>Noah</b:First>
</b:Person>
<b:Person>
<b:Last>Curless</b:Last>
<b:First>Brian</b:First>
</b:Person>
<b:Person>
<b:Last>Seitz</b:Last>
<b:Middle>M.</b:Middle>
<b:First>Steven</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>548-558</b:Pages>
<b:BookTitle>ACM Annual Conference on Computer Graphics</b:BookTitle>
<b:ConferenceName>ACM Annual Conference on Computer Graphics</b:ConferenceName>
<b:Month>August</b:Month>
<b:BIBTEX_Abstract>We present an end-to-end system that goes from video sequences to high resolution, editable, dynamically controllable face models. The capture system employs synchronized video cameras and structured light projectors to record videos of a moving face from multiple viewpoints. A novel spacetime stereo algorithm is introduced to compute depth maps accurately and overcome over-fitting deficiencies in prior work. A new template fitting and tracking procedure fills in missing data and yields point correspondence across the entire sequence without using markers. We demonstrate a data-driven, interactive method for inverse kinematics that draws on the large set of fitted templates and allows for posing new expressions by dragging surface points directly. Finally, we describe new tools that model the dynamics in the input sequence to enable new animations, created via key-framing or texture-synthesis techniques.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Gong2009</b:Tag>
<b:Title>3D Mesh Skeleton Extraction Based on Feature Points</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Gong</b:Last>
<b:First>Faming</b:First>
</b:Person>
<b:Person>
<b:Last>Kang</b:Last>
<b:First>Cui</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>326-329</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> DOI: 10.1109/ICCET.2009.71</b:StandardNumber>
<b:BookTitle>Computer Engineering and Technology</b:BookTitle>
<b:JournalName>Computer Engineering and Technology, 2009. ICCET '08. International Conference on</b:JournalName>
<b:ConferenceName>Computer Engineering and Technology</b:ConferenceName>
<b:Month>Jan.</b:Month>
<b:BIBTEX_Abstract>A novel efficient skeleton extraction algorithm is proposed, which is based on feature points extraction and Reeb graph theories. Because of the topological facility of feature points, a model can be divided into several branches according to them. One feature point can present one branch. So we just extract the other point of the branch - that could be skeleton point, connect these points with their corresponding feature points, then we can get all branch skeletons. Finally, connecting branch skeletons through connecting skeleton points according the topological relationship of each skeleton point preserving, then 3D modelpsilas skeleton can be extracted.Without pre-processing stages and without input parameters, this algorithm can automatically extract the skeleton of 3D models. Theoretical analyses and experimental results show that our method has a lower computing complexity, and meets the requirement of extracting nice-looking and affine-invariant skeletons efficiently.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational complexity, feature extraction3D mesh skeleton extraction, Reeb graph theories, affine-invariant skeletons, computing complexity, feature points extraction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Katz2003</b:Tag>
<b:Title>Hierarchical mesh decomposition using fuzzy clustering and cuts</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Katz</b:Last>
<b:First>Sagi</b:First>
</b:Person>
<b:Person>
<b:Last>Tal</b:Last>
<b:First>Ayellet</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>954-961</b:Pages>
<b:StandardNumber> ISBN: 1-58113-709-5 DOI: http://doi.acm.org/10.1145/1201775.882369</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '03: ACM SIGGRAPH 2003 Papers</b:BookTitle>
<b:ConferenceName>SIGGRAPH '03: ACM SIGGRAPH 2003 Papers</b:ConferenceName>
<b:BIBTEX_Abstract>Cutting up a complex object into simpler sub-objects is a fundamental problem in various disciplines. In image processing, images are segmented while in computational geometry, solid polyhedra are decomposed. In recent years, in computer graphics, polygonal meshes are decomposed into sub-meshes. In this paper we propose a novel hierarchical mesh decomposition algorithm. Our algorithm computes a decomposition into the meaningful components of a given mesh, which generally refers to segmentation at regions of deep concavities. The algorithm also avoids over-segmentation and jaggy boundaries between the components. Finally, we demonstrate the utility of the algorithm in control-skeleton extraction.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Zou2009</b:Tag>
<b:Title>Automatic reconstruction of 3D human motion pose from uncalibrated monocular video sequences based on markerless human motion tracking</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Zou</b:Last>
<b:First>Beiji</b:First>
</b:Person>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>Shu</b:First>
</b:Person>
<b:Person>
<b:Last>Shi</b:Last>
<b:First>Cao</b:First>
</b:Person>
<b:Person>
<b:Last>Providence</b:Last>
<b:Middle>Marie</b:Middle>
<b:First>Umugwaneza</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> - </b:Pages>
<b:Volume>In Press, Corrected Proof</b:Volume>
<b:StandardNumber> ISSN: 0031-3203 DOI: DOI: 10.1016/j.patcog.2008.12.024</b:StandardNumber>
<b:JournalName>Pattern Recognition</b:JournalName>
<b:URL>http://www.sciencedirect.com/science/article/B6V14-4VB01R5-2/2/efb5a08b5ccd91dc3ddc2f8c7b367a50</b:URL>
<b:BIBTEX_Abstract>We present a method to reconstruct human motion pose from uncalibrated monocular video sequences based on the morphing appearance model matching. The human pose estimation is made by integrated human joint tracking with pose reconstruction in depth-first order. Firstly, the Euler angles of joint are estimated by inverse kinematics based on human skeleton constrain. Then, the coordinates of pixels in the body segments in the scene are determined by forward kinematics, by projecting these pixels in the scene onto the image plane under the assumption of perspective projection to obtain the region of morphing appearance model in the image. Finally, the human motion pose can be reconstructed by histogram matching. The experimental results show that this method can obtain favorable reconstruction results on a number of complex human motion sequences.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>3D human motion reconstruction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Sinha2004</b:Tag>
<b:Title>Synchronization and calibration of camera networks from silhouettes</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Sinha</b:Last>
<b:First>S.N.</b:First>
</b:Person>
<b:Person>
<b:Last>Pollefeys</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> 116-119 Vol.1</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1051-4651  DOI: 10.1109/ICPR.2004.1334021</b:StandardNumber>
<b:BookTitle>Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on</b:BookTitle>
<b:ConferenceName>Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on</b:ConferenceName>
<b:Month>Aug.</b:Month>
<b:BIBTEX_Abstract> We propose an automatic approach to synchronize a network of uncalibrated and unsynchronized video cameras, and recover the complete calibration of all these cameras. In this paper, we extend recent work on computing the epipolar geometry from dynamic silhouettes, to deal with unsynchronized sequences and find the temporal offset between them. This is used to compute the fundamental matrices and the temporal offsets between many view-pairs in the network. Knowing the time-shifts between enough view-pairs allows us to robustly synchronize the whole network. The calibration of all the cameras is recovered from these fundamental matrices. The dynamic shape of the object can then be recovered using a visual-hull algorithm. Our method is especially useful for multi-camera shape-from-silhouette systems, as visual hulls can now be reconstructed without the need for a specific calibration session.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> calibration, image reconstruction, image sequences, matrix algebra, synchronisation, video cameras, video signal processing camera network calibration, camera network synchronization, dynamic silhouettes, epipolar geometry, fundamental matrices, image reconstruction, multicamera shape, silhouette systems, temporal offsets, uncalibrated video cameras, unsynchronized sequences, unsynchronized video cameras, visual hull algorithm</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>Book</b:SourceType>
<b:Tag>Spivak2-1999</b:Tag>
<b:Title>A Comprehensive Introduction to Differential Geometry</b:Title>
<b:Year>1999</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Spivak</b:Last>
<b:First>Michael</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Volume>2</b:Volume>
<b:Edition>3rd</b:Edition>
<b:StandardNumber> ISBN: 0914098853</b:StandardNumber>
<b:Publisher>{Publish or Perish, Inc}</b:Publisher>
<b:Month>January</b:Month>
<b:URL>http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&amp;path=ASIN/0914098853</b:URL>
<b:BIBTEX_KeyWords>differential-geometry</b:BIBTEX_KeyWords>
<b:BIBTEX_HowPublished>Hardcover</b:BIBTEX_HowPublished>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Ma2009</b:Tag>
<b:Title>Fingerprint Skeleton Extraction Based on Improved Principal Curve</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Ma</b:Last>
<b:First>Chi</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Hongyun</b:First>
</b:Person>
<b:Person>
<b:Last>Miao</b:Last>
<b:First>Duoqian</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>XueDong</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>605-610</b:Pages>
<b:StandardNumber> DOI: 10.1109/ICIS.2009.53</b:StandardNumber>
<b:BookTitle>Computer and Information Science, 2009. ICIS 2009. Eighth IEEE/ACIS International Conference on</b:BookTitle>
<b:ConferenceName>Computer and Information Science, 2009. ICIS 2009. Eighth IEEE/ACIS International Conference on</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>In the fingerprint recognition system, skeleton extraction for low quality fingerprint images is an emphasis and difficulty task. Traditional methods are, however, susceptible to noise. In view of this, we propose a principal curves-based approach to alleviate this difficulty. In the paper, according to some characteristics of the fingerprint dataset, we improve the original principal graph algorithm proposed by Kegl to obtain principal curves, which can be served as the skeleton of a fingerprint. Experimental results show that our improved principal curve algorithm is better in efficiency and quality than the original algorithm. Our algorithm contains more information quantity and is proved to be more accurate and anti-noisy than thinning algorithm.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>feature extraction, fingerprint identification, graph theory, image thinningantinoisy image, fingerprint image recognition system, fingerprint skeleton extraction, image thinning algorithm, original principal graph algorithm, principal curve-based approach</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Lin2008</b:Tag>
<b:Title>3D reconstruction by combining shape from silhouette with stereo</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Lin</b:Last>
<b:First>Huei-Yung</b:First>
</b:Person>
<b:Person>
<b:Last>Wu</b:Last>
<b:First>Jing-Ren</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-4</b:Pages>
<b:StandardNumber> ISSN: 1051-4651 DOI: 10.1109/ICPR.2008.4761016</b:StandardNumber>
<b:BookTitle>Pattern Recognition</b:BookTitle>
<b:JournalName>Pattern Recognition, 2008. ICPR 2008. 19th International Conference on</b:JournalName>
<b:ConferenceName>Pattern Recognition</b:ConferenceName>
<b:Month>Dec.</b:Month>
<b:BIBTEX_Abstract>In this paper we propose a 3D reconstruction algorithm by combining shape from silhouette with stereo. Visual hull of the object is first derived from multi-view silhouette images. Pairwise stereo matching for shape refinement is then accomplished using the best viewable images. Based on the reduced correspondence searching range constrained by contact points and bounding edges, significant improvement of visual hull is possible even if the number of cameras is limited. Experimental results are presented for both synthetic data and real scene images.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image matching, image reconstruction, stereo image processingmultiview silhouette images, object visual hull, pairwise stereo matching, reconstruction algorithm, shape refinement</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Hemayed2003</b:Tag>
<b:Title>A survey of camera self-calibration</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hemayed</b:Last>
<b:First>E.E.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>351-357</b:Pages>
<b:StandardNumber> ISSN:   DOI: 10.1109/AVSS.2003.1217942</b:StandardNumber>
<b:BookTitle>Proceedings. IEEE Conference on Advanced Video and Signal Based Surveillance, 2003.</b:BookTitle>
<b:ConferenceName>Proceedings. IEEE Conference on Advanced Video and Signal Based Surveillance, 2003.</b:ConferenceName>
<b:Month>July</b:Month>
<b:BIBTEX_Abstract>The paper surveys the developments of the last 10 years in the area of camera self-calibration. Self-calibration is an attempt to calibrate camera by finding intrinsic parameters that are consistent with the underlying projective geometry of a sequence of images. In order to solve this problem, the camera intrinsic constraints have been used separately and in conjunction with camera motion constraints or scene constraints. Most self-calibration algorithms are concerned with unknown but constant intrinsic camera parameters. Recently, camera self-calibration in the case of varying intrinsic camera parameters was also studied. We present the basic theories behind the different self-calibration techniques and discuss the ideas behind most of the self-calibration algorithms.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> calibration, cameras, computer vision, geometrical optics, image motion analysis, image sequences camera intrinsic constraints, camera motion constraints, camera parameters, camera self-calibration, computer vision, image sequence, intrinsic parameters, projective geometry, scene constraints</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Thormahlen2008</b:Tag>
<b:Title>3D-modeling by ortho-image generation from image sequences</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Thorm\"{a}hlen</b:Last>
<b:First>Thorsten</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>Hans-Peter</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-5</b:Pages>
<b:StandardNumber> DOI: http://doi.acm.org/10.1145/1399504.1360685</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '08: ACM SIGGRAPH 2008 papers</b:BookTitle>
<b:ConferenceName>SIGGRAPH '08: ACM SIGGRAPH 2008 papers</b:ConferenceName>
<b:BIBTEX_Abstract>This paper introduces an approach to performance animation that employs video cameras and a small set of retro-reflective markers to create a low-cost, easy-to-use system that might someday be practical for home use. The low-dimensional control signals from the user's performance are supplemented by a database of pre-recorded human motion. At run time, the system automatically learns a series of local models from a set of motion capture examples that are a close match to the marker locations captured by the cameras. These local models are then used to reconstruct the motion of the user as a full-body animation. We demonstrate the power of this approach with real-time control of six different behaviors using two video cameras and a small set of retro-reflective markers. We compare the resulting animation to animation from commercial motion capture equipment with a full set of markers.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Misc</b:SourceType>
<b:Tag>qt</b:Tag>
<b:Title>QT</b:Title>
<b:Comments>Cross-platform application and UI framework. http://qt-project.org/</b:Comments>
<b:Author/>
<b:PublicationTitle>QT</b:PublicationTitle>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Zhou2008</b:Tag>
<b:Title>Reconstruction of the Visual Hull with Modified Ray-tracing and Fast Slice-based Surface Extraction</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Zhou</b:Last>
<b:First>Jie</b:First>
</b:Person>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>Hai</b:First>
</b:Person>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>Yue</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>907-912</b:Pages>
<b:StandardNumber> DOI: 10.1109/ICYCS.2008.422</b:StandardNumber>
<b:BookTitle>Young Computer Scientists</b:BookTitle>
<b:JournalName>Young Computer Scientists, 2008. ICYCS 2008. The 9th International Conference for</b:JournalName>
<b:ConferenceName>Young Computer Scientists</b:ConferenceName>
<b:Month>Nov.</b:Month>
<b:BIBTEX_Abstract>This paper presents a novel method for constructing a surface mesh from silhouettes estimated from image sequences. We implement a modified ray-tracing algorithm with an epipolar-line examination to obtain the surface vertices and investigate surface topology information by a slice-based surface extraction algorithm. In the ray tracing stage, a 2D-vector-based sandwich test is designed to predict the results of intersection, while culling only needs sequence calculations. Both theoretical analysis and experiment results show that our method is significantly faster than the original ray-tracing algorithm without losing accuracy.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational geometry, feature extraction, image reconstruction, image sequences, mesh generation, ray tracing, surface fitting2D vector-based sandwich test, epipolar-line examination, image sequence, ray tracing, slice-based surface extraction, surface mesh construction, surface topology information, visual hull reconstruction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Hoppe1996</b:Tag>
<b:Title>Progressive meshes</b:Title>
<b:Year>1996</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hoppe</b:Last>
<b:First>Hugues</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>99-108</b:Pages>
<b:StandardNumber> ISBN: 0-89791-746-4 DOI: http://doi.acm.org/10.1145/237170.237216</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '96: Proceedings of the 23rd annual conference on Computer graphics and interactive techniques</b:BookTitle>
<b:ConferenceName>SIGGRAPH '96: Proceedings of the 23rd annual conference on Computer graphics and interactive techniques</b:ConferenceName>
<b:BIBTEX_Abstract>Highly detailed geometric models are rapidly becoming commonplace in computer graphics. These models, often represented as complex triangle meshes, challenge rendering performance, transmission bandwidth, and storage capacities. This paper introduces the progressive mesh (PM) representation, a new scheme for storing and transmitting arbitrary triangle meshes. This efficient, lossless, continuous-resolution representation addresses several practical problems in graphics: smooth geomorphing of level-of-detail approximations, progressive transmission, mesh compression, and selective refinement.
In addition, we present a new mesh simplification procedure for constructing a PM representation from an arbitrary mesh. The goal of this optimization procedure is to preserve not just the geometry of the original mesh, but more importantly its overall appearance as defined by its discrete and scalar appearance attributes such as material identifiers, color values, normals, and texture coordinates. We demonstrate construction of the PM representation and its applications using several practical models.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Pantuwong2010</b:Tag>
<b:Title>Skeleton-growing: a vector-field-based 3D curve-skeleton extraction algorithm</b:Title>
<b:Year>2010</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Pantuwong</b:Last>
<b:First>Natapon</b:First>
</b:Person>
<b:Person>
<b:Last>Sugimoto</b:Last>
<b:First>Masanori</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>6:1--6:2</b:Pages>
<b:StandardNumber> ISBN: 978-1-4503-0523-5 DOI: http://doi.acm.org/10.1145/1899950.1899956</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>ACM SIGGRAPH ASIA 2010 Sketches</b:BookTitle>
<b:ConferenceName>ACM SIGGRAPH ASIA 2010 Sketches</b:ConferenceName>
<b:URL>http://doi.acm.org/10.1145/1899950.1899956</b:URL>
<b:BIBTEX_Series>SA '10</b:BIBTEX_Series>
<b:BIBTEX_Abstract>The vector-field-based method is one of the 3D curve-skeleton extraction algorithms. Typically, critical points in the vector field inside 3D objects are connected to form the curve-skeleton. However, critical points usually do not distribute to all important parts of the 3D object. Therefore, other features are used to produce a reliable result. Although this strategy can deliver a curve-skeleton that captures all of the important parts, the curve-skeleton usually comes with unnecessary segments. This paper proposes the skeleton-growing algorithm that automatically produces the curve-skeleton with small amounts of such segments. It searches for a set of high-curvature boundary voxels as starting points to find a set of suitable seed points that will be used to grow the curve-skeleton. We propose an unnecessary segment removal algorithm that can reduce the skeleton-noise density. A direction-selection algorithm is developed to avoid searching in irrelevant directions. The proposed method can produce a single reliable result curve-skeleton that could be applied in many different applications, including matching, animation, and visualization.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>curvature, curve-skeleton, skeleton-growing, vector-field</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Shin2006</b:Tag>
<b:Title>Triangular Mesh Generation of Octrees of Non-Convex 3D Objects</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Shin</b:Last>
<b:First>Dongjoe</b:First>
</b:Person>
<b:Person>
<b:Last>Tjahjadi</b:Last>
<b:First>Tardi</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>950-953</b:Pages>
<b:Volume>3</b:Volume>
<b:StandardNumber> ISSN: 1051-4651 DOI: 10.1109/ICPR.2006.1137</b:StandardNumber>
<b:BookTitle>Pattern Recognition</b:BookTitle>
<b:JournalName>Pattern Recognition, 2006. ICPR 2006. 18th International Conference on</b:JournalName>
<b:ConferenceName>Pattern Recognition</b:ConferenceName>
<b:Month>0-0 </b:Month>
<b:BIBTEX_Abstract>A general surface-generating algorithm, the marching cube, produces triangular meshes from octants where the vertices of octants are clearly classified into either inside or outside the object. However, the algorithm is ambiguous for octrees corresponding to non-convex objects generated using a shape from silhouette technique. This paper presents a methodology which involves Delaunay triangulation to generate surface meshes for such octrees. Since the general 3D Delaunay triangulation creates 3D convex hull which consists of tetrahedron meshes, we propose a method which applies the Delaunay algorithm locally in order to deal with non-convex objects. The proposed method first slices an octree and detects the clusters in each slice. All clusters between adjacent slices are linked based on a 3D probability density cube. The Delaunay algorithm is then applied to locally-linked clusters. Finally the accumulation of triangular meshes forms a final non-convex surface mesh</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational geometry, mesh generation, object recognition, octrees, pattern clustering, probabilityDelaunay triangulation, marching cube, nonconvex 3D objects, octrees, probability density cube, silhouette technique, surface-generating algorithm, tetrahedron meshes, triangular mesh generation</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Gavrila1999</b:Tag>
<b:Title>The visual analysis of human movement: a survey</b:Title>
<b:Year>1999</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Gavrila</b:Last>
<b:Middle>M.</b:Middle>
<b:First>D.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>82-98</b:Pages>
<b:Volume>73</b:Volume>
<b:StandardNumber> ISSN: 1077-3142 DOI: http://dx.doi.org/10.1006/cviu.1998.0716</b:StandardNumber>
<b:Publisher>Elsevier Science Inc.</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>Comput. Vis. Image Underst.</b:JournalName>
<b:Issue>1</b:Issue>
<b:BIBTEX_Abstract>The ability to recognize humans and their activities by vision is key for a machine to interact intelligently and effortlessly with a human-inhabited environment. Because of many potentially important applications, “looking at people” is currently one of the most active application domains in computer vision. This survey identifies a number of promising applications and provides an overview of recent developments in this domain. The scope of this survey is limited to work on whole-body or hand motion; it does not include work on human faces. The emphasis is on discussing the various methodologies; they are grouped in 2-D approaches with or without explicit shape models and 3-D approaches. Where appropriate, systems are reviewed. We conclude with some thoughts about future directions.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Brito2008</b:Tag>
<b:Title>Synchronizing Video Cameras with Non-overlapping Fields of View</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Brito</b:Last>
<b:First>D.N.</b:First>
</b:Person>
<b:Person>
<b:Last>Padua</b:Last>
<b:First>F.L.C.</b:First>
</b:Person>
<b:Person>
<b:Last>Carceroni</b:Last>
<b:First>R.L.</b:First>
</b:Person>
<b:Person>
<b:Last>Pereira</b:Last>
<b:First>G.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>37-44</b:Pages>
<b:StandardNumber> ISSN: 1530-1834 DOI: 10.1109/SIBGRAPI.2008.28</b:StandardNumber>
<b:BookTitle>Computer Graphics and Image Processing, 2008. SIBGRAPI '08. XXI Brazilian Symposium on</b:BookTitle>
<b:ConferenceName>Computer Graphics and Image Processing, 2008. SIBGRAPI '08. XXI Brazilian Symposium on</b:ConferenceName>
<b:Month>Oct.</b:Month>
<b:BIBTEX_Abstract>This paper describes a method to estimate the temporal alignment between N unsynchronized video sequences captured by cameras with non-overlapping fields of view. The sequences are recorded by stationary video cameras, with fixed intrinsic and extrinsic parameters. The proposed approach reduces the problem of synchronizing N non-overlapping sequences to the robust estimation of a single line in RN+1. This line captures all temporal relations between the sequences and a moving sensor in the scene, whose locations in the world coordinate system may be estimated at a constant sampling rate. Experimental results with real-world sequences show that our method can accurately align the videos.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image sequences, synchronisation, video camerasnonoverlapping fields, single line robust estimation, synchronisation, video cameras, video sequences</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Magnor2004</b:Tag>
<b:Title>Spacetime-Coherent Geometry Reconstruction from Multiple Video Streams</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Magnor</b:Last>
<b:First>Marcus</b:First>
</b:Person>
<b:Person>
<b:Last>Goldlucke</b:Last>
<b:First>Bastian</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>365-372</b:Pages>
<b:StandardNumber> ISBN: 0-7695-2223-8 DOI: http://dx.doi.org/10.1109/3DPVT.2004.117</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>3DPVT '04: Proceedings of the 3D Data Processing, Visualization, and Transmission, 2nd International Symposium</b:BookTitle>
<b:ConferenceName>3DPVT '04: Proceedings of the 3D Data Processing, Visualization, and Transmission, 2nd International Symposium</b:ConferenceName>
<b:BIBTEX_Abstract>By reconstructing time-varying geometry one frame at a time, one ignores the continuity of natural motion, wasting useful information about the underlying video-image formation process and taking into account temporally discontinuous reconstruction results. In 4D spacetime, the surface of a dynamic object describes a continuous 3D hyper-surface. This hyper-surface can be implicitly defined as the minimum of an energy functional designed to optimize photo-consistency. Based on an Euler-Lagrange reformulation of the problem, we find this hyper-surface from a handful of synchronized video recordings. The resulting object geometry varies smoothly over time, and intermittently invisible object regions are correctly interpolated from previously and/or future frames.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Xu2004a</b:Tag>
<b:Title>Convergent discrete Laplace-Beltrami operators over triangular surfaces</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Xu</b:Last>
<b:First>Guoliang</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>195-204</b:Pages>
<b:StandardNumber> ISSN:   DOI: 10.1109/GMAP.2004.1290041</b:StandardNumber>
<b:BookTitle>Geometric Modeling and Processing</b:BookTitle>
<b:JournalName>Geometric Modeling and Processing, 2004. Proceedings</b:JournalName>
<b:ConferenceName>Geometric Modeling and Processing</b:ConferenceName>
<b:BIBTEX_Abstract> The convergence property of the discrete Laplace-Beltrami operators is the foundation of convergence analysis of the numerical simulation process of some geometric partial differential equations which involve the operator. In this paper we propose several simple discretization schemes of Laplace-Beltrami operators over triangulated surfaces. Convergence results for these discrete Laplace-Beltrami operators are established under various conditions. Numerical results that support the theoretical analysis are given. Application examples of the proposed discrete Laplace-Beltrami operators in surface processing and modelling are also presented.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> computational geometry, convergence of numerical methods, mathematical operators, partial differential equations, solid modelling convergence analysis, convergent Laplace-Beltrami operators, discrete Laplace-Beltrami operators, discretization schemes, geometric partial differential equations, numerical simulation, surface modelling, surface processing, surface triangulation, triangular surfaces</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Ladikos2008</b:Tag>
<b:Title>Efficient visual hull computation for real-time 3D reconstruction using CUDA</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Ladikos</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Benhimane</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Navab</b:Last>
<b:First>N.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:StandardNumber> DOI: 10.1109/CVPRW.2008.4563098</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition Workshops</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition Workshops, 2008. CVPRW '08. IEEE Computer Society Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition Workshops</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>In this paper we present two efficient GPU-based visual hull computation algorithms. We compare them in terms of performance using image sets of varying size and different voxel resolutions. In addition, we present a real-time 3D reconstruction system which uses the proposed GPU-based reconstruction method to achieve real-time performance (30 fps) using 16 cameras and 4 PCs.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational geometry, image reconstruction, image resolutionCUDA, GPU, image sets, real-time 3D reconstruction, real-time performance, visual hull computation, voxel resolutions</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Kry2009</b:Tag>
<b:Title>Modal locomotion: animating virtual characters with natural vibrations</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Kry</b:Last>
<b:First>Paul</b:First>
</b:Person>
<b:Person>
<b:Last>Rev\'eret</b:Last>
<b:First>Lionel</b:First>
</b:Person>
<b:Person>
<b:Last>Faure</b:Last>
<b:First>Fran\c{c}ois</b:First>
</b:Person>
<b:Person>
<b:Last>Cani</b:Last>
<b:First>Marie-Paule</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:City>France</b:City>
<b:BookTitle>Eurographics, , 2009</b:BookTitle>
<b:ConferenceName>Eurographics, , 2009</b:ConferenceName>
<b:BIBTEX_Abstract>We present a general method to intuitively create a wide range of locomotion controllers for 3D legged characters. The key of our approach is the assumption that efficient locomotion can exploit the natural vibration modes of the body, where these modes are related to morphological parameters such as the shape, size, mass, and joint stiffness. The vibration modes are computed for a mechanical model of any 3D character with rigid bones, elastic joints, and additional constraints as desired. A small number of vibration modes can be selected with respect to their relevance to locomotion patterns and combined into a compact controller driven by very few parameters. We show that these controllers can be used in dynamic simulations of simple creatures, and for kinematic animations of more complex creatures of a variety of shapes and sizes.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Matusik2000</b:Tag>
<b:Title>Image-based visual hulls</b:Title>
<b:Year>2000</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Matusik</b:Last>
<b:First>Wojciech</b:First>
</b:Person>
<b:Person>
<b:Last>Buehler</b:Last>
<b:First>Chris</b:First>
</b:Person>
<b:Person>
<b:Last>Raskar</b:Last>
<b:First>Ramesh</b:First>
</b:Person>
<b:Person>
<b:Last>Gortler</b:Last>
<b:Middle>J.</b:Middle>
<b:First>Steven</b:First>
</b:Person>
<b:Person>
<b:Last>McMillan</b:Last>
<b:First>Leonard</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>369-374</b:Pages>
<b:StandardNumber> ISBN: 1-58113-208-5 DOI: http://doi.acm.org/10.1145/344779.344951</b:StandardNumber>
<b:Publisher>ACM Press/Addison-Wesley Publishing Co.</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '00: Proceedings of the 27th annual conference on Computer graphics and interactive techniques</b:BookTitle>
<b:ConferenceName>SIGGRAPH '00: Proceedings of the 27th annual conference on Computer graphics and interactive techniques</b:ConferenceName>
<b:BIBTEX_Abstract>In this paper, we describe an efficient image-based approach to computing and shading visual hulls from silhouette image data. Our algorithm takes advantage of epipolar geometry and incremental computation to achieve a constant rendering cost per rendered pixel. It does not suffer from the computation complexity, limited resolution, or quantization artifacts of previous volumetric approaches. We demonstrate the use of this algorithm in a real-time virtualized reality application running off a small number of video streams.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Svensson2002</b:Tag>
<b:Title>Curve skeletonization of surface-like objects in 3D images guided by voxel classification</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Svensson</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Nyström</b:Last>
<b:First>I.</b:First>
</b:Person>
<b:Person>
<b:Last>di Baja</b:Last>
<b:Middle>Sanniti</b:Middle>
<b:First>G.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1419-1426</b:Pages>
<b:Volume>23</b:Volume>
<b:StandardNumber> ISSN: 0167-8655 DOI: DOI: 10.1016/S0167-8655(02)00102-2</b:StandardNumber>
<b:JournalName>Pattern Recognition Letters</b:JournalName>
<b:Issue>12</b:Issue>
<b:URL>http://www.sciencedirect.com/science/article/B6V15-45J91MV-8/2/dbac3094e925ba869a16d7801fc00b81</b:URL>
<b:BIBTEX_Abstract>Skeletonization is a way to reduce dimensionality of digital objects. Here, we present an algorithm that computes the curve skeleton of a surface-like object in a 3D image, i.e., an object that in one of the three dimensions is at most two-voxel thick. A surface-like object consists of surfaces and curves crossing each other. Its curve skeleton is a 1D set centred within the surface-like object and with preserved topological properties. It can be useful to achieve a qualitative shape representation of the object with reduced dimensionality. The basic idea behind our algorithm is to detect the curves and the junctions between different surfaces and prevent their removal as they retain the most significant shape representation.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Curve skeleton</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Sminchisescu2002</b:Tag>
<b:Title>Human pose estimation from silhouettes. a consistent approach using distance level sets</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Sminchisescu</b:Last>
<b:First>C.</b:First>
</b:Person>
<b:Person>
<b:Last>Telea</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>In WSCG International Conference on Computer Graphics, Visualization and Computer Vision</b:BookTitle>
<b:ConferenceName>In WSCG International Conference on Computer Graphics, Visualization and Computer Vision</b:ConferenceName>
<b:BIBTEX_Abstract>We present a novel similarity measure (likelihood) for estimating three-dimensional human pose from image silhouettes in model-based vision applications. One of the challenges in such approaches is the construction of a model-to-image likelihood that truly reflects the good configurations of the problem. This is hard, commonly due to the violation of consistency principle resulting in the introduction of spurious, unrelated peaks/minima that make the search for model localization difficult. We introduce an entirely continuous formulation which enforces model estimation consistency by means of an attraction/explanation silhouette-based term pair. We subsequently show how the proposed method provides significant consolidation and improved attraction zone around the desired likelihood configurations and elimination of some of the spurious ones. Finally, we present a skeleton-based smoothing method for the image silhouettes that stabilizes and accelerates the search process.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>HernandezEsteban2002</b:Tag>
<b:Title>Multi-stereo 3D object reconstruction</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hernandez Esteban</b:Last>
<b:First>C.</b:First>
</b:Person>
<b:Person>
<b:Last>Schmitt</b:Last>
<b:First>F.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>159-166</b:Pages>
<b:StandardNumber> DOI: 10.1109/TDPVT.2002.1024055</b:StandardNumber>
<b:BookTitle>3D Data Processing Visualization and Transmission</b:BookTitle>
<b:JournalName>3D Data Processing Visualization and Transmission, 2002. Proceedings. First International Symposium on</b:JournalName>
<b:ConferenceName>3D Data Processing Visualization and Transmission</b:ConferenceName>
<b:BIBTEX_Abstract>We present a method for the reconstruction of a 3D real object from a sequence of high-definition images. We combine two different procedures: a shape from silhouette technique which provides a coarse 3D initial model followed by a multi-stereo carving technique. We propose a fast but accurate method for the estimation of the carving depth at each vertex of the 3D mesh. The quality of the final textured 3D reconstruction models allows us to validate the method.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> computer graphics, image reconstruction, image resolution, image sequences, image texture, mesh generation, robot vision, stereo image processing 3D mesh vertex, 3D object reconstruction, 3D real object, carving depth estimation, coarse initial model, computer graphics, high-definition image sequence, multi-stereo carving, robot vision, shape from silhouette technique, textured 3D reconstruction models</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Yue2003</b:Tag>
<b:Title>View synthesis of articulating humans using visual hull</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Yue</b:Last>
<b:First>Zhanfeng</b:First>
</b:Person>
<b:Person>
<b:Last>Zhao</b:Last>
<b:First>Liang</b:First>
</b:Person>
<b:Person>
<b:Last>Chellappa</b:Last>
<b:First>R.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> I-489-92 vol.1</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN:   DOI: 10.1109/ICME.2003.1220961</b:StandardNumber>
<b:BookTitle>Multimedia and Expo</b:BookTitle>
<b:JournalName>Multimedia and Expo, 2003. ICME '03. Proceedings. 2003 International Conference on</b:JournalName>
<b:ConferenceName>Multimedia and Expo</b:ConferenceName>
<b:Month>July</b:Month>
<b:BIBTEX_Abstract> In this paper, we present a method, which combines image-based visual hull and human body part segmentation for overcoming the inability of the visual hull method to reconstruct concave regions. The virtual silhouette image corresponding to the given viewing direction is first produced with image-based visual hull. Human body part localization technique is used to segment the input images and the rendered virtual silhouette image into convex body parts. The body parts in the virtual view are generated separately from the corresponding body parts in the input views and then assembled together. The previously rendered silhouette image is used to locate the corresponding body parts in input views and avoid the unconnected or squeezed regions in the assembled final view. Experiments show that this method can improve the reconstruction of concave regions for human postures and texture mapping.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> gesture recognition, image motion analysis, image reconstruction, image segmentation, image texture convex body parts, human body part segmentation, human postures, image-based visual hull, texture mapping, view synthesis, virtual silhouette image</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>He2009</b:Tag>
<b:Title>Harmonic 1-form based skeleton extraction from examples</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>He</b:Last>
<b:First>Ying</b:First>
</b:Person>
<b:Person>
<b:Last>Xiao</b:Last>
<b:First>Xian</b:First>
</b:Person>
<b:Person>
<b:Last>Seah</b:Last>
<b:First>Hock-Soon</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>49-62</b:Pages>
<b:Volume>71</b:Volume>
<b:StandardNumber> ISSN: 1524-0703 DOI: DOI: 10.1016/j.gmod.2008.12.008</b:StandardNumber>
<b:JournalName>Graphical Models</b:JournalName>
<b:Issue>2</b:Issue>
<b:URL>http://www.sciencedirect.com/science/article/B6WG3-4VFK7Y1-1/2/0edbb5ad68c04f9732a76282ed25eaec</b:URL>
<b:BIBTEX_Abstract>This paper presents a method to extract skeletons using examples. Our method is based on the observation that many deformations in real-world applications are isometric or near isometric. By taking advantage of the intrinsic property of harmonic 1-form, i.e., it is determined by the metric and independent of the resolution and embedding, our method can easily find a consistent mapping between the reference and example poses which can be in different resolutions and triangulations. We first construct the skeleton-like Reeb graph of a harmonic function defined on the given poses. Then by examining the changes of mean curvatures, we identify the initial locations of joints. Finally we refine the joint locations by solving a constrained optimization problem. We demonstrate the efficacy of the proposed framework by pose space deformation, skeleton transfer, shape segmentation and pose-invariant shape signature.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Skeleton extraction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Mercier2005</b:Tag>
<b:Title>Shape from Silhouette: Image Pixels for Marching Cubes</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Mercier</b:Last>
<b:First>B.</b:First>
</b:Person>
<b:Person>
<b:Last>Meneveaux</b:Last>
<b:First>D.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>112-118</b:Pages>
<b:Volume>13</b:Volume>
<b:JournalName>Journal of WSCG'2005</b:JournalName>
<b:Month>feb</b:Month>
<b:BIBTEX_Abstract>In this paper, we propose to use image pixels for geometry reconstruction with a shape from silhouette approach.
We aim at estimating shape and normal for the surface of a single object seen through calibrated images. From the
voxel-based shape obtained with the algorithm proposed by R. Szeliski in [18], our main contribution concerns the
use of image pixels together with marching cubes for constructing a triangular mesh. We also provide a mean for
estimating a normal inside each voxel with two different methods: (i) using marching cubes triangles and (ii) using
only voxels. As seen in the results, our method proves accurate even for real objects acquired with a usual camera
and an inexpensive acquisition system</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Lazebnik2007</b:Tag>
<b:Title>Projective Visual Hulls</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Lazebnik</b:Last>
<b:First>Svetlana</b:First>
</b:Person>
<b:Person>
<b:Last>Furukawa</b:Last>
<b:First>Yasutaka</b:First>
</b:Person>
<b:Person>
<b:Last>Ponce</b:Last>
<b:First>Jean</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>137-165</b:Pages>
<b:Volume>74</b:Volume>
<b:JournalName>International Journal of Computer Vision</b:JournalName>
<b:Issue>2</b:Issue>
<b:Month>#aug#</b:Month>
<b:URL>http://dx.doi.org/10.1007/s11263-006-0008-x</b:URL>
<b:BIBTEX_Abstract>Abstract&amp;nbsp;&amp;nbsp;This article presents a novel method for computing the visual hull of a solid bounded by a smooth surface and observed by a finite set of cameras. The visual hull is the intersection of the visual cones formed by back-projecting the silhouettes found in the corresponding images. We characterize its surface as a generalized polyhedron whose faces are visual cone patches; edges are intersection curves between two viewing cones; and vertices are frontier points where the intersection of two cones is singular, or intersection points where triples of cones meet. We use the mathematical framework of oriented projective differential geometry to develop an image-based algorithm for computing the visual hull. This algorithm works in a weakly calibrated settingâ€“-that is, it only requires projective camera matrices or, equivalently, fundamental matrices for each pair of cameras. The promise of the proposed algorithm is demonstrated with experiments on several challenging data sets and a comparison to another state-of-the-art method.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Ma2003</b:Tag>
<b:Title>Skeleton Extraction of 3D Objects with Radial Basis Functions</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Ma</b:Last>
<b:First>Wan-Chun</b:First>
</b:Person>
<b:Person>
<b:Last>Wu</b:Last>
<b:First>Fu-Che</b:First>
</b:Person>
<b:Person>
<b:Last>Ouhyoung</b:Last>
<b:First>Ming</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>207</b:Pages>
<b:StandardNumber> ISBN: 0-7695-1909-1</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>SMI '03: Proceedings of the Shape Modeling International 2003</b:BookTitle>
<b:ConferenceName>SMI '03: Proceedings of the Shape Modeling International 2003</b:ConferenceName>
<b:BIBTEX_Abstract>Skeleton is a lower dimensional shape description of anobject. The requirements of a skeleton differ with applications.For example, object recognition requires skele-tonswith primitive shape features to make similarity comparison.On the other hand, surface reconstruction needsskeletons which contain detailed geometry information toreduce the approximation error in the reconstruction process.Whereas many previous works are concerned aboutskeleton extraction, most of these methods are sensitive tonoise, time consuming, or restricted to specific 3D models.A practical approach for extracting skeletons from general3D models using radial basis functions (RBFs) is proposed.Skeleton generated with this approach conformsmore to the human perception. Given a 3D polygonalmodel, the vertices are regarded as centers for RBF level setconstruction. Next, a gradient descent algorithm is appliedto each vertex to locate the local maxima in the RBF; thegradient is calculated directly from the partial derivativesof the RBF. Finally, with the inherited connectivity from theoriginal model, local maximum pairs are connected withlinks driven by the active contour model. The skeletonizationprocess is completed when the potential energy of theselinks is minimized.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Paris2004</b:Tag>
<b:Title>Capture of hair geometry from multiple images</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Paris</b:Last>
<b:First>Sylvain</b:First>
</b:Person>
<b:Person>
<b:Last>Brice\</b:Last>
<b:Middle>Hector M.</b:Middle>
<b:First>{n}o,</b:First>
</b:Person>
<b:Person>
<b:Last>Sillion</b:Last>
<b:Middle>X.</b:Middle>
<b:First>Fran\c{c}ois</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>712-719</b:Pages>
<b:Volume>23</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/1015706.1015784</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>Hair is a major feature of digital characters. Unfortunately, it has a complex geometry which challenges standard modeling tools. Some dedicated techniques exist, but creating a realistic hairstyle still takes hours. Complementary to user-driven methods, we here propose an image-based approach to capture the geometry of hair.The novelty of this work is that we draw information from the scattering properties of the hair that are normally considered a hindrance. To do so, we analyze image sequences from a fixed camera with a moving light source. We first introduce a novel method to compute the image orientation of the hairs from their anisotropic behavior. This method is proven to subsume and extend existing work while improving accuracy. This image orientation is then raised into a 3D orientation by analyzing the light reflected by the hair fibers. This part relies on minimal assumptions that have been proven correct in previous work.Finally, we show how to use several such image sequences to reconstruct the complete hair geometry of a real person. Results are shown to illustrate the fidelity of the captured geometry to the original hair. This technique paves the way for a new approach to digital hair generation.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Dey2012</b:Tag>
<b:Title>Eigen Deformation of 3D Models</b:Title>
<b:Year>2012</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Dey</b:Last>
<b:Middle>K.</b:Middle>
<b:First>Tamal</b:First>
</b:Person>
<b:Person>
<b:Last>Ranjan</b:Last>
<b:First>Pawas</b:First>
</b:Person>
<b:Person>
<b:Last>Wang</b:Last>
<b:First>Yusu</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>585-595</b:Pages>
<b:Volume>28</b:Volume>
<b:StandardNumber> ISSN: 0178-2789 DOI: 10.1007/s00371-012-0705-0</b:StandardNumber>
<b:Publisher>Springer-Verlag New York, Inc.</b:Publisher>
<b:City>Secaucus, NJ, USA</b:City>
<b:JournalName>Vis. Comput.</b:JournalName>
<b:Issue>6-8</b:Issue>
<b:Month>#jun#</b:Month>
<b:URL>http://dx.doi.org/10.1007/s00371-012-0705-0</b:URL>
<b:BIBTEX_Abstract>Recent advances in mesh deformations have been dominated by two techniques: one uses an intermediate structure like a cage which transfers the user intended moves to the mesh, the other lets the user to impart the moves to the mesh directly. The former one lets the user deform the model in real-time and also preserve the shape with sophisticated techniques like Green Coordinates. The direct techniques on the other hand free the user from the burden of creating an appropriate cage though they take more computing time to solve larger non-linear optimizations. It would be ideal to develop a cage-free technique that provides real-time deformation while respecting the local geometry. Using a simple eigen-framework, we devise such a technique. Our framework creates an implicit skeleton automatically. The user only specifies the motion in a simple and intuitive manner, and our algorithm computes a deformation whose quality is similar to that of the cage-based scheme with Green Coordinates.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Animation, Deformation, Eigenspace, Eigenvectors</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Cheung2003</b:Tag>
<b:Title>Shape-from-silhouette of articulated objects and its use for human body kinematics estimation and motion capture</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cheung</b:Last>
<b:First>K.M.G.</b:First>
</b:Person>
<b:Person>
<b:Last>Baker</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Kanade</b:Last>
<b:First>T.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> I-77-I-84 vol.1</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1063-6919  DOI: 10.1109/CVPR.2003.1211340</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract> Shape-from-silhouette (SFS), also known as visual hull (VH) construction, is a popular 3D reconstruction method, which estimates the shape of an object from multiple silhouette images. The original SFS formulation assumes that the entire silhouette images are captured either at the same time or while the object is static. This assumption is violated when the object moves or changes shape. Hence the use of SFS with moving objects has been restricted to treating each time instant sequentially and independently. Recently we have successfully extended the traditional SFS formulation to refine the shape of a rigidly moving object over time. We further extend SFS to apply to dynamic articulated objects. Given silhouettes of a moving articulated object, the process of recovering the shape and motion requires two steps: (1) correctly segmenting (points on the boundary of) the silhouettes to each articulated part of the object, (2) estimating the motion of each individual part using the segmented silhouette. In this paper, we propose an iterative algorithm to solve this simultaneous assignment and alignment problem. Once we have estimated the shape and motion of each part of the object, the articulation points between each pair of rigid parts are obtained by solving a simple motion constraint between the connected parts. To validate our algorithm, we first apply it to segment the different body parts and estimate the joint positions of a person. The acquired kinematic (shape and joint) information is then used to track the motion of the person in new video sequences.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> edge detection, image reconstruction, image segmentation, image sequences, iterative methods, kinematics, motion estimation, object detection, optical tracking, stereo image processing, video signal processing 3D reconstruction, dynamic articulated object, human body kinematics estimation, iterative algorithm, joint position estimation, motion capture, motion estimation, motion recovery, motion tracking, moving articulated object, multiple silhouette images, object shape estimation, shape recovery, shape-from-silhouette, silhouette image segmentation, video sequence, visual hull construction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Moeslund2006</b:Tag>
<b:Title>A survey of advances in vision-based human motion capture and analysis</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Moeslund</b:Last>
<b:Middle>B.</b:Middle>
<b:First>Thomas</b:First>
</b:Person>
<b:Person>
<b:Last>Hilton</b:Last>
<b:First>Adrian</b:First>
</b:Person>
<b:Person>
<b:Last>Krüger</b:Last>
<b:First>Volker</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>90-126</b:Pages>
<b:Volume>104</b:Volume>
<b:StandardNumber> ISSN: 1077-3142 DOI: DOI: 10.1016/j.cviu.2006.08.002</b:StandardNumber>
<b:JournalName>Computer Vision and Image Understanding</b:JournalName>
<b:Issue>2-3</b:Issue>
<b:URL>http://www.sciencedirect.com/science/article/B6WCX-4M1DB7H-1/2/8da6f6e7a8c8e07d9331bc7738c6d499</b:URL>
<b:BIBTEX_Abstract>This survey reviews advances in human motion capture and analysis from 2000 to 2006, following a previous survey of papers up to 2000 [T.B. Moeslund, E. Granum, A survey of computer vision-based human motion capture, Computer Vision and Image Understanding, 81(3) (2001) 231-268.]. Human motion capture continues to be an increasingly active research area in computer vision with over 350 publications over this period. A number of significant research advances are identified together with novel methodologies for automatic initialization, tracking, pose estimation, and movement recognition. Recent research has addressed reliable tracking and pose estimation in natural scenes. Progress has also been made towards automatic understanding of human actions and behavior. This survey reviews recent trends in video-based human capture and analysis, as well as discussing open problems for future research to achieve automatic visual analysis of human movement.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Review</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Suessmuth2008</b:Tag>
<b:Title>Reconstructing Animated Meshes from Time-Varying Point Clouds</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Süßmuth</b:Last>
<b:First>Jochen</b:First>
</b:Person>
<b:Person>
<b:Last>Winter</b:Last>
<b:First>Marco</b:First>
</b:Person>
<b:Person>
<b:Last>Greiner</b:Last>
<b:First>Günther</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1469-1476</b:Pages>
<b:Volume>27</b:Volume>
<b:JournalName>Computer Graphics Forum</b:JournalName>
<b:Issue>5</b:Issue>
<b:URL>http://dx.doi.org/10.1111/j.1467-8659.2008.01287.x</b:URL>
<b:BIBTEX_Abstract>In this paper, we describe a novel approach for the reconstruction of animated meshes from a series of time-deforming point clouds. Given a set of unordered point clouds that have been captured by a fast 3-D scanner, our algorithm is able to compute coherent meshes which approximate the input data at arbitrary time instances. Our method is based on the computation of an implicit function in 211D4 that approximates the time-space surface of the time-varying point cloud. We then use the four-dimensional implicit function to reconstruct a polygonal model for the first time-step. By sliding this template mesh along the time-space surface in an as-rigid-as-possible manner, we obtain reconstructions for further time-steps which have the same connectivity as the previously extracted mesh while recovering rigid motion exactly. The resulting animated meshes allow accurate motion tracking of arbitrary points and are well suited for animation compression. We demonstrate the qualities of the proposed method by applying it to several data sets acquired by real-time 3-D scanners.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Brunner2008</b:Tag>
<b:Title>Fast Force Field Approximation and its Application to Skeletonization of Discrete 3D Objects</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Brunner</b:Last>
<b:First>David</b:First>
</b:Person>
<b:Person>
<b:Last>Brunnett</b:Last>
<b:First>Guido</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>261-270</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISBN: 0167-7055</b:StandardNumber>
<b:JournalName>Computer Graphics forum journal, Vol. 27, No. 2 (2008), Eurographics 2008</b:JournalName>
<b:Month>04</b:Month>
<b:URL> http://www.tu-chemnitz.de/informatik/HomePages/GDV/forschung/doc/mi_prof_publik_208.x-pdf</b:URL>
<b:BIBTEX_Abstract>In this paper we present a novel method to approximate the force ?eld of a discrete 3d object with a time complexity that is linear in the number of voxels. We de?ne a rule, similar to the distance transform, to propagate forces associated with boundary points into the interior of the object. The result of this propagation depends on the order in which the points of the object are processed. Therefore we analyze how to obtain an order-invariant approximation formula. With the resulting formula it becomes possible to approximate the force ?eld and to use its features for a fast and topology preserving skeletonization. We use a thinning strategy on the body-centered cubic lattice to compute the skeleton and ensure that critical points of the force ?eld are not removed. This leads to improved skeletons with respect to the properties of centeredness and rotational invariance.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Landabaso2008</b:Tag>
<b:Title>Shape from inconsistent silhouette for free viewpoint video</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Landabaso</b:Last>
<b:First>J.-L.</b:First>
</b:Person>
<b:Person>
<b:Last>Lizcano</b:Last>
<b:First>L.</b:First>
</b:Person>
<b:Person>
<b:Last>Pardas</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>213-216</b:Pages>
<b:StandardNumber> ISSN: 1522-4880 DOI: 10.1109/ICIP.2008.4711729</b:StandardNumber>
<b:BookTitle>Image Processing</b:BookTitle>
<b:JournalName>Image Processing, 2008. ICIP 2008. 15th IEEE International Conference on</b:JournalName>
<b:ConferenceName>Image Processing</b:ConferenceName>
<b:Month>Oct.</b:Month>
<b:BIBTEX_Abstract>In this paper we present an efficient image-based rendering algorithm that obtains novel images from a set of views of the scene of interest. The approach described uses silhouette image data to compute the Visual Hull, the largest volume that is compatible with the silhouettes that delimit the objects of interest. Since the Visual Hull is not explicitly computed, this approach does not suffer from the quantization artifacts of volumetric approaches. In contrast to previous works, we explore how detection errors in the silhouettes affect the novel rendered view and propose a method to detect errors in the original silhouettes based on the consistency principle that states that the projection of the Visual Hull should exactly correspond with original silhouettes.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>rendering (computer graphics), video signal processingerror detection, free viewpoint video, image-based rendering algorithm, immersive videoconferencing system, inconsistent silhouette image, quantization artifacts, silhouette image data, visual hull</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Garland1997</b:Tag>
<b:Title>Surface simplification using quadric error metrics</b:Title>
<b:Year>1997</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Garland</b:Last>
<b:First>Michael</b:First>
</b:Person>
<b:Person>
<b:Last>Heckbert</b:Last>
<b:Middle>S.</b:Middle>
<b:First>Paul</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>209-216</b:Pages>
<b:StandardNumber> ISBN: 0-89791-896-7 DOI: http://dx.doi.org/10.1145/258734.258849</b:StandardNumber>
<b:Publisher>ACM Press/Addison-Wesley Publishing Co.</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>Proceedings of the 24th annual conference on Computer graphics and interactive techniques</b:BookTitle>
<b:ConferenceName>Proceedings of the 24th annual conference on Computer graphics and interactive techniques</b:ConferenceName>
<b:URL>http://dx.doi.org/10.1145/258734.258849</b:URL>
<b:BIBTEX_Series>SIGGRAPH '97</b:BIBTEX_Series>
<b:BIBTEX_Abstract>Many applications in computer graphics require complex, highly detailed models. However, the level of detail actually necessary may vary considerably. To control processing time, it is often desirable to use approximations in place of excessively detailed models. We have developed a surface simplification algorithm which can rapidly produce high quality approximations of polygonal models. The algorithm uses iterative contractions of vertex pairs to simplify models and maintains surface error approximations using quadric matrices. By contracting arbitrary vertex pairs (not just edges), our algorithm is able to join unconnected regions of models. This can facilitate much better approximations, both visually and with respect to geometric error. In order to allow topological joining, our system also supports non-manifold surface models. CR Categories: I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling---surface and object representations</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>level of detail, mutiresolution modeling, non-manifold, pair contraction, surface simplification</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Aguiar2005</b:Tag>
<b:Title>Reconstructing Human Shape and Motion from Multi-View Video</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>Edilson</b:First>
</b:Person>
<b:Person>
<b:Last>Theobalt</b:Last>
<b:First>Christian</b:First>
</b:Person>
<b:Person>
<b:Last>Magnor</b:Last>
<b:First>Marcus</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>Hans-Peter</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>42-49</b:Pages>
<b:StandardNumber> ISBN: 0-86341-583-0</b:StandardNumber>
<b:Publisher>The IEE</b:Publisher>
<b:City>London, UK</b:City>
<b:BookTitle>2nd European Conference on Visual Media Production (CVMP)</b:BookTitle>
<b:ConferenceName>2nd European Conference on Visual Media Production (CVMP)</b:ConferenceName>
<b:Month>December</b:Month>
<b:BIBTEX_Abstract>In model-based free-viewpoint video, a detailed representation of the time-varying geometry of a real-word scene is used to generate renditions of it from novel viewpoints. In this paper, we present a method for reconstructing such a dynamic geometry model of a human actor from multi-view video. In a two-step procedure, ?rst the spatio-temporally consistent shape and poses of a generic human body model are estimated by means of a silhouette-based analysis-by-synthesis method.
In a second step, subtle details in surface geometry that are speci?c to each particular time step are recovered by enforcing a color-consistency criterion. By this means, we generate a realistic representation of the time-varying geometry of a
moving person that also reproduces these dynamic surface variations.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Hassouna2005a</b:Tag>
<b:Title>Robust Centerline Extraction Framework Using Level Sets</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hassouna</b:Last>
<b:Middle>Sabry</b:Middle>
<b:First>M.</b:First>
</b:Person>
<b:Person>
<b:Last>Farag</b:Last>
<b:Middle>A.</b:Middle>
<b:First>Aly</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>458-465</b:Pages>
<b:StandardNumber> ISBN: 0-7695-2372-2 DOI: http://dx.doi.org/10.1109/CVPR.2005.306</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>CVPR '05: Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1</b:BookTitle>
<b:ConferenceName>CVPR '05: Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1</b:ConferenceName>
<b:BIBTEX_Abstract>In this paper, we present a novel framework for computing centerlines for both 2D and 3D shape analysis. The framework works as follows: an object centerline point is selected automatically as the point of global maximum Euclidean distance from the boundary, and is considered a point source (PS) that transmits a wave front that evolves over time and traverses the object domain. The front propagates at each object point with a speed that is proportional to its Euclidean distance from the boundary. The motion of the front is governed by a nonlinear partial differential equation whose solution is computed efficiently using level set methods. Initially, the PS transmits a moderate speed wave to explore the object domain and extract its topological information such as merging and extreme points. Then, it transmits a new front that is much faster at centerline points than non central ones. As a consequence, centerlines intersect the propagating fronts at those points of maximum positive curvature. Centerlines are computed by tracking them, starting from each topological point until the PS is reached, by solving an ordinary differential equation using an efficient numerical scheme. The proposed method is computationally inexpensive, handles efficiently objects with complex topology, and computes centerlines that are centered, connected, one point thick, and less sensitive to boundary noise. In addition, the extracted paths form a tree graph without additional cost. We have extensively validated the robustness of the proposed method both quantitatively and qualitatively against several 2D and 3D shapes.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Botsch2008</b:Tag>
<b:Title>On Linear Variational Surface Deformation Methods</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Botsch</b:Last>
<b:First>Mario</b:First>
</b:Person>
<b:Person>
<b:Last>Sorkine</b:Last>
<b:First>Olga</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>213-230</b:Pages>
<b:Volume>14</b:Volume>
<b:StandardNumber> ISSN: 1077-2626 DOI: http://dx.doi.org/10.1109/TVCG.2007.1054</b:StandardNumber>
<b:Publisher>IEEE Educational Activities Department</b:Publisher>
<b:City>Piscataway, NJ, USA</b:City>
<b:JournalName>IEEE Transactions on Visualization and Computer Graphics</b:JournalName>
<b:Issue>1</b:Issue>
<b:BIBTEX_Abstract>This survey reviews the recent advances in linear variational mesh deformation techniques. These methods were developed for editing detailed high-resolution meshes, like those produced by scanning real-world objects. The challenge of manipulating such complex surfaces is three-fold: the deformation technique has to be sufficiently fast, robust, and intuitive and easy to control to be useful for interactive applications. An intuitive, and thus predictable, deformation tool should provide physically plausible and aesthetically pleasing surface deformations, which in particular requires its geometric details to be preserved. The methods we survey generally formulate surface deformation as a global variational optimization problem that addresses the differential properties of the edited surface. Efficiency and robustness are achieved by linearizing the underlying objective functional, such that the global optimization amounts to solving a sparse linear system of equations. We review the different deformation energies and detail preservation techniques that were proposed in the recent years, together with the various techniques to rectify the linearization artifacts. Our goal is to provide the reader with a systematic classification and comparative description of the different techniques, revealing the strengths and weaknesses of each approach in common editing scenarios.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Shapira2008</b:Tag>
<b:Title>Consistent mesh partitioning and skeletonisation using the shape diameter function</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Shapira</b:Last>
<b:First>Lior</b:First>
</b:Person>
<b:Person>
<b:Last>Shamir</b:Last>
<b:First>Ariel</b:First>
</b:Person>
<b:Person>
<b:Last>Cohen-Or</b:Last>
<b:First>Daniel</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>249-259</b:Pages>
<b:Volume>24</b:Volume>
<b:StandardNumber> ISSN: 0178-2789 DOI: http://dx.doi.org/10.1007/s00371-007-0197-5</b:StandardNumber>
<b:Publisher>Springer-Verlag New York, Inc.</b:Publisher>
<b:City>Secaucus, NJ, USA</b:City>
<b:JournalName>Vis. Comput.</b:JournalName>
<b:Issue>4</b:Issue>
<b:BIBTEX_Abstract>Mesh partitioning and skeletonisation are fundamental for many computer graphics and animation techniques. Because of the close link between an object’s skeleton and its boundary, these two problems are in many cases complementary. Any partitioning of the object can assist in the creation of a skeleton and any segmentation of the skeleton can infer a partitioning of the object. In this paper, we consider these two problems on a wide variety of meshes, and strive to construct partitioning and skeletons which remain consistent across a family of objects, not a single one. Such families can consist of either a single object in multiple poses and resolutions, or multiple objects which have a general common shape. To achieve consistency, we base our algorithms on a volume-based shape-function called the shape-diameter-function (SDF), which remains largely oblivious to pose changes of the same object and maintains similar values in analogue parts of different objects. The SDF is a scalar function defined on the mesh surface; however, it expresses a measure of the diameter of the object’s volume in the neighborhood of each point on the surface. Using the SDF we are able to process and manipulate families of objects which contain similarities using a simple and consistent algorithm: consistently partitioning and creating skeletons among multiple meshes.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Kry2006</b:Tag>
<b:Title>Interaction capture and synthesis</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Kry</b:Last>
<b:Middle>G.</b:Middle>
<b:First>Paul</b:First>
</b:Person>
<b:Person>
<b:Last>Pai</b:Last>
<b:Middle>K.</b:Middle>
<b:First>Dinesh</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>872-880</b:Pages>
<b:Volume>25</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/1141911.1141969</b:StandardNumber>
<b:Publisher>ACM Press</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>Modifying motion capture to satisfy the constraints of new animation is difficult when contact is involved, and a critical problem for animation of hands. The compliance with which a character makes contact also reveals important aspects of the movement’s purpose. We present a new technique called interaction capture, for capturing these contact phenomena. We capture contact forces at the same time as motion, at a high rate, and use both to estimate a nominal reference trajectory and joint compliance. Unlike traditional methods, our method estimates joint compliance without the need for motorized perturbation devices. New interactions can then be synthesized by physically based simulation. We describe a novel position-based linear complementarity problem formulation that includes friction, breaking contact, and the compliant coupling between contacts at different fingers. The technique is validated using data from previous work and our own perturbation-based estimates.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Franco2009</b:Tag>
<b:Title>Efficient Polyhedral Modeling from Silhouettes</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Franco</b:Last>
<b:First>J.-S.</b:First>
</b:Person>
<b:Person>
<b:Last>Boyer</b:Last>
<b:First>E.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>414-427</b:Pages>
<b:Volume>31</b:Volume>
<b:StandardNumber> ISSN: 0162-8828 DOI: 10.1109/TPAMI.2008.104</b:StandardNumber>
<b:JournalName>Pattern Analysis and Machine Intelligence, IEEE Transactions on</b:JournalName>
<b:Issue>3</b:Issue>
<b:Month>March </b:Month>
<b:BIBTEX_Abstract>Modeling from silhouettes is a popular and useful topic in computer vision. Many methods exist to compute the surface of the visual hull from silhouettes, but few address the problem of ensuring good topological properties of the surface, such as manifoldness. This article provides an efficient algorithm to compute such a surface in the form of a polyhedral mesh. It relies on a small number of geometric operations to compute a visual hull polyhedron in a single pass. Such simplicity enables the algorithm to combine the advantages of being fast, producing pixel-exact surfaces, and repeatably yield manifold and watertight polyhedra in general experimental conditions with real data, as verified with all datasets tested. The algorithm is fully described, its complexity analyzed and modeling results given.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational complexity, computational geometry, computer vision, mesh generation, solid modelling, surface fittingcomputational complexity, computer vision, geometric operation, polyhedral mesh, silhouette polyhedral modeling, topological property, visual hull surface</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Aganj2007</b:Tag>
<b:Title>Spatio-Temporal Shape from Silhouette using Four-Dimensional Delaunay Meshing</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Aganj</b:Last>
<b:First>E.</b:First>
</b:Person>
<b:Person>
<b:Last>Pons</b:Last>
<b:First>J.-P.</b:First>
</b:Person>
<b:Person>
<b:Last>Segonne</b:Last>
<b:First>F.</b:First>
</b:Person>
<b:Person>
<b:Last>Keriven</b:Last>
<b:First>R.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:StandardNumber> ISSN: 1550-5499 DOI: 10.1109/ICCV.2007.4409016</b:StandardNumber>
<b:BookTitle>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:BookTitle>
<b:JournalName>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:JournalName>
<b:ConferenceName>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:ConferenceName>
<b:Month>Oct.</b:Month>
<b:BIBTEX_Abstract>We propose a novel method for computing a four-dimensional (4D) representation of the spatio-temporal visual hull of a dynamic scene, based on an extension of a recent provably correct Delaunay meshing algorithm. By considering time as an additional dimension, our approach exploits seamlessly the time coherence between different frames to produce a compact and high-quality 4D mesh representation of the visual hull. The 3D visual hull at a given time instant is easily obtained by intersecting this 4D mesh with a temporal plane, thus enabling interpolation of objects' shape between consecutive frames. In addition, our approach offers easy and extensive control over the size and quality of the output mesh as well as over its associated re- projection error. Our numerical experiments demonstrate the effectiveness and flexibility of our approach for generating compact, high-quality, time-coherent visual hull representations from real silhouette image data.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image representation, interpolation, mesh generation, spatiotemporal phenomenafour-dimensional Delaunay meshing algorithm, image representation, interpolation, silhouette image data, spatio-temporal visual hull</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Tierny2008</b:Tag>
<b:Title>Fast and precise kinematic skeleton extraction of 3D dynamic meshes</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tierny</b:Last>
<b:First>J.</b:First>
</b:Person>
<b:Person>
<b:Last>Vandeborre</b:Last>
<b:First>J.-P.</b:First>
</b:Person>
<b:Person>
<b:Last>Daoudi</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-4</b:Pages>
<b:StandardNumber> ISSN: 1051-4651 DOI: 10.1109/ICPR.2008.4761011</b:StandardNumber>
<b:BookTitle>Pattern Recognition</b:BookTitle>
<b:JournalName>Pattern Recognition, 2008. ICPR 2008. 19th International Conference on</b:JournalName>
<b:ConferenceName>Pattern Recognition</b:ConferenceName>
<b:Month>Dec.</b:Month>
<b:BIBTEX_Abstract>Shape skeleton extraction is a fundamental pre-processing task in shape-based pattern recognition. This paper presents a new algorithm for fast and precise extraction of kinematic skeletons of 3D dynamic surface meshes. Unlike previous approaches, surface motions are characterized by the mesh edge-length deviation induced by its transformation through time. Then a static skeleton extraction algorithm based on Reeb graphs exploits this latter information to extract the kinematic skeleton. This hybrid static and dynamic shape analysis enables the precise detection of objectspsila articulations as well as shape topological transitions corresponding to possibly-articulated immobile objectspsila features. Experiments show that the proposed algorithm is faster than previous techniques and still achieves better accuracy.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational geometry, graph theory, mesh generation, pattern recognition3D dynamic meshes, 3D dynamic surface meshes, Reeb graphs, dynamic shape analysis, fast kinematic skeleton extraction, mesh edge-length deviation, possibly-articulated immobile objects features, precise kinematic skeleton extraction, preprocessing task, shape skeleton extraction, shape topological transitions, shape-based pattern recognition, static shape analysis, static skeleton extraction algorithm, surface motions</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Deng2009</b:Tag>
<b:Title>Perceptually Consistent Example-based Human Motion Retrieval</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Deng</b:Last>
<b:First>Z.</b:First>
</b:Person>
<b:Person>
<b:Last>Gu</b:Last>
<b:First>Q.</b:First>
</b:Person>
<b:Person>
<b:Last>Li</b:Last>
<b:First>Q.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>191-198</b:Pages>
<b:BookTitle>Proc. of ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</b:BookTitle>
<b:ConferenceName>Proc. of ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</b:ConferenceName>
<b:Month>Feb</b:Month>
<b:BIBTEX_Abstract>Large amount of human motion capture data have been increasingly recorded and used in animation and gaming applications. Efficient retrieval of logically similar motions from a large data repository thereby serves as a fundamental basis for these motion data based applications. In this paper we present a perceptually consistent, example-based human motion retrieval approach that is capable of efficiently searching for and ranking similar motion sequences given a query motion input. Our method employs a motion pattern discovery and matching scheme that breaks human motions into a part-based, hierarchical motion representation. Building upon this representation, a fast string match algorithm is used for efficient runtime motion query processing. Finally, we conducted comparative user studies to evaluate the accuracy and perceptual-consistency of our approach by comparing it with the state of the art example-based human motion search algorithms.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Reniers2008</b:Tag>
<b:Title>Part-type Segmentation of Articulated Voxel-Shapes using the Junction Rule</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Reniers</b:Last>
<b:First>Dennie</b:First>
</b:Person>
<b:Person>
<b:Last>Telea</b:Last>
<b:First>Alexandru</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1845-1852</b:Pages>
<b:Volume>27</b:Volume>
<b:JournalName>Computer Graphics Forum</b:JournalName>
<b:Issue>7</b:Issue>
<b:BIBTEX_Abstract>We present a part-type segmentation method for articulated voxel-shapes based on curve skeletons. Shapes are considered to consist of several simpler, intersecting shapes. Our method is based on the junction rule: the observation that two intersecting shapes generate an additional junction in their joined curve-skeleton near the place of intersection. For each curve-skeleton point, we construct a piecewise-geodesic loop on the shape surface. Starting from the junctions, we search along the curve skeleton for points whose associated loops make for suitable part cuts. The segmentations are robust to noise and discretization artifacts, because the curve skeletonization incorporates a single user-parameter to filter spurious curve-skeleton branches. Furthermore, segment borders are smooth and minimally twisting by construction. We demonstrate our method on several real-world examples and compare it to existing part-type segmentation methods.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>articulated, part-type, segmentation, voxel-shapes</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>1060250</b:Tag>
<b:Title>Homotopy-preserving medial axis simplification</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Sud</b:Last>
<b:First>Avneesh</b:First>
</b:Person>
<b:Person>
<b:Last>Foskey</b:Last>
<b:First>Mark</b:First>
</b:Person>
<b:Person>
<b:Last>Manocha</b:Last>
<b:First>Dinesh</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>39-50</b:Pages>
<b:StandardNumber> ISBN: 1-59593-015-9 DOI: http://doi.acm.org/10.1145/1060244.1060250</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SPM '05: Proceedings of the 2005 ACM symposium on Solid and physical modeling</b:BookTitle>
<b:ConferenceName>SPM '05: Proceedings of the 2005 ACM symposium on Solid and physical modeling</b:ConferenceName>
<b:BIBTEX_Abstract>We present a novel algorithm to compute a simplified medial axis of a polyhedron. Our simplification algorithm tends to remove unstable features of Blum's medial axis. Moreover, our algorithm preserves the topological structure of the original medial axis and ensures that the simplified medial axis has the same homotopy type as Blum's medial axis. We use the separation angle formed by connecting a point on the medial axis to closest points on the boundary as a measure of the stability of the medial axis at the point. The medial axis is decomposed into its parts that are the sheets, seams and junctions. We present a stability measure of each part of the medial axis based on separation angles and examine the relation between the stability measures of adjacent parts. Our simplification algorithm uses iterative pruning of the parts based on efficient local tests. We have applied the algorithm to compute a simplified medial axis of complex models with tens of thousands of triangles and complex topologies.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Pan2009</b:Tag>
<b:Title>ProFORMA: Probabilistic Feature-based On-line Rapid Model Acquisition</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Pan</b:Last>
<b:First>Q.</b:First>
</b:Person>
<b:Person>
<b:Last>Reitmayr</b:Last>
<b:First>G.</b:First>
</b:Person>
<b:Person>
<b:Last>Drummond</b:Last>
<b:First>T.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:City>London</b:City>
<b:BookTitle>Proc. 20th British Machine Vision Conference (BMVC)</b:BookTitle>
<b:ConferenceName>Proc. 20th British Machine Vision Conference (BMVC)</b:ConferenceName>
<b:Month>September</b:Month>
<b:BIBTEX_Abstract>Off-line model reconstruction relies on an image collection phase and a slow reconstruction phase, requiring a long time to verify a model obtained from an image sequence is acceptable. We propose a new model acquisition system, called ProFORMA, which generates a 3D model on-line as the input sequence is being collected. As the user rotates the object in front of a stationary camera, a partial model is reconstructed and displayed to the user to assist view planning. The model is also used by the system to robustly track the pose of the object. Models are rapidly produced through a Delaunay tetrahedralisation of points obtained from on-line structure from motion estimation, followed by a probabilistic tetrahedron carving step to obtain a textured surface mesh of the object.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Min2008</b:Tag>
<b:Title>Graph-Cut Based Background Subtraction Using Visual Hull in Multiveiw Images</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Min</b:Last>
<b:First>Seungki</b:First>
</b:Person>
<b:Person>
<b:Last>Kim</b:Last>
<b:First>Jungwhan</b:First>
</b:Person>
<b:Person>
<b:Last>Park</b:Last>
<b:First>Anjin</b:First>
</b:Person>
<b:Person>
<b:Last>Hong</b:Last>
<b:First>Gwangjin</b:First>
</b:Person>
<b:Person>
<b:Last>Jung</b:Last>
<b:First>Keechul</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>372-377</b:Pages>
<b:StandardNumber> DOI: 10.1109/DICTA.2008.84</b:StandardNumber>
<b:BookTitle>Computing: Techniques and Applications</b:BookTitle>
<b:JournalName>Computing: Techniques and Applications, 2008. DICTA '08.Digital Image</b:JournalName>
<b:ConferenceName>Computing: Techniques and Applications</b:ConferenceName>
<b:Month>Dec.</b:Month>
<b:BIBTEX_Abstract>A graph-cut method has been successfully used in many applications for image segmentation. However, it needs lots of time and user intervention. In case of multi view image (MVI), it is especially hard to segment all images in a short time because of numerous images in MVI. In this paper, we describe a new technique for multi view image segmentation, which needs minimum user intervention and provides fast processing time. The user marks certain pixels as "target object" or "background" to provide a constraint for segmentation to only one of the MVI. The seed information is propagated to all images in the MVI. In this step, we can acquire tentative segment result and then apply them to reconstruct the 3D model which exploits the visual hull. After the 3D model is reconstructed, segment error that is found located out of foreground is eliminated. Although visual hull has a shortcoming that cannot represent whether the object is convex or concave, tentative segment result is easy to use and proven to be enough as our proposed method. We can acquire final segment result in a short time by integrating these two simple methods. According to the experiments, our method shows better performance in terms of processing time and minimizing user intervention.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>graph theory, image reconstruction, image representation, image segmentation3D model reconstruction, graph-cut method, image segmentation, multiview image segmentation, target object, visual hull</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Wang2003</b:Tag>
<b:Title>Video Analysis of Human Dynamics - a Survey</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Wang</b:Last>
<b:Middle>Junlin</b:Middle>
<b:First>Jessica</b:First>
</b:Person>
<b:Person>
<b:Last>Singh</b:Last>
<b:First>Sameer</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>321-346</b:Pages>
<b:Volume>9</b:Volume>
<b:JournalName>Real Time Imaging</b:JournalName>
<b:BIBTEX_Abstract>Video analysis of human dynamics is an important area of research devoted to detecting people and understanding their dynamic physical behavior in a complex environment that can be used for biometric applications. This paper provides a detailed survey of the various studies in areas related to the tracking of people and body parts such as face, hands, fingers, legs, etc., and modeling behavior using motion analysis.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Caillette2005</b:Tag>
<b:Title>Real-Time 3-D Human Body Tracking Using Variable Length Markov Models</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Caillette</b:Last>
<b:First>Fabrice</b:First>
</b:Person>
<b:Person>
<b:Last>Galata</b:Last>
<b:First>Aphrodite</b:First>
</b:Person>
<b:Person>
<b:Last>Howard</b:Last>
<b:First>Toby</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>469-478</b:Pages>
<b:BookTitle>In British Machine Vision Conf</b:BookTitle>
<b:ConferenceName>In British Machine Vision Conf</b:ConferenceName>
<b:BIBTEX_Abstract>In this paper, we introduce a 3-D human-body tracker capable of handling fast and complex motions in real-time. The parameter space, augmented with first order derivatives, is automatically partitioned into Gaussian clusters each representing an elementary motion: hypothesis propagation inside each cluster is therefore accurate and efficient. The transitions between clusters use the predictions of a Variable Length Markov Model which can explain highlevel behaviours over a long history. Using Monte-Carlo methods, evaluation of model candidates is critical for both speed and robustness. We present a new evaluation scheme based on volumetric reconstruction and blobs-fitting, where appearance models and image evidences are represented by Gaussian mixtures. We demonstrate the application of our tracker to long video sequences exhibiting rapid and diverse movements.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Book</b:SourceType>
<b:Tag>Spivak1-1999</b:Tag>
<b:Title>A Comprehensive Introduction to Differential Geometry</b:Title>
<b:Year>1999</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Spivak</b:Last>
<b:First>Michael</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Volume>1</b:Volume>
<b:Edition>3rd</b:Edition>
<b:StandardNumber> ISBN: 0914098705</b:StandardNumber>
<b:Publisher>{Publish or Perish, Inc}</b:Publisher>
<b:Month>January</b:Month>
<b:URL>http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&amp;path=ASIN/0914098705</b:URL>
<b:BIBTEX_KeyWords>differential-geometry</b:BIBTEX_KeyWords>
<b:BIBTEX_HowPublished>Hardcover</b:BIBTEX_HowPublished>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Fujiyoshi1998</b:Tag>
<b:Title>Real-Time Human Motion Analysis By Image Skeletonization</b:Title>
<b:Year>1998</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Fujiyoshi</b:Last>
<b:First>Hironobu</b:First>
</b:Person>
<b:Person>
<b:Last>Lipton</b:Last>
<b:Middle>J.</b:Middle>
<b:First>Alan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>15-21</b:Pages>
<b:BookTitle>In Proceedings of IEEE WACV98</b:BookTitle>
<b:ConferenceName>In Proceedings of IEEE WACV98</b:ConferenceName>
<b:BIBTEX_Abstract>In this paper, a process is described for analysing the motion of a human target in a video stream. Moving targets are detected and their boundaries extracted. From these, a "star" skeleton is produced. Two motion cues are determined from this skeletonization: body posture, and cyclic motion of skeleton segments. These cues are used to determine human activities such as walking or running, and even potentially, the target's gait. Unlike other methods, this does not require an a priori human model, or a large number of "pixels on target". Furthermore, it is computationally inexpensive, and thus ideal for real-world video applications such as outdoor video surveillance.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Reuter2009</b:Tag>
<b:Title>Discrete Laplace–Beltrami operators for shape analysis and segmentation </b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Reuter</b:Last>
<b:First>Martin</b:First>
</b:Person>
<b:Person>
<b:Last>Biasotti</b:Last>
<b:First>Silvia</b:First>
</b:Person>
<b:Person>
<b:Last>Giorgi</b:Last>
<b:First>Daniela</b:First>
</b:Person>
<b:Person>
<b:Last>Patanè</b:Last>
<b:First>Giuseppe</b:First>
</b:Person>
<b:Person>
<b:Last>Spagnuolo</b:Last>
<b:First>Michela</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>381-390</b:Pages>
<b:Volume>33</b:Volume>
<b:StandardNumber> ISSN: 0097-8493 DOI: http://dx.doi.org/10.1016/j.cag.2009.03.005</b:StandardNumber>
<b:JournalName>Computers \&amp; Graphics </b:JournalName>
<b:Issue>3</b:Issue>
<b:URL>http://www.sciencedirect.com/science/article/pii/S0097849309000272</b:URL>
<b:BIBTEX_Abstract>Shape analysis plays a pivotal role in a large number of applications, ranging from traditional geometry processing to more recent 3D content management. In this scenario, spectral methods are extremely promising as they provide a natural library of tools for shape analysis, intrinsically defined by the shape itself. In particular, the eigenfunctions of the Laplace–Beltrami operator yield a set of real-valued functions that provide interesting insights in the structure and morphology of the shape. In this paper, we first analyze different discretizations of the Laplace–Beltrami operator (geometric Laplacians, linear and cubic FEM operators) in terms of the correctness of their eigenfunctions with respect to the continuous case. We then present the family of segmentations induced by the nodal sets of the eigenfunctions, discussing its meaningfulness for shape understanding.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Laplace–Beltrami operator</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Brand2004</b:Tag>
<b:Title>Algebraic solution for the visual hull</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Brand</b:Last>
<b:First>M.</b:First>
</b:Person>
<b:Person>
<b:Last>Kang</b:Last>
<b:First>Kongbin</b:First>
</b:Person>
<b:Person>
<b:Last>Cooper</b:Last>
<b:First>D.B.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> I-30-I-35 Vol.1</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN: 1063-6919  DOI: 10.1109/CVPR.2004.1315010</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition</b:ConferenceName>
<b:Month>June-2 July</b:Month>
<b:BIBTEX_Abstract>We introduce an algebraic dual-space method for reconstructing the visual hull of a three-dimensional object from occluding contours observed in 2D images. The method exploits the differential structure of the manifold rather than parallax geometry, and therefore requires no correspondences. We begin by observing that the set of 2D contour tangents determines a surface in a dual space where each point represents a tangent plane to the original surface. The primal and dual surfaces have a symmetric algebra: A point on one is orthogonal to its dual point and tangent basis on the other. Thus the primal surface can be reconstructed if the local dual tangent basis can be estimated. Typically this is impossible because the dual surface is noisy and riddled with tangent singularities due to self-crossings. We identify a directionally-indexed local tangent basis that is well-defined and estimable everywhere on the dual surface. The estimation procedure handles singularities in the dual surface and degeneracies arising from measurement noise. The resulting method has O(N) complexity for N observed contour points and gives asymptotically exact reconstructions of surfaces that are totally observable from occluding contours.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> algebra, computational complexity, computational geometry, differential geometry, image reconstruction 2D contour tangents, O(N) complexity, algebraic dual space method, algebraic solution, directionally indexed local tangent basis, image reconstruction, measurement noise, occluding contours, parallax geometry, symmetric algebra, three dimensional object, visual hull reconstruction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Slyper2008</b:Tag>
<b:Title>Action Capture with Accelerometers</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Slyper</b:Last>
<b:First>Ronit</b:First>
</b:Person>
<b:Person>
<b:Last>Hodgins</b:Last>
<b:First>Jessica</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>2008 ACM SIGGRAPH / Eurographics Symposium on Computer Animation</b:BookTitle>
<b:ConferenceName>2008 ACM SIGGRAPH / Eurographics Symposium on Computer Animation</b:ConferenceName>
<b:Month>#jul#</b:Month>
<b:BIBTEX_Abstract>We create a performance animation system that leverages the power of low-cost accelerometers, readily available motion capture databases, and construction techniques from e-textiles. Our system, built with only off-the-shelf parts, consists of five accelerometers sewn into a comfortable shirt that streams data to a computer. The accelerometer readings are continuously matched against accelerations computed from existing motion capture data, and an avatar is animated with the closest match. We evaluate our system visually and using simultaneous motion and accelerometer capture.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Report</b:SourceType>
<b:BIBTEX_Entry>phdthesis</b:BIBTEX_Entry>
<b:Tag>KryPhd05</b:Tag>
<b:Title>Interaction Capture and Synthesis of Human Hands</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Kry</b:Last>
<b:Middle>G.</b:Middle>
<b:First>Paul</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Department>University of British Columbia</b:Department>
<b:ThesisType>Ph.D. dissertation</b:ThesisType>
<b:BIBTEX_Abstract>This thesis addresses several issues in modelling interaction with human hands in computer graphics and animation. Modifying motion capture to satisfy the constraints of new animation is difficult when contact is involved because physical interaction involves energy or power transfer between the system of interest and the environment, and is a critical problem for computer animation of hands. Although contact force measurements provide a means of monitoring this transfer, motion capture as currently used for creating animation has largely ignored contact forces. We present a system of capturing synchronized motion and contact forces, called interaction capture. We transform interactions such as grasping into joint compliances and a nominal reference trajectory in an approach inspired by the equilibrium point hypothesis of human motor control. New interactions are synthesized through simulation of a quasi-static compliant articulated model in a dynamic environment that includes friction. This uses a novel position-based linear complementarity problem formulation that includes friction, breaking contact, and coupled compliance between contacts at different fingers. We present methods for reliable interaction capture, addressing calibration, force estimation, and synchronization. Additionally, although joint compliances are traditionally estimated with perturbation-based methods, we introduce a technique that instead produces estimates without perturbation. We validate our results with data from previous work and our own perturbation-based estimates. A complementary goal of this work is hand-based interaction in virtual environments. We present techniques for whole-hand interaction using the Tango, a novel sensor that performs interaction capture by measuring pressure images and accelerations. We approximate grasp hand-shapes from previously observed data through rotationally invariant comparison of pressure measurements. We also introduce methods involving heuristics and thresholds that make reliable drift-free navigation possible with the Tango. Lastly, rendering the skin deformations of articulated characters is a fundamental problem for computer animation of hands. We present a deformation model, called EigenSkin, which provides a means of rendering physically- or example-based deformation models at interactive rates on graphics hardware.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Boehnen2009</b:Tag>
<b:Title>3D Signatures for Fast 3D Face Recognition</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Boehnen</b:Last>
<b:First>Chris</b:First>
</b:Person>
<b:Person>
<b:Last>Peters</b:Last>
<b:First>Tanya</b:First>
</b:Person>
<b:Person>
<b:Last>Flynn</b:Last>
<b:First>Patrick</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>Proceedings of International Conference on Biometrics (ICB) 2009</b:BookTitle>
<b:ConferenceName>Proceedings of International Conference on Biometrics (ICB) 2009</b:ConferenceName>
<b:BIBTEX_Abstract>We propose a vector representation (called a 3D signature) for 3D face shape in biometrics applications. Elements of the vector correspond to fixed surface points in a face-centered coordinate system. Since the elements are registered to the face comparisons of vectors to produce match scores can be performed without a probe to gallery alignment step such as an invocation of the iterated closest point (ICPalgorithm in the calculation of each match score. The proposed 3D face recognition method employing the 3D signature ran more than three orders of magnitude faster than a traditional ICP based distance implementation, without sacrificing accuracy. As a result, it is feasible to apply distance based 3D face biometrics to recognition scenarios that, because of computational constraints, may have previously been limited to verification. Our use of more complex shape regions, which is a trivial task with the use of 3D signatures, improves biometric performance over simple spherical cut regions used previously [1]. Experimental results with a large database of 3D images demonstrate the technique and its advantages.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Levet2007</b:Tag>
<b:Title>Improved skeleton extraction and surface generation for sketch-based modeling</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Levet</b:Last>
<b:First>Florian</b:First>
</b:Person>
<b:Person>
<b:Last>Granier</b:Last>
<b:First>Xavier</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>27-33</b:Pages>
<b:StandardNumber> ISBN: 978-1-56881-337-0 DOI: http://doi.acm.org/10.1145/1268517.1268524</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>GI '07: Proceedings of Graphics Interface 2007</b:BookTitle>
<b:ConferenceName>GI '07: Proceedings of Graphics Interface 2007</b:ConferenceName>
<b:BIBTEX_Abstract>For the generation of freeform models, sketching interfaces have raised an increasing interest due to their intuitive approach. It is now possible to infer a 3D model directly from a sketched curved. Unfortunately, a limit of current systems is the poor quality of the skeleton automatically extracted from this silhouette, leading to low quality meshes for the resulting objects.

In this paper, we present new solutions that improve the surface generation for sketch-based modeling systems. First, we propose a new algorithm that extracts a smoother skeleton compared to previous approaches. Then, we present a new sampling scheme for the creation of good-quality 3D mesh. Finally, we propose to use a profile curve composed of disconnected components in order to create models which genus is greater than 0.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Surazhsky2005</b:Tag>
<b:Title>Fast exact and approximate geodesics on meshes</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Surazhsky</b:Last>
<b:First>Vitaly</b:First>
</b:Person>
<b:Person>
<b:Last>Surazhsky</b:Last>
<b:First>Tatiana</b:First>
</b:Person>
<b:Person>
<b:Last>Kirsanov</b:Last>
<b:First>Danil</b:First>
</b:Person>
<b:Person>
<b:Last>Gortler</b:Last>
<b:Middle>J.</b:Middle>
<b:First>Steven</b:First>
</b:Person>
<b:Person>
<b:Last>Hoppe</b:Last>
<b:First>Hugues</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>553-560</b:Pages>
<b:Volume>24</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/1073204.1073228</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>The computation of geodesic paths and distances on triangle meshes is a common operation in many computer graphics applications. We present several practical algorithms for computing such geodesics from a source point to one or all other points efficiently. First, we describe an implementation of the exact "single source, all destination" algorithm presented by Mitchell, Mount, and Papadimitriou (MMP). We show that the algorithm runs much faster in practice than suggested by worst case analysis. Next, we extend the algorithm with a merging operation to obtain computationally efficient and accurate approximations with bounded error. Finally, to compute the shortest path between two given points, we use a lower-bound property of our approximate geodesic algorithm to efficiently prune the frontier of the MMP algorithm. thereby obtaining an exact solution even more quickly.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Chai2005</b:Tag>
<b:Title>Performance animation from low-dimensional control signals</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Chai</b:Last>
<b:First>Jinxiang</b:First>
</b:Person>
<b:Person>
<b:Last>Hodgins</b:Last>
<b:Middle>K.</b:Middle>
<b:First>Jessica</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>686-696</b:Pages>
<b:Volume>24</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/1073204.1073248</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>This paper introduces an approach to performance animation that employs video cameras and a small set of retro-reflective markers to create a low-cost, easy-to-use system that might someday be practical for home use. The low-dimensional control signals from the user's performance are supplemented by a database of pre-recorded human motion. At run time, the system automatically learns a series of local models from a set of motion capture examples that are a close match to the marker locations captured by the cameras. These local models are then used to reconstruct the motion of the user as a full-body animation. We demonstrate the power of this approach with real-time control of six different behaviors using two video cameras and a small set of retro-reflective markers. We compare the resulting animation to animation from commercial motion capture equipment with a full set of markers.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Cornea2007</b:Tag>
<b:Title>Curve-Skeleton Properties, Applications, and Algorithms</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cornea</b:Last>
<b:Middle>D.</b:Middle>
<b:First>Nicu</b:First>
</b:Person>
<b:Person>
<b:Last>Min</b:Last>
<b:First>Patrick</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>530-548</b:Pages>
<b:Volume>13</b:Volume>
<b:StandardNumber> ISSN: 1077-2626 DOI: http://dx.doi.org/10.1109/TVCG.2007.1002</b:StandardNumber>
<b:Publisher>IEEE Educational Activities Department</b:Publisher>
<b:City>Piscataway, NJ, USA</b:City>
<b:JournalName>IEEE Transactions on Visualization and Computer Graphics</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>Curve-skeletons are thinned 1D representations of 3D objects useful for many visualization tasks including virtual
navigation, reduced-model formulation, visualization improvement, animation, etc. There are many algorithms in the literature
describing extraction methodologies for different applications; however, it is unclear how general and robust they are. In this paper, we
provide an overview of many curve-skeleton applications and compile a set of desired properties of such representations. We also give
a taxonomy of methods and analyze the advantages and drawbacks of each class of algorithms</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Xu2004</b:Tag>
<b:Title>Discrete Laplace-Beltrami operators and their convergence</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Xu</b:Last>
<b:First>Guoliang</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>767-784</b:Pages>
<b:Volume>21</b:Volume>
<b:StandardNumber> ISSN: 0167-8396 DOI: http://dx.doi.org/10.1016/j.cagd.2004.07.007</b:StandardNumber>
<b:Publisher>Elsevier Science Publishers B. V.</b:Publisher>
<b:City>Amsterdam, The Netherlands, The Netherlands</b:City>
<b:JournalName>Comput. Aided Geom. Des.</b:JournalName>
<b:Issue>8</b:Issue>
<b:BIBTEX_Abstract>The convergence property of the discrete Laplace–Beltrami operators is the foundation of convergence analysis of the numerical simulation process of some geometric partial differential equations which involve the operator. In this paper we propose several simple discretization schemes of Laplace–Beltrami operators over triangulated surfaces. Convergence results for these discrete Laplace–Beltrami operators are established under various conditions. Numerical results that support the theoretical analysis are given. Application examples of the proposed discrete Laplace–Beltrami operators in surface processing and modelling are also presented</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Turaga2009</b:Tag>
<b:Title>Unsupervised view and rate invariant clustering of video sequences</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Turaga</b:Last>
<b:First>Pavan</b:First>
</b:Person>
<b:Person>
<b:Last>Veeraraghavan</b:Last>
<b:First>Ashok</b:First>
</b:Person>
<b:Person>
<b:Last>Chellappa</b:Last>
<b:First>Rama</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>353-371</b:Pages>
<b:Volume>113</b:Volume>
<b:StandardNumber> ISSN: 1077-3142 DOI: http://dx.doi.org/10.1016/j.cviu.2008.08.009</b:StandardNumber>
<b:Publisher>Elsevier Science Inc.</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>Comput. Vis. Image Underst.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>Videos play an ever increasing role in our everyday lives with applications ranging from news, entertainment, scientific research, security and surveillance. Coupled with the fact that cameras and storage media are becoming less expensive, it has resulted in people producing more video content than ever before. This necessitates the development of efficient indexing and retrieval algorithms for video data. Most state-of-the-art techniques index videos according to the global content in the scene such as color, texture, brightness, etc. In this paper, we discuss the problem of activity-based indexing of videos. To address the problem, first we describe activities as a cascade of dynamical systems which significantly enhances the expressive power of the model while retaining many of the computational advantages of using dynamical models. Second, we also derive methods to incorporate view and rate-invariance into these models so that similar actions are clustered together irrespective of the viewpoint or the rate of execution of the activity. We also derive algorithms to learn the model parameters from a video stream and demonstrate how a single video sequence may be clustered into different clusters where each cluster represents an activity. Experimental results for five different databases show that the clusters found by the algorithm correspond to semantically meaningful activities.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>She2009</b:Tag>
<b:Title>Improved 3D Thinning Algorithms for Skeleton Extraction</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>She</b:Last>
<b:First>F.H.</b:First>
</b:Person>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>R.H.</b:First>
</b:Person>
<b:Person>
<b:Last>Gao</b:Last>
<b:First>W.M.</b:First>
</b:Person>
<b:Person>
<b:Last>Hodgson</b:Last>
<b:First>P.H.</b:First>
</b:Person>
<b:Person>
<b:Last>Kong</b:Last>
<b:First>L.X.</b:First>
</b:Person>
<b:Person>
<b:Last>Hong</b:Last>
<b:First>H.Y.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>14-18</b:Pages>
<b:StandardNumber> DOI: 10.1109/DICTA.2009.13</b:StandardNumber>
<b:BookTitle>Digital Image Computing: Techniques and Applications, 2009. DICTA '09.</b:BookTitle>
<b:ConferenceName>Digital Image Computing: Techniques and Applications, 2009. DICTA '09.</b:ConferenceName>
<b:Month>dec.</b:Month>
<b:BIBTEX_Abstract>In this study, we focused on developing a novel 3D Thinning algorithm to extract one-voxel wide skeleton from various 3D objects aiming at preserving the topological information. The 3D Thinning algorithm was testified on computer-generated and real 3D reconstructed image sets acquired from TEMT and compared with other existing 3D Thinning algorithms. It is found that the algorithm has conserved medial axes and simultaneously topologies very well, demonstrating many advantages over the existing technologies. They are versatile, rigorous, efficient and rotation invariant.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>3D reconstructed image sets;3D thinning algorithms;TEMT;one-voxel wide skeleton;skeleton extraction;topological information;feature extraction;image reconstruction;image thinning;</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Laurentini2003</b:Tag>
<b:Title>The visual hull for understanding shapes from contours: a survey</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Laurentini</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> 25-28 vol.1</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> ISSN:   DOI: 10.1109/ISSPA.2003.1224631</b:StandardNumber>
<b:BookTitle>Signal Processing and Its Applications</b:BookTitle>
<b:JournalName>Signal Processing and Its Applications, 2003. Proceedings. Seventh International Symposium on</b:JournalName>
<b:ConferenceName>Signal Processing and Its Applications</b:ConferenceName>
<b:Month>July</b:Month>
<b:BIBTEX_Abstract> In several practical situations the only available information for recognizing or reconstructing 3D objects are the object contours. Some recent theoretical developments put on a firm ground understanding 3D shapes from silhouettes. In this paper we present survey of these developments, related to the geometric concept of visual hull.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> image recognition, image reconstruction, object recognition 3D object recognizing, 3D object reconstructing, 3D shape, object contour, silhouette, visual hull geometric concept</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>You2005</b:Tag>
<b:Title>Wavelet-Based Approach for Skeleton Extraction</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>You</b:Last>
<b:First>Xinge</b:First>
</b:Person>
<b:Person>
<b:Last>Fang</b:Last>
<b:First>Bin</b:First>
</b:Person>
<b:Person>
<b:Last>Tang</b:Last>
<b:Middle>Yan</b:Middle>
<b:First>Yuan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>228-233</b:Pages>
<b:StandardNumber> ISBN: 0-7695-2271-8-1 DOI: http://dx.doi.org/10.1109/ACVMOT.2005.125</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>WACV-MOTION '05: Proceedings of the Seventh IEEE Workshops on Application of Computer Vision (WACV/MOTION'05) - Volume 1</b:BookTitle>
<b:ConferenceName>WACV-MOTION '05: Proceedings of the Seventh IEEE Workshops on Application of Computer Vision (WACV/MOTION'05) - Volume 1</b:ConferenceName>
<b:BIBTEX_Abstract>We propose a novel wavelet-based approach to extract skeleton of ribbon-like shapes based on a new concept called Wavelet-based Local Modulus Maxima Symmetry (WLMMS). The development of the new approach benefits from the desirable properties of the constructed new wavelet function. Based on the proposed WLMMS, initial skeleton of the regular region of ribbon-like shape are computed. Special attention is given to development of a new amendment technique which is called interpolation compensation. It is used to to remove artifacts of the initial skeletons and compute the skeletons in the singular region of the shape. Experimental results show that the proposed approach is not only capable of extracting precisely the skeleton of the ribbon-like shape with the low computational cost, but also robust against noise. And the proposed algorithm is applicable to both binary and gray scale image, as most traditional methods fail to do.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Unal2007</b:Tag>
<b:Title>A Variational Approach to Problems in Calibration of Multiple Cameras</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Unal</b:Last>
<b:First>G.</b:First>
</b:Person>
<b:Person>
<b:Last>Yezzi</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Soatto</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Slabaugh</b:Last>
<b:First>G.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1322-1338</b:Pages>
<b:Volume>29</b:Volume>
<b:StandardNumber> ISSN: 0162-8828 DOI: 10.1109/TPAMI.2007.1035</b:StandardNumber>
<b:JournalName>Pattern Analysis and Machine Intelligence, IEEE Transactions on</b:JournalName>
<b:Issue>8</b:Issue>
<b:Month>Aug. </b:Month>
<b:BIBTEX_Abstract>This paper addresses the problem of calibrating camera parameters using variational methods. One problem addressed is the severe lens distortion in low-cost cameras. For many computer vision algorithms aiming at reconstructing reliable representations of 3D scenes, the camera distortion effects will lead to inaccurate 3D reconstructions and geometrical measurements if not accounted for. A second problem is the color calibration problem caused by variations in camera responses that result in different color measurements and affects the algorithms that depend on these measurements. We also address the extrinsic camera calibration that estimates relative poses and orientations of multiple cameras in the system and the intrinsic camera calibration that estimates focal lengths and the skew parameters of the cameras. To address these calibration problems, we present multiview stereo techniques based on variational methods that utilize partial and ordinary differential equations. Our approach can also be considered as a coordinated refinement of camera calibration parameters. To reduce computational complexity of such algorithms, we utilize prior knowledge on the calibration object, making a piecewise smooth surface assumption, and evolve the pose, orientation, and scale parameters of such a 3D model object without requiring a 2D feature extraction from camera views. We derive the evolution equations for the distortion coefficients, the color calibration parameters, the extrinsic and intrinsic parameters of the cameras, and present experimental results.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>calibration, cameras, computational complexity, computer vision, feature extraction, image colour analysis, image reconstruction, image representation, partial differential equations, pose estimation, stereo image processing, variational techniques3D scene, color calibration, computational complexity, computer vision, feature extraction, image reconstruction, image representation, lens distortion, multiple camera calibration, multiview stereo technique, ordinary differential equation, partial differential equation, piecewise smooth surface assumption, pose estimation, variational method</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Schaefer2007</b:Tag>
<b:Title>Example-Based Skeleton Extraction</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Schaefer</b:Last>
<b:First>Scott</b:First>
</b:Person>
<b:Person>
<b:Last>Yuksel</b:Last>
<b:First>Can</b:First>
</b:Person>
</b:NameList>
</b:Author>
<b:Editor>
<b:NameList>
<b:Person>
<b:Last>Belyaev</b:Last>
<b:First>Alexander</b:First>
</b:Person>
<b:Person>
<b:Last>Garland</b:Last>
<b:First>Michael</b:First>
</b:Person>
</b:NameList>
</b:Editor>
</b:Author>
<b:Pages>153-162</b:Pages>
<b:StandardNumber> DOI: 10.2312/SGP/SGP07/153-162</b:StandardNumber>
<b:BookTitle>Geometry Processing</b:BookTitle>
<b:ConferenceName>Geometry Processing</b:ConferenceName>
<b:URL>http://www.eg.org/EG/DL/WS/SGP/SGP07/153-162.pdf</b:URL>
<b:BIBTEX_Abstract>We present a method for extracting a hierarchical, rigid skeleton from a set of example poses. We then use this skeleton to not only reproduce the example poses, but create new deformations in the same style as the examples. Since rigid skeletons are used by most 3D modeling software, this skeleton and the corresponding vertex weights can be inserted directly into existing production pipelines. To create the skeleton, we first estimate the rigid transformations of the bones using a fast, face clustering approach. We present an efficient method for clustering by providing a Rigid Error Function that finds the best rigid transformation from a set of points in a robust, space efficient manner and supports fast clustering operations. Next, we solve for the vertex weights and enforce locality in the resulting weight distributions. Finally, we use these weights to determine the connectivity and joint locations of the skeleton.</b:BIBTEX_Abstract>
<b:BIBTEX_CrossRef>SGP07-proc</b:BIBTEX_CrossRef>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>4178157</b:Tag>
<b:Title>Surface Capture for Performance-Based Animation</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Starck</b:Last>
<b:First>Jonathan</b:First>
</b:Person>
<b:Person>
<b:Last>Hilton</b:Last>
<b:First>Adrian</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>21-31</b:Pages>
<b:Volume>27</b:Volume>
<b:StandardNumber> ISSN: 0272-1716 DOI: 10.1109/MCG.2007.68</b:StandardNumber>
<b:JournalName>Computer Graphics and Applications, IEEE</b:JournalName>
<b:Issue>3</b:Issue>
<b:Month>May-June </b:Month>
<b:BIBTEX_Abstract>Creating realistic animated models of people is a central task in digital content production. Traditionally, highly skilled artists and animators construct shape and appearance models for digital character. They then define the character's motion at each time frame or specific key-frames in a motion sequence to create a digital performance. Increasingly, producers are using motion capture technology to record animations from an actor's performance. This technology reduces animation production time and captures natural movements to create a more believable production. However, motion capture requires the use of specialist suits and markers and only records skeletal motion. It lacks the detailed secondary surface dynamics of cloth and hair that provide the visual realism of a live performance. Over the last decade, we have investigated studio capture technology with the objective of creating models of real people that accurately reflect the time-varying shape and appearance of the whole body with clothing. Surface capture is a fully automated system for capturing a human's shape and appearance as well as motion from multiple video cameras to create highly realistic animated content from an actor's performance in full wardrobe. Our system solves two key problems in performance capture: scene capture from a limited number of camera views and efficient scene representation for visualization</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computer animation, data visualisation, image motion analysis, image sequences, realistic images, video camerasdata visualization, digital content production, motion sequence, multiple video cameras, realistic animated model, skeletal motion, surface capture</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Aguiar2008a</b:Tag>
<b:Title>Automatic Conversion of Mesh Animations into Skeleton-based Animations</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>E.</b:First>
</b:Person>
<b:Person>
<b:Last>Theobalt</b:Last>
<b:First>C.</b:First>
</b:Person>
<b:Person>
<b:Last>Thrun</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>H.-P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>xx--xx</b:Pages>
<b:Volume>27</b:Volume>
<b:City>Hersonissos, Crete, Greece</b:City>
<b:BookTitle>COMPUTER GRAPHICS FORUM</b:BookTitle>
<b:JournalName>Computer Graphics Forum (Proc. Eurographics EG'08)</b:JournalName>
<b:Issue>2</b:Issue>
<b:ConferenceName>COMPUTER GRAPHICS FORUM</b:ConferenceName>
<b:Month>4</b:Month>
<b:BIBTEX_Abstract>Recently, it has become increasingly popular to represent animations not by means of a classical skeleton-based model, but in the form of deforming mesh sequences. The reason for this new trend is that novel mesh deformation methods as well as new surface based scene capture techniques offer a great level of flexibility during animation creation. Unfortunately, the resulting scene representation is less compact than skeletal ones and there is not yet a rich toolbox available which enables easy post-processing and modification of mesh animations. To bridge this gap between the mesh-based and the skeletal paradigm, we propose a new method that automatically extracts a plausible kinematic skeleton, skeletal motion parameters, as well as surface skinning weights from arbitrary mesh animations. By this means, deforming mesh sequences can be fully-automatically transformed into fullyrigged virtual subjects. The original input can then be quickly rendered based on the new compact bone and skin representation, and it can be easily modified using the full repertoire of already existing animation tools.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>AitAider2006</b:Tag>
<b:Title>Simultaneous Object Pose and Velocity Computation Using a Single View from a Rolling Shutter Camera</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Ait Aider</b:Last>
<b:First>O.</b:First>
</b:Person>
<b:Person>
<b:Last>Andreff</b:Last>
<b:First>N.</b:First>
</b:Person>
<b:Person>
<b:Last>Lavest</b:Last>
<b:First>J.M.</b:First>
</b:Person>
<b:Person>
<b:Last>Martinet</b:Last>
<b:First>P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>II: 56-68</b:Pages>
<b:BookTitle>#ECCV06#</b:BookTitle>
<b:ConferenceName>#ECCV06#</b:ConferenceName>
<b:BIBTEX_Abstract>An original method for computing instantaneous 3D pose and velocity of fast moving objects using a single view is presented. It exploits image deformations induced by rolling shutter in CMOS image sensors. First of all, a general perspective projection model of a moving 3D point is presented. A solution for the pose and velocity recovery problem is then described. The method is based on bundle adjustment and uses point correspondences. The resulting algorithm enables to transform a CMOS low cost and low power camera into an original velocity sensor. Finally, experimental results with real data confirm the relevance of the approach.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Shin2008</b:Tag>
<b:Title>Local Hull-Based Surface Construction of Volumetric Data From Silhouettes</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Shin</b:Last>
<b:First>Dongjoe</b:First>
</b:Person>
<b:Person>
<b:Last>Tjahjadi</b:Last>
<b:First>T.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1251-1260</b:Pages>
<b:Volume>17</b:Volume>
<b:StandardNumber> ISSN: 1057-7149 DOI: 10.1109/TIP.2008.926149</b:StandardNumber>
<b:JournalName>Image Processing, IEEE Transactions on</b:JournalName>
<b:Issue>8</b:Issue>
<b:Month>Aug. </b:Month>
<b:BIBTEX_Abstract>The marching cubes (MC) is a general method which can construct a surface of an object from its volumetric data generated using a shape from silhouette method. Although MC is efficient and straightforward to implement, a MC surface may have discontinuity even though the volumetric data is continuous. This is because surface construction is more sensitive to image noise than the construction of volumetric data. To address this problem, we propose a surface construction algorithm which aggregates local surfaces constructed by the 3-D convex hull algorithm. Thus, the proposed method initially classifies local convexities from imperfect MC vertices based on sliced volumetric data. Experimental results show that continuous surfaces are obtained from imperfect silhouette images of both convex and nonconvex objects.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image denoising, image reconstruction3D convex hull algorithm, image noise, local hull-based surface construction, marching cubes, silhouette method, volumetric data</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Curless1996</b:Tag>
<b:Title>A volumetric method for building complex models from range images</b:Title>
<b:Year>1996</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Curless</b:Last>
<b:First>Brian</b:First>
</b:Person>
<b:Person>
<b:Last>Levoy</b:Last>
<b:First>Marc</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>303-312</b:Pages>
<b:StandardNumber> ISBN: 0-89791-746-4 DOI: http://doi.acm.org/10.1145/237170.237269</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '96: Proceedings of the 23rd annual conference on Computer graphics and interactive techniques</b:BookTitle>
<b:ConferenceName>SIGGRAPH '96: Proceedings of the 23rd annual conference on Computer graphics and interactive techniques</b:ConferenceName>
<b:BIBTEX_Abstract>A number of techniques have been developed for reconstructing surfaces by integrating groups of aligned range images. A desirable set of properties for such algorithms includes: incremental updating, representation of directional uncertainty, the ability to fill gaps in the reconstruction, and robustness in the presence of outliers. Prior algorithms possess subsets of these properties. In this paper, we present a volumetric method for integrating range images that possesses all of these properties.

Our volumetric representation consists of a cumulative weighted signed distance function. Working with one range image at a time, we first scan-convert it to a distance function, then combine this with the data already acquired using a simple additive scheme. To achieve space efficiency, we employ a run-length encoding of the volume. To achieve time efficiency, we resample the range image to align with the voxel grid and traverse the range and voxel scanlines synchronously. We generate the final manifold by extracting an isosurface from the volumetric grid. We show that under certain assumptions, this isosurface is optimal in the least squares sense. To fill gaps in the model, we tessellate over the boundaries between regions seen to be empty and regions never observed.

Using this method, we are able to integrate a large number of range images (as many as 70) yielding seamless, high-detail models of up to 2.6 million triangles.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Shalom2008</b:Tag>
<b:Title>Part Analogies in Sets of Objects</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Shalom</b:Last>
<b:First>Shy</b:First>
</b:Person>
<b:Person>
<b:Last>Shapira</b:Last>
<b:First>Lior</b:First>
</b:Person>
<b:Person>
<b:Last>Shamir</b:Last>
<b:First>Ariel</b:First>
</b:Person>
<b:Person>
<b:Last>Cohen-Or</b:Last>
<b:First>Daniel</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>Eurographics Workshop on 3D Object Retrieval ‘08</b:BookTitle>
<b:ConferenceName>Eurographics Workshop on 3D Object Retrieval ‘08</b:ConferenceName>
<b:BIBTEX_Abstract>Shape retrieval can benefit from analogies among similar shapes and parts of different objects. By partitioning an object to meaningful parts and finding analogous parts in other objects, sub-parts and partial match queries can be utilized. First by searching for similar parts in the context of their shape, and second by finding similarities even among objects that differ in their general shape and topology. Moreover, analogies can create the basis for semantic text-based searches: for instance, in this paper we demonstrate a simple annotation tool that carries tags of object parts from one model to many others using analogies. We partition 3D objects based on the shape-diameter function (SDF), and use it to find corresponding parts in other objects. We present results on finding analogies among numerous objects from shape repositories, and demonstrate sub-part queries using an implementation of a simple search and retrieval application.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Ishikawa2005</b:Tag>
<b:Title>Real-time generation of novel views of a dynamic scene using morphing and visual hull</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Ishikawa</b:Last>
<b:First>T.</b:First>
</b:Person>
<b:Person>
<b:Last>Yamazawa</b:Last>
<b:First>K.</b:First>
</b:Person>
<b:Person>
<b:Last>Yokoya</b:Last>
<b:First>N.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> I-1013-16</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> DOI: 10.1109/ICIP.2005.1529925</b:StandardNumber>
<b:BookTitle>Image Processing</b:BookTitle>
<b:JournalName>Image Processing, 2005. ICIP 2005. IEEE International Conference on</b:JournalName>
<b:ConferenceName>Image Processing</b:ConferenceName>
<b:Month>Sept.</b:Month>
<b:BIBTEX_Abstract>Recently, generation of novel views from images acquired by multiple cameras has been investigated. It can be applied to telepresence effectively. Most conventional methods need some assumptions about the scene such as a static scene and limited positions of objects. In this paper, we propose a new method for generating novel view images of a dynamic scene with a wide view, which does not depend on the scene. The images acquired from omni-directional cameras are first divided into static regions and dynamic regions. The novel view images are then generated by applying a morphing technique to static regions and by computing visual hulls for dynamic regions in real-time. In experiments, we show that a prototype system can generate novel view images in real-time from live video streams.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> cameras, image processing, video streaming dynamic scene, morphing technique, omnidirectional cameras, video streams, view images, visual hull</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Remondino2002</b:Tag>
<b:Title>Human Body Reconstruction from Image Sequences</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Remondino</b:Last>
<b:First>Fabio</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>50-57</b:Pages>
<b:Publisher>Springer</b:Publisher>
<b:BookTitle>Pattern Recognition (DAGM 2002), Lecture Notes in Computer Science 2449</b:BookTitle>
<b:ConferenceName>Pattern Recognition (DAGM 2002), Lecture Notes in Computer Science 2449</b:ConferenceName>
<b:BIBTEX_Abstract>The generation of 3-D models from uncalibrated sequences is a challenging problem that has been investigated in many research activities in the last decade. In particular, a topic of great interest is the modeling of real humans. In this paper a method for the 3-D reconstruction of static human body shapes from images acquired with a video-camera is presented. The process includes the orientation and calibration of the sequence, the extraction of correspondences on the body using least squares matching technique and the reconstruction of the 3-D point cloud of the human body.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>starck06volumetric</b:Tag>
<b:Title>Volumetric stereo with silhouette and feature constraints</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Starck</b:Last>
<b:First>J.</b:First>
</b:Person>
<b:Person>
<b:Last>Hilton</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Miller</b:Last>
<b:First>G.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>British Machine Vision Conference</b:BookTitle>
<b:ConferenceName>British Machine Vision Conference</b:ConferenceName>
<b:Month>September</b:Month>
<b:BIBTEX_Abstract>This paper presents a novel volumetric reconstruction technique that combines shape-from-silhouette with stereo photo-consistency in a global optimisation that enforces feature constraints across multiple views. Human
shape reconstruction is considered where extended regions of uniform appearance, complex self-occlusions and sparse feature cues represent a challenging problem for conventional reconstruction techniques. A uni?ed approach is introduced to ?rst reconstruct the occluding contours and left-right consistent edge contours in a scene and then incorporate these contour constraints in a global surface optimisation using graph-cuts. The proposed technique maximises photo-consistency on the surface, while satisfying silhouette constraints to provide shape in the presence of uniform surface appearance and edge feature constraints to align key image features across views.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>3d, graphcut</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Tagliasacchi2009</b:Tag>
<b:Title>Curve skeleton extraction from incomplete point cloud</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tagliasacchi</b:Last>
<b:First>Andrea</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Hao</b:First>
</b:Person>
<b:Person>
<b:Last>Cohen-Or</b:Last>
<b:First>Daniel</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-9</b:Pages>
<b:Volume>28</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/1531326.1531377</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>We present an algorithm for curve skeleton extraction from imperfect point clouds where large portions of the data may be missing. Our construction is primarily based on a novel notion of generalized rotational symmetry axis (ROSA) of an oriented point set. Specifically, given a subset S of oriented points, we introduce a variational definition for an oriented point that is most rotationally symmetric with respect to S. Our formulation effectively utilizes normal information to compensate for the missing data and leads to robust curve skeleton computation over regions of a shape that are generally cylindrical. We present an iterative algorithm via planar cuts to compute the ROSA of a point cloud. This is complemented by special handling of non-cylindrical joint regions to obtain a centered, topologically clean, and complete 1D skeleton. We demonstrate that quality curve skeletons can be extracted from a variety of shapes captured by incomplete point clouds. Finally, we show how our algorithm assists in shape completion under these challenges by developing a skeleton-driven point cloud completion scheme.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Alexa2002</b:Tag>
<b:Title>Wiener Filtering of Meshes</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Alexa</b:Last>
<b:First>Marc</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>51--</b:Pages>
<b:StandardNumber> ISBN: 0-7695-1546-0</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>Proceedings of the Shape Modeling International 2002 (SMI'02)</b:BookTitle>
<b:ConferenceName>Proceedings of the Shape Modeling International 2002 (SMI'02)</b:ConferenceName>
<b:URL>http://dl.acm.org/citation.cfm?id=882487.884142</b:URL>
<b:BIBTEX_Abstract>This work investigates smoothing, fairing, or, more generally,filtering of mesh geometry.The approach transfersthe ideas of optimal (Wiener) filtering to the setting ofmeshes.It extends fairing approaches that use only firstorder neighborhoods and allows to assume arbitrary localspectral properties of the mesh geometry.The definitionof the local autocorrelation allows the design of filters forsmoothing as well as for special effects in shape modeling.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Mesh, Smoothing, Fairing, Wiener filter</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Sundareswara2005</b:Tag>
<b:Title>Bayesian modelling of camera calibration and reconstruction</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Sundareswara</b:Last>
<b:First>Rashmi</b:First>
</b:Person>
<b:Person>
<b:Last>Schrater</b:Last>
<b:First>P.R.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>394-401</b:Pages>
<b:StandardNumber> ISSN: 1550-6185  DOI: 10.1109/3DIM.2005.24</b:StandardNumber>
<b:BookTitle>3-D Digital Imaging and Modeling, 2005. 3DIM 2005. Fifth International Conference on</b:BookTitle>
<b:ConferenceName>3-D Digital Imaging and Modeling, 2005. 3DIM 2005. Fifth International Conference on</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract> Camera calibration methods, whether implicit or explicit, are a critical part of most 3D vision systems. These methods involve estimation of a model for the camera that produced the visual input, and subsequently to infer the 3D structure that gave rise to the input. However, in these systems the error in calibration is typically unknown, or if known, the effect of calibration error on subsequent processing (e.g. 3D reconstruction) is not accounted for. In this paper, we propose a Bayesian camera calibration method that explicitly computes calibration error, and we show how knowledge of this error can be used to improve the accuracy of subsequent processing. What distinguishes the work is the explicit computation of a posterior distribution on unknown camera parameters, rather than just a best estimate. Marginalizing (averaging) subsequent estimates by this posterior is shown to reduce reconstruction error over calibration approaches that rely on a single best estimate. The method is made practical using sampling techniques, that require only the evaluation of the calibration error function and the specification of priors. Samples with their corresponding probability weights can be used to produce better estimates of the camera parameters. Moreover, these samples can be directly used to improve estimates that rely on calibration information, like 3D reconstruction. We evaluate our method using simulated data for a structure from motion problem, in which the same point matches are used to calibrate the camera, estimate the motion, and reconstruct the 3D geometry. Our results show improved reconstruction over non-linear Camera calibration methods like the Maximum Likelihood estimate. Additionally, this approach scales much better in the face of increasingly noisy point matches.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> Bayes methods, belief networks, calibration, cameras, computational geometry, image reconstruction, maximum likelihood estimation, motion estimation, solid modelling Bayesian modelling, calibration error, camera calibration, image reconstruction, maximum likelihood estimation, motion estimation, noisy point matches</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Zheng2010</b:Tag>
<b:Title>Consensus Skeleton for Non-Rigid Space-Time Registration</b:Title>
<b:Year>2010</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Zheng</b:Last>
<b:First>Qian</b:First>
</b:Person>
<b:Person>
<b:Last>Sharf</b:Last>
<b:First>Andrei</b:First>
</b:Person>
<b:Person>
<b:Last>Tagliasacchi</b:Last>
<b:First>Andrea</b:First>
</b:Person>
<b:Person>
<b:Last>Chen</b:Last>
<b:First>Baoquan</b:First>
</b:Person>
<b:Person>
<b:Last>Zhang</b:Last>
<b:First>Hao</b:First>
</b:Person>
<b:Person>
<b:Last>Sheffer</b:Last>
<b:First>Alla</b:First>
</b:Person>
<b:Person>
<b:Last>Cohen-Or</b:Last>
<b:First>Daniel</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>to appear</b:Pages>
<b:Volume>29</b:Volume>
<b:JournalName>Computer Graphcis Forum (Special Issue of Eurographics)</b:JournalName>
<b:Issue>2</b:Issue>
<b:BIBTEX_Abstract>We introduce the notion of consensus skeletons for non-rigid space-time registration of a deforming shape. Instead of basing the registration on point features, which are local and sensitive to noise, we adopt the curve skeleton of the shape as a global and descriptive feature for the task. Our method uses no template and only assumes that the skeletal structure of the captured shape remains largely consistent over time. Such an assumption is generally weaker than those relying on large overlap of point features between successive frames, allowing for more sparse acquisition across time. Building our registration framework on top of the low-dimensional skeletontime structure avoids heavy processing of dense point or volumetric data, while skeleton consensusization provides robust handling of incompatibilities between per-frame skeletons. To register point clouds from all frames, we deform them by their skeletons, mirroring the skeleton registration process, to jump-start a non-rigid ICP. We present results for non-rigid space-time registration under sparse and noisy spatio-temporal sampling, including cases where data was captured from only a single view.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Aguiar2007</b:Tag>
<b:Title>Marker-less Deformable Mesh Tracking for Human Shape and Motion Capture</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>E.</b:First>
</b:Person>
<b:Person>
<b:Last>Theobalt</b:Last>
<b:First>C.</b:First>
</b:Person>
<b:Person>
<b:Last>Stoll</b:Last>
<b:First>C.</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:Middle>P.</b:Middle>
<b:First>H.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:StandardNumber> DOI: http://dx.doi.org/10.1109/CVPR.2007.383296</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on</b:ConferenceName>
<b:URL>http://dx.doi.org/10.1109/CVPR.2007.383296</b:URL>
<b:BIBTEX_Abstract>We present a novel algorithm to jointly capture the motion and the dynamic shape of humans from multiple video streams without using optical markers. Instead of relying on kinematic skeletons, as traditional motion capture methods, our approach uses a deformable high-quality mesh of a human as scene representation. It jointly uses an image-based 3D correspondence estimation algorithm and a fast Laplacian mesh deformation scheme to capture both motion and surface deformation of the actor from the input video footage. As opposed to many related methods, our algorithm can track people wearing wide apparel, it can straightforwardly be applied to any type of subject, e.g. animals, and it preserves the connectivity of the mesh over time. We demonstrate the performance of our approach using synthetic and captured real-world video sequences and validate its accuracy by comparison to the ground truth.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>capture, cg</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Cheung2003a</b:Tag>
<b:Title>Visual hull alignment and refinement across time: a 3D reconstruction algorithm combining shape-from-silhouette with stereo</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cheung</b:Last>
<b:First>G.K.M.</b:First>
</b:Person>
<b:Person>
<b:Last>Baker</b:Last>
<b:First>S.</b:First>
</b:Person>
<b:Person>
<b:Last>Kanade</b:Last>
<b:First>T.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> II-375-82 vol.2</b:Pages>
<b:Volume>2</b:Volume>
<b:StandardNumber> ISSN: 1063-6919  DOI: 10.1109/CVPR.2003.1211493</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>Visual hull (VH) construction from silhouette images is a popular method of shape estimation. The method, also known as shape-from-silhouette (SFS), is used in many applications such as non-invasive 3D model acquisition, obstacle avoidance, and more recently human motion tracking and analysis. One of the limitations of SFS, however, is that the approximated shape can be very coarse when there are only a few cameras. In this paper, we propose an algorithm to improve the shape approximation by combining multiple silhouette images captured across time. The improvement is achieved by first estimating the rigid motion between the visual hulls formed at different time instants (visual hull alignment) and then combining them (visual hull refinement) to get a tighter bound on the object's shape. Our algorithm first constructs a representation of the VHs called the bounding edge representation. Utilizing a fundamental property of visual hulls, which states that each bounding edge must touch the object at at least one point, we use multi-view stereo to extract points called colored surface points (CSP) on the surface of the object. These CSPs are then used in a 3D image alignment algorithm to find the 6 DOF rigid motion between two visual hulls. Once the rigid motion across time is known, all of the silhouette images are treated as being captured at the same time instant and the shape of the object is refined. We validate our algorithm on both synthetic and real data and compare it with space carving.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> computer vision, edge detection, image colour analysis, image reconstruction, motion estimation, object detection, stereo image processing 3D image alignment algorithm, 3D reconstruction algorithm, 6 DOF rigid motion, algorithm validation, bounding edge representation, camera, colored surface points, computer vision, human motion tracking, motion analysis, multiview stereo, noninvasive 3D model acquisition, object shape, object surface, obstacle avoidance, real data, rigid motion estimation, shape approximation, shape estimation, shape-from-silhouette, silhouette image, space carving, stereo image, synthetic data, time instant, visual hull alignment, visual hull refinement</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Park2002a</b:Tag>
<b:Title>Shape Decomposition and Skeleton Extraction of Character Patterns</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Park</b:Last>
<b:First>Jeong-Sun</b:First>
</b:Person>
<b:Person>
<b:Last>Oh</b:Last>
<b:First>Il-Seok</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>30411</b:Pages>
<b:StandardNumber> ISBN: 0-7695-1695-X</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:BookTitle>ICPR '02: Proceedings of the 16 th International Conference on Pattern Recognition (ICPR'02) Volume 3</b:BookTitle>
<b:ConferenceName>ICPR '02: Proceedings of the 16 th International Conference on Pattern Recognition (ICPR'02) Volume 3</b:ConferenceName>
<b:BIBTEX_Abstract>This paper proposes an approach to extract skeletons from the character patterns. It first decomposes the pattern into a set of near-convex parts and then extracts skeletons from the parts. In shape decomposition stage, the convex hull information is used to identify the splitting paths. For the skeleton extraction, an operation that ties the adjacent strokes by a knot is developed. Our control procedure processes a variety of different situations of the adjacentstrokes in a systematic way.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Report</b:SourceType>
<b:BIBTEX_Entry>phdthesis</b:BIBTEX_Entry>
<b:Tag>Tierny2008b</b:Tag>
<b:Title>Reeb graph based 3D shape modeling and applications</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tierny</b:Last>
<b:First>Julien</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Department>Universite des Sciences et Technologies de Lille</b:Department>
<b:ThesisType>Ph.D. dissertation</b:ThesisType>
<b:BIBTEX_Abstract>With the ongoing development of 3D technologies, 3D shapes are becoming an interactive media of major importance. Their commonest representation, the surface mesh, suffers however from high variability towards standard shape-preserving surface transformations.It is necessary thus to design intrinsic shape modeling techniques.
In this thesis, we explore topological modeling by studying Reeb graph based structures. In particular, we introduce a novel shape abstraction, called the enhanced topological skeleton, which enables not only the study of the topological evolution of Morse functions' level sets but also that of their geometrical evolution. We show the utility of this intrinsic shape representation in three research problems related to Computer Graphics and Computer Vision.
First, we introduce the notion of geometrical calculus on Reeb graphs for the stable and automatic computation of control skeletons for interactive shape handling.
Then, by introducing the notions of Reeb chart and Reeb pattern, we propose a new method for partial 3D shape similarity estimation. We show this approach outperforms the competing methods of the international SHape REtrieval Contest 2007 by a gain of 14%.
Finally, we present two techniques for the functional decomposition computation of a 3D shape, both from human perception based heuristics and from the analysis of time-varying 3D data.
For each of these research problems, concrete applicative examples are presented to assess the utility of our approach.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Reniers2007</b:Tag>
<b:Title>Skeleton-based Hierarchical Shape Segmentation</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Reniers</b:Last>
<b:First>D.</b:First>
</b:Person>
<b:Person>
<b:Last>Telea</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>179-188</b:Pages>
<b:StandardNumber> DOI: 10.1109/SMI.2007.33</b:StandardNumber>
<b:BookTitle>Shape Modeling and Applications, 2007. SMI '07. IEEE International Conference on</b:BookTitle>
<b:ConferenceName>Shape Modeling and Applications, 2007. SMI '07. IEEE International Conference on</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>We present an effective framework for segmenting 3D shapes into meaningful components using the curve skeleton. Our algorithm identifies a number of critical points on the curve skeleton, either fully automatically as the junctions of the curve skeleton, or based on user input. We use these points to construct a partitioning of the object surface using geodesies. Because it is based on the curve skeleton, our segmentation intrinsically reflects the shape symmetry and topology. By using geodesies we obtain segments that have smooth, minimally twisting borders. Finally, we present a hierarchical segmentation of shapes which reflects the hierarchical structure of the curve skeleton. We describe a voxel-based implementation of our method which is robust and noise resistant, computationally efficient, able to handle shapes of complex topology, and which delivers level- of-detail segmentations. We demonstrate the framework on various real-world 3D shapes.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>curve fitting, surface fittingcurve skeleton-based hierarchical shape segmentation, object surface partitioning</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Aguiar2008</b:Tag>
<b:Title>Performance capture from sparse multi-view video</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>Edilson</b:First>
</b:Person>
<b:Person>
<b:Last>Stoll</b:Last>
<b:First>Carsten</b:First>
</b:Person>
<b:Person>
<b:Last>Theobalt</b:Last>
<b:First>Christian</b:First>
</b:Person>
<b:Person>
<b:Last>Ahmed</b:Last>
<b:First>Naveed</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>Hans-Peter</b:First>
</b:Person>
<b:Person>
<b:Last>Thrun</b:Last>
<b:First>Sebastian</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-10</b:Pages>
<b:StandardNumber> DOI: http://doi.acm.org/10.1145/1399504.1360697</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '08: ACM SIGGRAPH 2008 papers</b:BookTitle>
<b:ConferenceName>SIGGRAPH '08: ACM SIGGRAPH 2008 papers</b:ConferenceName>
<b:BIBTEX_Abstract>This paper proposes a new marker-less approach to capturing human performances from multi-view video. Our algorithm can jointly reconstruct spatio-temporally coherent geometry, motion and textural surface appearance of actors that perform complex and rapid moves. Furthermore, since our algorithm is purely meshbased and makes as few as possible prior assumptions about the type of subject being tracked, it can even capture performances of people wearing wide apparel, such as a dancer wearing a skirt. To serve this purpose our method efficiently and effectively combines the power of surface- and volume-based shape deformation techniques with a new mesh-based analysis-through-synthesis framework. This framework extracts motion constraints from video and makes the laser-scan of the tracked subject mimic the recorded performance. Also small-scale time-varying shape detail is recovered by applying model-guided multi-view stereo to refine the model surface. Our method delivers captured performance data at higher level of detail, is highly versatile, and is applicable to many complex types of scenes that could not be handled by alternative marker-based or marker-free recording techniques.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Gyulassy2007</b:Tag>
<b:Title>Topologically Clean Distance Fields</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Gyulassy</b:Last>
<b:First>A.G.</b:First>
</b:Person>
<b:Person>
<b:Last>Duchaineau</b:Last>
<b:First>M.A.</b:First>
</b:Person>
<b:Person>
<b:Last>Natarajan</b:Last>
<b:First>Vijay</b:First>
</b:Person>
<b:Person>
<b:Last>Pascucci</b:Last>
<b:First>V.</b:First>
</b:Person>
<b:Person>
<b:Last>Bringa</b:Last>
<b:First>E.M.</b:First>
</b:Person>
<b:Person>
<b:Last>Higginbotham</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Hamann</b:Last>
<b:First>B.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1432-1439</b:Pages>
<b:Volume>13</b:Volume>
<b:StandardNumber> ISSN: 1077-2626 DOI: 10.1109/TVCG.2007.70603</b:StandardNumber>
<b:JournalName>Visualization and Computer Graphics, IEEE Transactions on</b:JournalName>
<b:Issue>6</b:Issue>
<b:Month>Nov.-Dec. </b:Month>
<b:BIBTEX_Abstract>Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the "difference" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>computational geometry, curve fitting, topologyMS complex, Morse theory, curved skeleton representation, filament structures, porous solids, simulated porous solid, topologically clean distance fields, volumetric domain</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Cornea2005b</b:Tag>
<b:Title>3D object retrieval using many-to-many matching of curve skeletons</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cornea</b:Last>
<b:First>N.D.</b:First>
</b:Person>
<b:Person>
<b:Last>Demirci</b:Last>
<b:First>M.F.</b:First>
</b:Person>
<b:Person>
<b:Last>Silver</b:Last>
<b:First>D.</b:First>
</b:Person>
<b:Person>
<b:Last>Shokoufandeh</b:Last>
</b:Person>
<b:Person>
<b:Last>Dickinson</b:Last>
<b:First>S.J.</b:First>
</b:Person>
<b:Person>
<b:Last>Kantor</b:Last>
<b:First>P.B.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>366-371</b:Pages>
<b:StandardNumber> DOI: 10.1109/SMI.2005.1</b:StandardNumber>
<b:BookTitle>Shape Modeling and Applications, 2005 International Conference</b:BookTitle>
<b:ConferenceName>Shape Modeling and Applications, 2005 International Conference</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>We present a 3D matching framework based on a many-to-many matching algorithm that works with skeletal representations of 3D volumetric objects. We demonstrate the performance of this approach on a large database of 3D objects containing more than 1000 exemplars. The method is especially suited to matching objects with distinct part structure and is invariant to part articulation. Skeletal matching has an intuitive quality that helps in defining the search and visualizing the results. In particular, the matching algorithm produces a direct correspondence between two skeletons and their parts, which can be used for registration and juxtaposition.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> curve fitting, data visualisation, image matching, image registration, object recognition, very large databases 3D object retrieval, 3D volumetric objects, curve skeletons, large database, many-to-many matching, scientific visualization</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Oda2006</b:Tag>
<b:Title>Interactive skeleton extraction for 3D animation using geodesic distances</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Oda</b:Last>
<b:First>Takuya</b:First>
</b:Person>
<b:Person>
<b:Last>Itoh</b:Last>
<b:First>Yuichi</b:First>
</b:Person>
<b:Person>
<b:Last>Nakai</b:Last>
<b:First>Wataru</b:First>
</b:Person>
<b:Person>
<b:Last>Nomura</b:Last>
<b:First>Katsuhiro</b:First>
</b:Person>
<b:Person>
<b:Last>Kitamura</b:Last>
<b:First>Yoshifumi</b:First>
</b:Person>
<b:Person>
<b:Last>Kishino</b:Last>
<b:First>Fumio</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>9</b:Pages>
<b:StandardNumber> ISBN: 1-59593-364-6 DOI: http://doi.acm.org/10.1145/1179622.1179632</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SIGGRAPH '06: ACM SIGGRAPH 2006 Research posters</b:BookTitle>
<b:ConferenceName>SIGGRAPH '06: ACM SIGGRAPH 2006 Research posters</b:ConferenceName>
<b:BIBTEX_Abstract>This paper proposes a method of extracting skeleton interactively for 3D character animation. A skeleton is automatically and interactively generated from the object data of 3D models in a process that consists of ?ve steps: 1) transformation into a low polygon model from the original model composed of a large number of polygons; 2) calculation of the sum of the geodesic distance from speci?c points to all vertices on the 3D model; 3) subdivision of the 3D model using the sum of geodesic distances; 4) generation of skeleton joints (skeleton nodes) on each boundary surface between those subdivision areas; and 5) connection of all skeleton nodes. We also propose a method for ?exible skeleton generation using boundary shapes and the sum of geodesic distances. After generating the skeleton, various animations can be created by interpolating key poses created from user manipulation of skeleton joints. Since skeletons can be generated with this method where speci?ed by users, users are expected to create interactively ?exible animations of 3D models</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Lavoue2008</b:Tag>
<b:LCID>0</b:LCID>
<b:Title>Markov Random Fields for Improving 3D Mesh Analysis and Segmentation</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Lavoué</b:Last>
<b:First>Guillaume</b:First>
</b:Person>
<b:Person>
<b:Last>Wolf</b:Last>
<b:First>Christian</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>Eurographics 2008 Workshop on 3D Object Retrieval</b:BookTitle>
<b:ConferenceName>Eurographics 2008 Workshop on 3D Object Retrieval</b:ConferenceName>
<b:Month>#apr#</b:Month>
<b:URL>http://liris.cnrs.fr/publis/?id=3365</b:URL>
<b:BIBTEX_Abstract>Mesh analysis and clustering have became important issues in order to improve the efficiency of common processingoperations like compression, watermarking or simplification. In this context we present a new method for clustering / labeling a 3D mesh given any field of scalar values associated with its vertices (curvature, density, roughness etc.). Our algorithm is based on Markov Random Fields, graphical probabilistic models. This Bayesian framework allows (1) to integrate both the attributes and the geometry in the clustering, and (2) to obtain an optimal global solution using only local interactions, due to the Markov property of the random field. We have defined new observation and prior models for 3D meshes, adapted from image processing which achieve very good results in terms of spatial coherency of the labeling. All model parameters are estimated, resulting in a fully automatic process (the only required parameter is the number of clusters) which works in reasonable time (several seconds).</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Rusinkiewicz2002</b:Tag>
<b:Title>Real-time 3D model acquisition</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Rusinkiewicz</b:Last>
<b:First>Szymon</b:First>
</b:Person>
<b:Person>
<b:Last>Hall-Holt</b:Last>
<b:First>Olaf</b:First>
</b:Person>
<b:Person>
<b:Last>Levoy</b:Last>
<b:First>Marc</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>438-446</b:Pages>
<b:Volume>21</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/566654.566600</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>The digitization of the 3D shape of real objects is a rapidly expanding field, with applications in entertainment, design, and archaeology. We propose a new 3D model acquisition system that permits the user to rotate an object by hand and see a continuously-updated model as the object is scanned. This tight feedback loop allows the user to find and fill holes in the model in real time, and determine when the object has been completely covered. Our system is based on a 60 Hz. structured-light rangefinder, a real-time variant of ICP (iterative closest points) for alignment, and point-based merging and rendering algorithms. We demonstrate the ability of our prototype to scan objects faster and with greater ease than conventional model acquisition pipelines.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Weiler1985</b:Tag>
<b:Title>Edge-Based Data Structures for Solid Modeling in Curved-Surface Environments</b:Title>
<b:Year>1985</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Weiler</b:Last>
<b:First>K.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>21-40</b:Pages>
<b:Volume>5</b:Volume>
<b:StandardNumber> ISSN: 0272-1716 DOI: 10.1109/MCG.1985.276271</b:StandardNumber>
<b:JournalName>Computer Graphics and Applications, IEEE</b:JournalName>
<b:Issue>1</b:Issue>
<b:Month>Jan. </b:Month>
<b:BIBTEX_Abstract>CAD/CAM applications need quick and easy access to topological information about objects. Here, four structures for representing this information are evaluated for sufficiency, efficiency, and ease of implementation.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Furukawa2008</b:Tag>
<b:Title>Dense 3D motion capture from synchronized video streams</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Furukawa</b:Last>
<b:First>Y.</b:First>
</b:Person>
<b:Person>
<b:Last>Ponce</b:Last>
<b:First>J.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:StandardNumber> ISSN: 1063-6919 DOI: 10.1109/CVPR.2008.4587495</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on</b:BookTitle>
<b:ConferenceName>Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>This paper proposes a novel approach to non-rigid, markerless motion capture from synchronized video streams acquired by calibrated cameras. The instantaneous geometry of the observed scene is represented by a polyhedral mesh with fixed topology. The initial mesh is constructed in the first frame using the publicly available PMVS software for multi-view stereo [7]. Its deformation is captured by tracking its vertices over time, using two optimization processes at each frame: a local one using a rigid motion model in the neighborhood of each vertex, and a global one using a regularized nonrigid model for the whole mesh. Qualitative and quantitative experiments using seven real datasets show that our algorithm effectively handles complex nonrigid motions and severe occlusions.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>cameras, image motion analysis, stereo image processing, video streamingcomplex nonrigid motions, dense 3D motion capture, fixed topology, multiview stereo software, rigid motion model, video stream synchronization</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Shiratori2008</b:Tag>
<b:Title>Accelerometer-based User Interfaces for the Control of a Physically Simulated Character</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Shiratori</b:Last>
<b:First>Takaaki</b:First>
</b:Person>
<b:Person>
<b:Last>Hodgins</b:Last>
<b:Middle>K.</b:Middle>
<b:First>Jessica</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-9</b:Pages>
<b:Volume>27</b:Volume>
<b:StandardNumber> DOI: http://doi.acm.org/10.1145/1409060.1409076</b:StandardNumber>
<b:JournalName>ACM Transactions on Graphics (SIGGRAPH Asia 2008)</b:JournalName>
<b:Issue>5</b:Issue>
<b:Month>#aug#</b:Month>
<b:BIBTEX_Abstract>In late 2006, Nintendo released a new game controller, the Wiimote, which included a three-axis accelerometer. Since then, a large variety of novel applications for these controllers have been developed by both independent and commercial developers. We add to this growing library with three performance interfaces that allow the user to control the motion of a dynamically simulated, animated character through the motion of his or her arms, wrists, or legs. For comparison, we also implement a traditional joystick/button interface. We assess these interfaces by having users test them on a set of tracks containing turns and pits. Two of the interfaces (legs and wrists) were judged to be more immersive and were better liked than the joystick/button interface by our subjects. All three of the Wiimote interfaces provided better control than the joystick interface based on an analysis of the failures seen during the user study.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Wii</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Cornea2005a</b:Tag>
<b:Title>Curve-skeleton applications</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cornea</b:Last>
<b:First>N.D.</b:First>
</b:Person>
<b:Person>
<b:Last>Silver</b:Last>
<b:First>D.</b:First>
</b:Person>
<b:Person>
<b:Last>Min</b:Last>
<b:First>P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>95-102</b:Pages>
<b:StandardNumber> DOI: 10.1109/VISUAL.2005.1532783</b:StandardNumber>
<b:BookTitle>Visualization, 2005. VIS 05. IEEE</b:BookTitle>
<b:ConferenceName>Visualization, 2005. VIS 05. IEEE</b:ConferenceName>
<b:Month>Oct.</b:Month>
<b:BIBTEX_Abstract>Curve-skeletons are a 1D subset of the medial surface of a 3D object and are useful for many visualization tasks including virtual navigation, reduced-model formulation, visualization improvement, mesh repair, animation, etc. There are many algorithms in the literature describing extraction methodologies for different applications; however, it is unclear how general and robust they are. In this paper, we provide an overview of many curve-skeleton applications and compile a set of desired properties of such representations. We also give a taxonomy of methods and analyze the advantages and drawbacks of each class of algorithms.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> computational geometry, curve fitting, data visualisation, image representation, image thinning, set theory, solid modelling 1D subset, 3D object, curve-skeleton applications, medial surface, visualization tasks</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Ahmed2005</b:Tag>
<b:Title>Automatic Generation of Personalized Human Avatars from Multi-View Video</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Ahmed</b:Last>
<b:First>Naveed</b:First>
</b:Person>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>Edilson</b:First>
</b:Person>
<b:Person>
<b:Last>Theobalt</b:Last>
<b:First>Christian</b:First>
</b:Person>
<b:Person>
<b:Last>Magnor</b:Last>
<b:First>Marcus</b:First>
</b:Person>
<b:Person>
<b:Last>Seidel</b:Last>
<b:First>Hans-Peter</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>257-260</b:Pages>
<b:StandardNumber> ISBN: 1-59593-098-1</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>Monterey, USA</b:City>
<b:BookTitle>VRST '05: Proceedings of the ACM symposium on Virtual reality software and technology</b:BookTitle>
<b:ConferenceName>VRST '05: Proceedings of the ACM symposium on Virtual reality software and technology</b:ConferenceName>
<b:Month>December</b:Month>
<b:BIBTEX_Abstract>In multi-user virtual environments, like online games or 3D chat rooms, real-world people interact via digital avatars. In order to make the step from the real world onto the virtual stage convincing the digital equivalent of the user has to be personalized. It should reflect the shape and proportions, the kinematic properties, as well as the textural appearance of its real-world equivalent. In [1] we present a novel easy-to-use and fully-automatic approach to create a personalized avatar from multi-view video data of a moving person. An adaptable generic human body model is scaled and deformed until its shape and skeletal dimensions match the real human shown in the video footage. A consistent surface texture for the model is generated using multi-view video frames from different camera views and different body poses. With our proposed method photo-realistic human avatars can be robustly generated.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Bajaj2003</b:Tag>
<b:Title>Anisotropic diffusion of surfaces and functions on surfaces</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Bajaj</b:Last>
<b:Middle>L.</b:Middle>
<b:First>Chandrajit</b:First>
</b:Person>
<b:Person>
<b:Last>Xu</b:Last>
<b:First>Guoliang</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>4-32</b:Pages>
<b:Volume>22</b:Volume>
<b:StandardNumber> ISSN: 0730-0301 DOI: http://doi.acm.org/10.1145/588272.588276</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:JournalName>ACM Trans. Graph.</b:JournalName>
<b:Month>January</b:Month>
<b:URL>http://doi.acm.org/10.1145/588272.588276</b:URL>
<b:BIBTEX_Abstract>We present a unified anisotropic geometric diffusion PDE model for smoothing (fairing) out noise both in triangulated two-manifold surface meshes in IR3 and functions defined on these surface meshes, while enhancing curve features on both by careful choice of an anisotropic diffusion tensor. We combine the C1 limit representation of Loop's subdivision for triangular surface meshes and vector functions on the surface mesh with the established diffusion model to arrive at a discretized version of the diffusion problem in the spatial direction. The time direction discretization then leads to a sparse linear system of equations. Iteratively solving the sparse linear system yields a sequence of faired (smoothed) meshes as well as faired functions.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Loop's subdivision, Riemannian manifold, Surface function diffusion, noise reduction, texture mapping</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Wren1997</b:Tag>
<b:Title>Pfinder: real-time tracking of the human body</b:Title>
<b:Year>1997</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Wren</b:Last>
<b:Middle>R.</b:Middle>
<b:First>C.</b:First>
</b:Person>
<b:Person>
<b:Last>Azarbayejani</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Darrell</b:Last>
<b:First>T.</b:First>
</b:Person>
<b:Person>
<b:Last>Pentland</b:Last>
<b:Middle>P.</b:Middle>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>780-785</b:Pages>
<b:Volume>19</b:Volume>
<b:JournalName>Pattern Analysis and Machine Intelligence, IEEE Transactions on</b:JournalName>
<b:Issue>7</b:Issue>
<b:URL>http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=598236</b:URL>
<b:BIBTEX_Abstract>Pfinder is a real-time system for tracking people and interpreting their behavior. It runs at 10 Hz on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multiclass statistical model of color and shape to obtain a 2D representation of head and hands in a wide range of viewing conditions. Pfinder has been successfully used in a wide range of applications including wireless interfaces, video databases, and low-bandwidth coding</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>blob, detection, model, shape</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Giblin2004</b:Tag>
<b:Title>A Formal Classification of 3D Medial Axis Points and Their Local Geometry</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Giblin</b:Last>
<b:First>Peter</b:First>
</b:Person>
<b:Person>
<b:Last>Kimia</b:Last>
<b:Middle>B.</b:Middle>
<b:First>Benjamin</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>238-251</b:Pages>
<b:Volume>26</b:Volume>
<b:StandardNumber> ISSN: 0162-8828 DOI: http://dx.doi.org/10.1109/TPAMI.2004.1262192</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Washington, DC, USA</b:City>
<b:JournalName>IEEE Trans. Pattern Anal. Mach. Intell.</b:JournalName>
<b:Month>January</b:Month>
<b:URL>http://dx.doi.org/10.1109/TPAMI.2004.1262192</b:URL>
<b:BIBTEX_Abstract>This paper proposes a novel hypergraph skeletal representation for 3D shape based on a formal derivation ofthe generic structure of its medial axis. By classifying each skeletal point by its order of contact, we show that, generically, the medial axis consists of five types of points, which are then organized into sheets, curves, and points: 1) sheets (manifolds with boundary) which are the locus of bitangent spheres with regular tangency A_1^2 (A_k^n notation means n distinct k{\hbox{-}}{\rm{fold}} tangencies of the sphere of contact, as explained in the text); two types of curves, 2) the intersection curve of three sheets and the locus of centers of tritangent spheres, A_1^3, and 3) the boundary of sheets, which are the locus of centers of spheres whose radius equals the larger principal curvature, i.e., higher order contact A_3 points; and two types of points, 4) centers of quad-tangent spheres, A_1^4, and 5) centers of spheres with one regular tangency and one higher order tangency, A_1A_3. The geometry of the 3D medial axis thus consists of sheets (A_1^2) bounded by one type of curve (A_3) on their free end, which corresponds to ridges on the surface, and attached to two other sheets at another type of curve (A_1^3), which support a generalized cylinder description. The A_3 curves can only end in A_1A_3 points where they must meet an A_1^3 curve. The A_1^3 curves meet together in fours at an A_1^4 point. This formal result leads to a compact representation for 3D shape, referred to as the medial axis hypergraph representation consisting of nodes (A_1^4 and A_1 A_3 points), links between pairs of nodes (A_1^3 and A_3 curves) and hyperlinks between groups of links (A_1^2 sheets). The description of the local geometry at nodes by itself is sufficient to capture qualitative aspects of shapes, in analogy to 2D. We derive a pointwise reconstruction formula to reconstruct a surface from this medial axis hypergraph together with the radius function. Thus, this information completely characterizes 3D shape and lays the theoretical foundation for its use in recognition, morphing, design, and manipulation of shapes.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>3D medial axis, skeleton, shocks, curve skeleton, order of contact, local form, medial topology, ridges, generalized axis.</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Slabaugh2004</b:Tag>
<b:Title>Methods for Volumetric Reconstruction of Visual Scenes</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Slabaugh</b:Last>
<b:Middle>G.</b:Middle>
<b:First>Gregory</b:First>
</b:Person>
<b:Person>
<b:Last>Culbertson</b:Last>
<b:Middle>Bruce</b:Middle>
<b:First>W.</b:First>
</b:Person>
<b:Person>
<b:Last>Malzbender</b:Last>
<b:First>Thomas</b:First>
</b:Person>
<b:Person>
<b:Last>Stevens</b:Last>
<b:Middle>R.</b:Middle>
<b:First>Mark</b:First>
</b:Person>
<b:Person>
<b:Last>Schafer</b:Last>
<b:Middle>W.</b:Middle>
<b:First>Ronald</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>179-199</b:Pages>
<b:Volume>57</b:Volume>
<b:JournalName>International Journal of Computer Vision</b:JournalName>
<b:Issue>3</b:Issue>
<b:Month>#may#</b:Month>
<b:URL>http://dx.doi.org/10.1023/B:VISI.0000013093.45070.3b</b:URL>
<b:BIBTEX_Abstract>In this paper, we present methods for 3D volumetric reconstruction of visual scenes photographed by multiple calibrated cameras placed at arbitrary viewpoints. Our goal is to generate a 3D model that can be rendered to synthesize new photo-realistic views of the scene. We improve upon existing voxel coloring/space carving approaches by introducing new ways to compute visibility and photo-consistency, as well as model infinitely large scenes. In particular, we describe a visibility approach that uses all possible color information from the photographs during reconstruction, photo-consistency measures that are more robust and/or require less manual intervention, and a volumetric warping method for application of these reconstruction methods to large-scale scenes.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>Misc</b:SourceType>
<b:Tag>Hasinoff2006</b:Tag>
<b:Title>Confocal Stereo</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hasinoff</b:Last>
<b:First>Samuel</b:First>
</b:Person>
<b:Person>
<b:Last>Kutulakos</b:Last>
<b:First>Kiriakos</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>620-634</b:Pages>
<b:JournalName>Computer Vision â€“ ECCV 2006</b:JournalName>
<b:URL>http://dx.doi.org/10.1007/11744023_48</b:URL>
<b:PublicationTitle>Confocal Stereo</b:PublicationTitle>
<b:BIBTEX_Abstract>We present confocal stereo, a new method for computing 3D shape by controlling the focus and aperture of a lens. The method is specifically designed for reconstructing scenes with high geometric complexity or fine-scale texture. To achieve this, we introduce the confocal constancy property, which states that as the lens aperture varies, the pixel intensity of a visible in-focus scene point will vary in a scene-independent way, that can be predicted by prior radiometric lens calibration. The only requirement is that incoming radiance within the cone subtended by the largest aperture is nearly constant. First, we develop a detailed lens model that factors out the distortions in high resolution SLR cameras (12MP or more) with large-aperture lenses (e.g., f1.2). This allows us to assemble an A F aperture-focus image (AFI) for each pixel, that collects the undistorted measurements over all A apertures and F focus settings. In the AFI representation, confocal constancy reduces to color comparisons within regions of the AFI, and leads to focus metrics that can be evaluated separately for each pixel. We propose two such metrics and present initial reconstruction results for complex scenes.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Hassouna2009</b:Tag>
<b:Title>Variational Curve Skeletons Using Gradient Vector Flow</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hassouna</b:Last>
<b:Middle>Sabry</b:Middle>
<b:First>M.</b:First>
</b:Person>
<b:Person>
<b:Last>Farag</b:Last>
<b:Middle>A.</b:Middle>
<b:First>Aly</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>2257-2274</b:Pages>
<b:Volume>31</b:Volume>
<b:StandardNumber> ISSN: 0162-8828 DOI: http://doi.ieeecomputersociety.org/10.1109/TPAMI.2008.271</b:StandardNumber>
<b:Publisher>IEEE Computer Society</b:Publisher>
<b:City>Los Alamitos, CA, USA</b:City>
<b:JournalName>IEEE Transactions on Pattern Analysis and Machine Intelligence</b:JournalName>
<b:Issue>12</b:Issue>
<b:BIBTEX_Abstract>Representing a 3D shape by a set of 1D curves that are locally symmetric with respect to its boundary (i.e., curve skeletons) is of importance in several machine intelligence tasks. This paper presents a fast, automatic, and robust variational framework for computing continuous, subvoxel accurate curve skeletons from volumetric objects. A reference point inside the object is considered a point source that transmits two wave fronts of different energies. The first front (\beta-front) converts the object into a graph, from which the object salient topological nodes are determined. Curve skeletons are tracked from these nodes along the cost field constructed by the second front (\alpha-front) until the point source is reached. The accuracy and robustness of the proposed work are validated against competing techniques as well as a database of 3D objects. Unlike other state-of-the-art techniques, the proposed framework is highly robust because it avoids locating and classifying skeletal junction nodes, employs a new energy that does not form medial surfaces, and finally extracts curve skeletons that correspond to the most prominent parts of the shape and hence are less sensitive to noise.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>1487512</b:Tag>
<b:Title>Confocal Stereo</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hasinoff</b:Last>
<b:Middle>W.</b:Middle>
<b:First>Samuel</b:First>
</b:Person>
<b:Person>
<b:Last>Kutulakos</b:Last>
<b:Middle>N.</b:Middle>
<b:First>Kiriakos</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>82-104</b:Pages>
<b:Volume>81</b:Volume>
<b:StandardNumber> ISSN: 0920-5691 DOI: http://dx.doi.org/10.1007/s11263-008-0164-2</b:StandardNumber>
<b:Publisher>Kluwer Academic Publishers</b:Publisher>
<b:City>Hingham, MA, USA</b:City>
<b:JournalName>Int. J. Comput. Vision</b:JournalName>
<b:Issue>1</b:Issue>
<b:BIBTEX_Abstract>We present confocal stereo, a new method for computing 3D shape by controlling the focus and aperture of a lens. The method is specifically designed for reconstructing scenes with high geometric complexity or fine-scale texture. To achieve this, we introduce the confocal constancy property, which states that as the lens aperture varies, the pixel intensity of a visible in-focus scene point will vary in a scene-independent way, that can be predicted by prior radiometric lens calibration. The only requirement is that incoming radiance within the cone subtended by the largest aperture is nearly constant. First, we develop a detailed lens model that factors out the distortions in high resolution SLR cameras (12MP or more) with large-aperture lenses (e.g., f1.2). This allows us to assemble an A×F aperture-focus image (AFI) for each pixel, that collects the undistorted measurements over all A apertures and F focus settings. In the AFI representation, confocal constancy reduces to color comparisons within regions of the AFI, and leads to focus metrics that can be evaluated separately for each pixel. We propose two such metrics and present initial reconstruction results for complex scenes, as well as for a scene with known ground-truth shape.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Laurentini1999</b:Tag>
<b:Title>The visual hull of curved objects</b:Title>
<b:Year>1999</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Laurentini</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>356-361 vol.1</b:Pages>
<b:Volume>1</b:Volume>
<b:StandardNumber> DOI: 10.1109/ICCV.1999.791242</b:StandardNumber>
<b:BookTitle>Computer Vision</b:BookTitle>
<b:JournalName>Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference on</b:JournalName>
<b:ConferenceName>Computer Vision</b:ConferenceName>
<b:BIBTEX_Abstract>The visual hull is a geometric tool which relates the 3D shape of a concave object to its silhouettes or shadows. This paper deals with the computation of the visual hull of objects bounded by smooth curved surfaces. We show that the surfaces which bound the visual hull are surfaces relevant for the construction of the aspect graph of the object, and that the algorithms for computing the aspect graph of curved objects can be exploited for computing their visual hull</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image reconstruction, surface fittingaspect graph, concave object, curved objects, curved surfaces, visual hull</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Park2002</b:Tag>
<b:Title>Automatic 3D model reconstruction using voxel coding and pose integration</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Park</b:Last>
<b:First>Soon-Yong</b:First>
</b:Person>
<b:Person>
<b:Last>Subbarao</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages> II-533-II-536 vol.2</b:Pages>
<b:Volume>2</b:Volume>
<b:StandardNumber> ISSN: 1522-4880  DOI: 10.1109/ICIP.2002.1040005</b:StandardNumber>
<b:BookTitle>3D Data Processing Visualization and Transmission</b:BookTitle>
<b:JournalName>Image Processing. 2002. Proceedings. 2002 International Conference on</b:JournalName>
<b:ConferenceName>3D Data Processing Visualization and Transmission</b:ConferenceName>
<b:BIBTEX_Abstract>Automatic reconstruction of a complete 3D model of a complex object is presented. The complete 3D model is reconstructed by integrating two 3D models which are reconstructed from different poses of the object. For each pose of the object, a 3D model is reconstructed by combining stereo image analysis, shape from silhouettes, and a volumetric integration technique. Stereo image analysis and shape from silhouettes techniques complement each other to reconstruct an accurate and noise-resistant 3D model. For a reliable volumetric integration of multiple partial shapes, a voxel coding technique is introduced. The voxel coding technique facilitates a selection of consistent partial shapes for shape integration. In order to reconstruct all visible surfaces of a complex object with concavities and holes, two 3D models from different poses of the object are reconstructed and integrated to obtain the complete 3D model. A voxel coding technique is again used during pose integration. Experimental results on a real object demonstrate that our approach has advantages and is effective.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> binary codes, image reconstruction, stereo image processing, virtual reality automatic reconstruction, complete 3D model, complex object, multiple partial shapes, partial shapes, poses, shape integration, silhouettes, stereo image analysis, volumetric integration technique, voxel coding technique</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>blum1967</b:Tag>
<b:Title>A Transformation for Extracting New Descriptors of Shape</b:Title>
<b:Year>1967</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Blum</b:Last>
<b:First>Harry</b:First>
</b:Person>
</b:NameList>
</b:Author>
<b:Editor>
<b:NameList>
<b:Person>
<b:Last>Wathen-Dunn</b:Last>
<b:First>Weiant</b:First>
</b:Person>
</b:NameList>
</b:Editor>
</b:Author>
<b:Pages>362-380</b:Pages>
<b:Volume>1</b:Volume>
<b:Publisher>MIT Press</b:Publisher>
<b:City>Cambridge, MA</b:City>
<b:JournalName>Models for the Perception of Speech and Visual Form</b:JournalName>
<b:URL>http://pageperso.lif.univ-mrs.fr/~edouard.thiel/rech/1967-blum.pdf</b:URL>
<b:BIBTEX_KeyWords>voronoi</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>Report</b:SourceType>
<b:BIBTEX_Entry>mastersthesis</b:BIBTEX_Entry>
<b:Tag>Aguiar2003</b:Tag>
<b:Title>Character Animation from a Motion Capture Database</b:Title>
<b:Year>2003</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>de Aguiar</b:Last>
<b:First>Edilson</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Department>Universit{\"a}t des Saarlandes</b:Department>
<b:ThesisType>Master's thesis</b:ThesisType>
<b:Month>November</b:Month>
<b:BIBTEX_Abstract>With the advent of photo-realism in Computer Graphics, life-like character animations that capture fine details of a motion have become more important. We have studied methods [1] that use the information contained in a motion capture database to assist in the creation of a realistic character animation. Starting with an animation sketch, where only a small number of keyframes for some degrees of freedom are set, the motion capture data is used to enhance the initial motion.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Yan2008</b:Tag>
<b:Title>Learning 4D action feature models for arbitrary view action recognition</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Yan</b:Last>
<b:First>Pingkun</b:First>
</b:Person>
<b:Person>
<b:Last>Khan</b:Last>
<b:First>S.M.</b:First>
</b:Person>
<b:Person>
<b:Last>Shah</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-7</b:Pages>
<b:StandardNumber> ISSN: 1063-6919 DOI: 10.1109/CVPR.2008.4587737</b:StandardNumber>
<b:BookTitle>Computer Vision and Pattern Recognition</b:BookTitle>
<b:JournalName>Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on</b:JournalName>
<b:ConferenceName>Computer Vision and Pattern Recognition</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>In this paper we present a novel approach using a 4D (x,y,z,t) action feature model (4D-AFM) for recognizing actions from arbitrary views. The 4D-AFM elegantly encodes shape and motion of actors observed from multiple views. The modeling process starts with reconstructing 3D visual hulls of actors at each time instant. Spatiotemporal action features are then computed in each view by analyzing the differential geometric properties of spatio-temporal volumes (3D STVs) generated by concatenating the actorpsilas silhouette over the course of the action (x, y, t). These features are mapped to the sequence of 3D visual hulls over time (4D) to build the initial 4D-AFM. Actions are recognized based on the scores of matching action features from the input videos to the model points of 4D-AFMs by exploiting pairwise interactions of features. Promising recognition results have been demonstrated on the multi-view IXMAS dataset using both single and multi-view input videos.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image coding, image matching, image recognition, image sequences, video signal processing3D visual hulls, 4D action feature models, 4D-AFM, arbitrary view action recognition, multiview input videos, spatiotemporal action features, spatiotemporal volumes</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>Misc</b:SourceType>
<b:Tag>Wren2004</b:Tag>
<b:Title>Perception for Human Motion Understanding</b:Title>
<b:Year>2004</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Wren</b:Last>
<b:Middle>R.</b:Middle>
<b:First>Christopher</b:First>
</b:Person>
<b:Person>
<b:Last>D</b:Last>
<b:First>Ph.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:PublicationTitle>Perception for Human Motion Understanding</b:PublicationTitle>
<b:BIBTEX_Abstract>The fact that people are embodied places powerful contraints on their motion. By leveraging these constraints, we can build systems to perceive human motion that are fast and robust. More importantly, by understanding how these constraint systems relate to one another, and to the perceptual process itself, we can make progress toward building systems that interpret, not just capture, human motion.</b:BIBTEX_Abstract>
<b:BIBTEX_HowPublished>Innovations in Machine Intelligence \&amp; Robot Perception</b:BIBTEX_HowPublished>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Bradley2008</b:Tag>
<b:Title>Markerless Garment Capture</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Bradley</b:Last>
<b:First>Derek</b:First>
</b:Person>
<b:Person>
<b:Last>Popa</b:Last>
<b:First>Tiberiu</b:First>
</b:Person>
<b:Person>
<b:Last>Sheffer</b:Last>
<b:First>Alla</b:First>
</b:Person>
<b:Person>
<b:Last>Heidrich</b:Last>
<b:First>Wolfgang</b:First>
</b:Person>
<b:Person>
<b:Last>Boubekeur</b:Last>
<b:First>Tamy</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>99</b:Pages>
<b:Volume>27</b:Volume>
<b:JournalName>ACM Trans. Graphics (Proc. SIGGRAPH)</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>A lot of research has recently focused on the problem of capturing the geometry and motion of garments. Such work usually relies on special markers printed on the fabric to establish temporally coherent correspondences between points on the garment’s surface at different times. Unfortunately, this approach is tedious and prevents the capture of off-the-shelf clothing made from interesting fabrics.

In this paper, we describe a marker-free approach to capturing garment motion that avoids these downsides. We establish temporally coherent parameterizations between incomplete geometries that we extract at each timestep with a multiview stereo algorithm. We then fill holes in the geometry using a template. This approach, for the first time, allows us to capture the geometry and motion of unpatterned, off-the-shelf garments made from a range of different fabrics.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Cornea2005</b:Tag>
<b:Title>Computing hierarchical curve-skeletons of 3D objects</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Cornea</b:Last>
<b:Middle>D.</b:Middle>
<b:First>Nicu</b:First>
</b:Person>
<b:Person>
<b:Last>Silver</b:Last>
<b:First>Deborah</b:First>
</b:Person>
<b:Person>
<b:Last>Yuan</b:Last>
<b:First>Xiaosong</b:First>
</b:Person>
<b:Person>
<b:Last>Balasubramanian</b:Last>
<b:First>Raman</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>945-955</b:Pages>
<b:Volume>21</b:Volume>
<b:JournalName>The Visual Computer</b:JournalName>
<b:Issue>11</b:Issue>
<b:Month>#oct#</b:Month>
<b:URL>http://dx.doi.org/10.1007/s00371-005-0308-0</b:URL>
<b:BIBTEX_Abstract>A curve-skeleton of a 3D object is a stick-like figure or centerline representation of that object. It is used for diverse applications, including virtual colonoscopy and animation. In this paper, we introduce the concept of hierarchical curve-skeletons and describe a general and robust methodology that computes a family of increasingly detailed curve-skeletons. The algorithm is based upon computing a repulsive force field over a discretization of the 3D object and using topological characteristics of the resulting vector field, such as critical points and critical curves, to extract the curve-skeleton. We demonstrate this method on many different types of 3D objects (volumetric, polygonal and scattered point sets) and discuss various extensions of this approach.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Giesen2009</b:Tag>
<b:Title>The scale axis transform</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Giesen</b:Last>
<b:First>Joachim</b:First>
</b:Person>
<b:Person>
<b:Last>Miklos</b:Last>
<b:First>Balint</b:First>
</b:Person>
<b:Person>
<b:Last>Pauly</b:Last>
<b:First>Mark</b:First>
</b:Person>
<b:Person>
<b:Last>Wormser</b:Last>
<b:First>Camille</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>106-115</b:Pages>
<b:StandardNumber> ISBN: 978-1-60558-501-7 DOI: http://doi.acm.org/10.1145/1542362.1542388</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>Proceedings of the 25th annual symposium on Computational geometry</b:BookTitle>
<b:ConferenceName>Proceedings of the 25th annual symposium on Computational geometry</b:ConferenceName>
<b:URL>http://doi.acm.org/10.1145/1542362.1542388</b:URL>
<b:BIBTEX_Series>SCG '09</b:BIBTEX_Series>
<b:BIBTEX_Abstract>We introduce the scale axis transform, a new skeletal shape representation for bounded open sets O ? Rd. The scale axis transform induces a family of skeletons that captures the important features of a shape in a scale-adaptive way and yields a hierarchy of successively simplified skeletons. Its definition is based on the medial axis transform and the simplification of the shape under multiplicative scaling: the s-scaled shape Os is the union of the medial balls of O with radii scaled by a factor of s. The s-scale axis transform of O is the medial axis transform of Os, with radii scaled back by a factor of 1/s. We prove topological properties of the scale axis transform and we describe the evolution s ? Os by defining the multiplicative distance function to the shape and studying properties of the corresponding steepest ascent flow. All our theoretical results hold for any dimension. In addition, using a discrete approximation, we present several examples of two-dimensional scale axis transforms that illustrate the practical relevance of our new framework.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>medial axis, skeleton, topology</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Li2002</b:Tag>
<b:Title>Combining stereo and visual hull information for on-line reconstruction and rendering of dynamic scenes</b:Title>
<b:Year>2002</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Li</b:Last>
<b:First>Ming</b:First>
</b:Person>
<b:Person>
<b:Last>Schirmacher</b:Last>
<b:First>H.</b:First>
</b:Person>
<b:Person>
<b:Last>Magnor</b:Last>
<b:First>M.</b:First>
</b:Person>
<b:Person>
<b:Last>Siedel</b:Last>
<b:First>H.-P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>9-12</b:Pages>
<b:StandardNumber> ISSN:  </b:StandardNumber>
<b:BookTitle>Multimedia Signal Processing</b:BookTitle>
<b:JournalName>Multimedia Signal Processing, 2002 IEEE Workshop on</b:JournalName>
<b:ConferenceName>Multimedia Signal Processing</b:ConferenceName>
<b:Month>Dec.</b:Month>
<b:BIBTEX_Abstract>In this paper, we present a novel system which, combines depth-from-stereo and visual hull reconstruction for acquiring dynamic real-world scenes at interactive rates. First, we use the silhouettes from multiple views to construct a polyhedral visual hull is then used to limit the disparity range during depth-from-stereo computation. The restricted search range improves both speed and quality of the stereo reconstruction. In return, stereo information can compensate for some of the visual hull method, such as inability to reconstruct surface details and concave regions. Our system achieves a reconstruction frame rate of 4fps.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords> image reconstruction, rendering (computer graphics), stereo image processing depth-from-stereo computation, disparity range, dynamic scene rendering, frame rate reconstruction, interactive rates, on-line reconstruction, polyhedral visual hull, stereo reconstruction, visual hull information, visual hull reconstruction</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Tierny2006a</b:Tag>
<b:Title>Invariant High-Level Reeb Graphs of 3D Polygonal Meshes</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Tierny</b:Last>
<b:First>Julien</b:First>
</b:Person>
<b:Person>
<b:Last>Vandeborre</b:Last>
<b:First>Jean-Philippe</b:First>
</b:Person>
<b:Person>
<b:Last>Daoudi</b:Last>
<b:First>Mohamed</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>105-112</b:Pages>
<b:City>Chapel Hill, North Carolina, USA</b:City>
<b:BookTitle>3rd IEEE International Symposium on 3D Data Processing, Visualization and Transmission (3DPVT'06)</b:BookTitle>
<b:ConferenceName>3rd IEEE International Symposium on 3D Data Processing, Visualization and Transmission (3DPVT'06)</b:ConferenceName>
<b:BIBTEX_Abstract>Many applications in computer graphics need high level shape descriptions, in order to benefit from a global understanding of shapes.
Topological approaches enable pertinent surface decompositions, providing structural descriptions of 3D polygonal meshes; but in practice, their use raises several difficulties.
In this paper, we present a novel method for the construction of invariant high level Reeb graphs, topological entities that give a good overview of the shape structure. With this aim, we propose an accurate and straightforward feature point extraction algorithm for the computation of an invariant and meaningful quotient function. Moreover, we propose a new graph construction algorithm, based on an analysis of the connectivity evolutions of discrete level lines. This algorithm brings a practical solution for the suppression of non-significant critical points over piecewise continuous functions, providing meaningful Reeb graphs.
Presented method gives accurate results, with satisfactory execution times and without input parameter. The geometrical invariance of resulting graphs and their robustness to variance in model pose and mesh sampling make them good candidates for several applications, like shape deformation (experimented in this paper), recognition, compression, indexing, etc.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Yamazaki2008</b:Tag>
<b:Title>The Theory and Practice of Coplanar Shadowgram Imaging forÂ Acquiring Visual Hulls of Intricate Objects</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Yamazaki</b:Last>
<b:First>Shuntaro</b:First>
</b:Person>
<b:Person>
<b:Last>Narasimhan</b:Last>
<b:First>Srinivasa</b:First>
</b:Person>
<b:Person>
<b:Last>Baker</b:Last>
<b:First>Simon</b:First>
</b:Person>
<b:Person>
<b:Last>Kanade</b:Last>
<b:First>Takeo</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>--</b:Pages>
<b:Volume>1</b:Volume>
<b:JournalName>International Journal of Computer Vision</b:JournalName>
<b:URL>http://dx.doi.org/10.1007/s11263-008-0170-4</b:URL>
<b:BIBTEX_Abstract>Abstract&amp;nbsp;&amp;nbsp;Acquiring 3D models of intricate objects (like tree branches, bicycles and insects) is a challenging task due to severe self-occlusions, repeated thin structures, and surface discontinuities. In theory, a shape-from-silhouettes (SFS) approach can overcome these difficulties and reconstruct visual hulls that are close to the actual shapes, regardless of the complexity of the object. In practice, however, SFS is highly sensitive to errors in silhouette contours and the calibration of the imaging system, and has therefore not been used for obtaining accurate shapes with a large number of views. In this work, we present a practical approach to SFS using a novel technique called coplanar shadowgram imaging that allows us to use dozens to even hundreds of views for visual hull reconstruction. A point light source is moved around an object and the shadows (silhouettes) cast onto a single background plane are imaged. We characterize this imaging system in terms of image projection, reconstruction ambiguity, epipolar geometry, and shape and source recovery. The coplanarity of the shadowgrams yields unique geometric properties that are not possible in traditional multi-view camera-based imaging systems. These properties allow us to derive a robust and automatic algorithm to recover the visual hull of an object and the 3D positions of the light source simultaneously, regardless of the complexity of the object. We demonstrate the acquisition of several intricate shapes with severe occlusions and thin structures, using 50 to 120 views.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Miklos2010</b:Tag>
<b:Title>Discrete {S}cale {A}xis {R}epresentations for 3{D} {G}eometry</b:Title>
<b:Year>2010</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Miklos</b:Last>
<b:First>Balint</b:First>
</b:Person>
<b:Person>
<b:Last>Giesen</b:Last>
<b:First>Joachim</b:First>
</b:Person>
<b:Person>
<b:Last>Pauly</b:Last>
<b:First>Mark</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:BookTitle>{ACM} {T}ransactions on {G}raphics ({P}roceedings of {SIGGRAPH})</b:BookTitle>
<b:ConferenceName>{ACM} {T}ransactions on {G}raphics ({P}roceedings of {SIGGRAPH})</b:ConferenceName>
<b:BIBTEX_Abstract>This paper addresses the fundamental problem of computing stable medial representations of 3D shapes. We propose a spatially adaptive classi?cation of geometric features that yields a robust algorithm for generating medial representations at different levels of abstraction. The recently introduced continuous scale axis transform serves as the mathematical foundation of our algorithm. We show how geometric and topological properties of the continuous setting carry over to discrete shape representations. Our method combines scaling operations of medial balls for geometric simpli?cation with ?ltrations of the medial axis and provably good conversion steps to and from union of balls, to enable ef?cient processing of a wide variety shape representations including polygon meshes,
3D images, implicit surfaces, and point clouds. We demonstrate the robustness and versatility of our algorithm with an extensive validation on hundreds of shapes including complex geometries consisting of millions of triangles.</b:BIBTEX_Abstract>
<b:BIBTEX_Affiliation>EPFL</b:BIBTEX_Affiliation>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Hou2007</b:Tag>
<b:Title>Real-time Body Tracking Using a Gaussian Process Latent Variable Model</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Hou</b:Last>
<b:First>Shaobo</b:First>
</b:Person>
<b:Person>
<b:Last>Galata</b:Last>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Caillette</b:Last>
<b:First>F.</b:First>
</b:Person>
<b:Person>
<b:Last>Thacker</b:Last>
<b:First>N.</b:First>
</b:Person>
<b:Person>
<b:Last>Bromiley</b:Last>
<b:First>P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:StandardNumber> ISSN: 1550-5499 DOI: 10.1109/ICCV.2007.4408946</b:StandardNumber>
<b:BookTitle>IEEE Internat. Conf. on Computer Vision</b:BookTitle>
<b:JournalName>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:JournalName>
<b:ConferenceName>IEEE Internat. Conf. on Computer Vision</b:ConferenceName>
<b:Month>Oct.</b:Month>
<b:BIBTEX_Abstract>In this paper, we present a tracking framework for capturing articulated human motions in real-time, without the need for attaching markers onto the subject's body. This is achieved by first obtaining a low dimensional representation of the training motion data, using a nonlinear dimensionality reduction technique called back-constrained GPLVM. A prior dynamics model is then learnt from this low dimensional representation by partitioning the motion sequences into elementary movements using an unsupervised EM clustering algorithm. The temporal dependencies between these elementary movements are efficiently captured by a Variable Length Markov Model. The learnt dynamics model is used to bias the propagation of candidate pose feature vectors in the low dimensional space. By combining this with an efficient volumetric reconstruction algorithm, our framework can quickly evaluate each candidate pose against image evidence captured from multiple views. We present results that show our system can accurately track complex structured activities such as ballet dancing in real-time.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>Gaussian processes, Markov processes, image motion analysis, image reconstruction, image sequences, pattern clusteringGaussian process latent variable model, backconstrained GPLVM, human motions, low dimensional representation, motion sequences, nonlinear dimensionality reduction technique, pose feature vectors, real-time body tracking, training motion data, unsupervised EM clustering algorithm, variable length Markov model, volumetric reconstruction algorithm</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Holroyd2008</b:Tag>
<b:Title>A Photometric Approach for Estimating Normals and Tangents</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Holroyd</b:Last>
<b:First>Michael</b:First>
</b:Person>
<b:Person>
<b:Last>Lawrence</b:Last>
<b:First>Jason</b:First>
</b:Person>
<b:Person>
<b:Last>Humphreys</b:Last>
<b:First>Greg</b:First>
</b:Person>
<b:Person>
<b:Last>Zickler</b:Last>
<b:First>Todd</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>133</b:Pages>
<b:Volume>27</b:Volume>
<b:StandardNumber> DOI: http://doi.acm.org/10.1145/1409060.1409086</b:StandardNumber>
<b:JournalName>ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2008)</b:JournalName>
<b:Issue>5</b:Issue>
<b:BIBTEX_Abstract>This paper presents a novel technique for acquiring the shape of real-world objects with complex isotropic and anisotropic reflectance. Our method estimates the local normal and tangent vectors at each pixel in a reference view from a sequence of images taken under varying point lighting. We show that for many real-world materials and a restricted set of light positions, the 2D slice of the BRDF obtained by fixing the local view direction is symmetric under reflections of the halfway vector across the normal-tangent and normal-binormal planes. Based on this analysis, we develop an optimization that estimates the local surface frame by identifying these planes of symmetry in the measured BRDF. As with other photometric methods, a key benefit of our approach is that the input is easy to acquire and is less sensitive to calibration errors than stereo or multi-view techniques. Unlike prior work, our approach allows estimating the surface tangent in the case of anisotropic reflectance. We confirm the accuracy and reliability of our approach with analytic and measured data, present several normal and tangent fields acquired with our technique, and demonstrate applications to image relighting and appearance editing.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Pham2007</b:Tag>
<b:Title>Real-Time Posture Analysis in a Crowd using Thermal Imaging</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Pham</b:Last>
<b:First>Q.C.</b:First>
</b:Person>
<b:Person>
<b:Last>Gond</b:Last>
<b:First>L.</b:First>
</b:Person>
<b:Person>
<b:Last>Begard</b:Last>
<b:First>J.</b:First>
</b:Person>
<b:Person>
<b:Last>Allezard</b:Last>
<b:First>N.</b:First>
</b:Person>
<b:Person>
<b:Last>Sayd</b:Last>
<b:First>P.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-8</b:Pages>
<b:BookTitle>#VS07#</b:BookTitle>
<b:ConferenceName>#VS07#</b:ConferenceName>
<b:BIBTEX_Abstract>This article describes a video-surveillance system developed within the ISCAPS project. Thermal imaging provides a robust solution to visibility change (illumination, smoke) and is a relevant technology for discriminating humans in complex scenes. In this article, we demonstrate its efficiency for posture analysis in dense groups of people. The objective is to automatically detect several persons lying down in a very crowded area. The presented method is based on the detection and segmentation of individuals within groups of people using a combination of several weak classifiers. The classification of extracted silhouettes enables to detect abnormal situations. This approach was successfully applied to the detection of terrorist gas attacks on railway platform and experimentally validated in the project. Some of the results are presented here.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Au2008</b:Tag>
<b:Title>Skeleton Extraction by Mesh Contraction</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Au</b:Last>
<b:Middle>Kin-Chung</b:Middle>
<b:First>Oscar</b:First>
</b:Person>
<b:Person>
<b:Last>Tai</b:Last>
<b:First>Chiew-Lan</b:First>
</b:Person>
<b:Person>
<b:Last>Chu</b:Last>
<b:First>Hung-Kuo</b:First>
</b:Person>
<b:Person>
<b:Last>Cohen-Or</b:Last>
<b:First>Daniel</b:First>
</b:Person>
<b:Person>
<b:Last>Lee</b:Last>
<b:First>Tong-Yee</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>10</b:Pages>
<b:Volume>27</b:Volume>
<b:JournalName>ACM Transactions on Graphics</b:JournalName>
<b:Issue>3</b:Issue>
<b:BIBTEX_Abstract>Extraction of curve-skeletons is a fundamental problem with many applications in computer graphics and visualization. In this paper, we present a simple and robust skeleton extraction method based on mesh contraction. The method works directly on the mesh domain, without pre-sampling the mesh model into a volumetric representation. The method first contracts the mesh geometry into a zero-volume skeletal shape by applying implicit Laplacian smoothing with global positional constraints. The contraction does not alter the mesh connectivity and retains the key features of the original mesh. The contracted mesh is then converted into a 1D curve-skeleton through a connectivity surgery process to remove all the collapsed faces while preserving the shape of the contracted mesh and the original topology. The centeredness of the skeleton is refined by exploiting the induced skeleton-mesh mapping. The contraction process generates valuable information about the object's geometry, in particular, the skeleton-vertex correspondence and the local thickness, which are useful for various applications. We demonstrate its effectiveness in mesh segmentation and skinning animation.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Bitter2001</b:Tag>
<b:Title>Penalized-distance volumetric skeleton algorithm</b:Title>
<b:Year>2001</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Bitter</b:Last>
<b:First>I.</b:First>
</b:Person>
<b:Person>
<b:Last>Kaufman</b:Last>
<b:Middle>E.</b:Middle>
<b:First>A.</b:First>
</b:Person>
<b:Person>
<b:Last>Sato</b:Last>
<b:First>M.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>195-206</b:Pages>
<b:Volume>7</b:Volume>
<b:StandardNumber> DOI: 10.1109/2945.942688</b:StandardNumber>
<b:BookTitle>Transactions on Visualization and Computer Graphics</b:BookTitle>
<b:JournalName>Transactions on Visualization and Computer Graphics</b:JournalName>
<b:Issue>3</b:Issue>
<b:ConferenceName>Transactions on Visualization and Computer Graphics</b:ConferenceName>
<b:URL>http://dx.doi.org/10.1109/2945.942688</b:URL>
<b:BIBTEX_Abstract>Introduces a refined general definition of a skeleton that is based on a penalized distance function and that cannot create any of the degenerate cases of the earlier CEASAR (Center-line Extraction Algorithm-Smooth, Accurate and Robust) and TEASAR (Tree-structure Extraction Algorithm for Skeletons-Accurate and Robust) algorithms. Additionally, we provide an algorithm that finds the skeleton accurately and rapidly. Our solution is fully automatic, which frees the user from having to engage in manual data pre-processing. We present the accurate skeletons computed on a number of test data sets. The algorithm is very efficient, as demonstrated by the running times, which were all below seven minutes</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>distance-field, skeleton</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Jia2008</b:Tag>
<b:Title>Markerless human body motion capture using multiple cameras</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Jia</b:Last>
<b:First>Li</b:First>
</b:Person>
<b:Person>
<b:Last>Zhenjiang</b:Last>
<b:First>Miao</b:First>
</b:Person>
<b:Person>
<b:Last>Chengkai</b:Last>
<b:First>Wan</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1469-1474</b:Pages>
<b:StandardNumber> DOI: 10.1109/ICOSP.2008.4697410</b:StandardNumber>
<b:BookTitle>Signal Processing</b:BookTitle>
<b:JournalName>Signal Processing, 2008. ICSP 2008. 9th International Conference on</b:JournalName>
<b:ConferenceName>Signal Processing</b:ConferenceName>
<b:Month>Oct.</b:Month>
<b:BIBTEX_Abstract>In this paper, we present an approach for markerless model-based full human-body motion capture using multi-view images as input. We extract volume data (voxels) representation from the silhouettes extracted from multiple-view video images by the method of shape from Silhouettes (SFS), and match our predefined human body model to the volume data. We construct an energy field in the volume of interest based on the volume data and human body model with pose parameters, and transform the matching to an energy minimizing problem. By dynamic graph cut, we get the minimum energy of certain pose parameters, and at last we optimize the pose parameters using Powell algorithm with a novel approach that uses the linear prediction guiding the optimization process and get the pose recovered. Through the test results on several video sequences of human body movements in an unaugmented office environment, we demonstrate the effectiveness and robustness of our approach.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>cameras, image motion analysis, image sequences, optimisationPowell algorithm, dynamic graph cut, linear prediction, markerless human body motion, multiple cameras, multiple-view video images, optimization process, pose parameter, unaugmented office environment, video sequences, volume data representation</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Wang2008</b:Tag>
<b:Title>Curve-Skeleton Extraction Using Iterative Least Squares Optimization</b:Title>
<b:Year>2008</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Wang</b:Last>
<b:First>Yu-Shuen</b:First>
</b:Person>
<b:Person>
<b:Last>Lee</b:Last>
<b:First>Tong-Yee</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>926-936</b:Pages>
<b:Volume>14</b:Volume>
<b:StandardNumber> ISSN: 1077-2626 DOI: http://dx.doi.org/10.1109/TVCG.2008.38</b:StandardNumber>
<b:Publisher>IEEE Educational Activities Department</b:Publisher>
<b:City>Piscataway, NJ, USA</b:City>
<b:JournalName>IEEE Transactions on Visualization and Computer Graphics</b:JournalName>
<b:Issue>4</b:Issue>
<b:BIBTEX_Abstract>A curve skeleton is a compact representation of 3D objects and has numerous applications. It can be used to describe an object¡¦s geometry and topology. In this paper, we introduce a novel approach for computing curve skeletons for volumetric representations of the input models. Our algorithm consists of three major steps: 1) using iterative least squares optimization to shrink models and, at the same time, preserving their geometries and topologies; 2) extracting curve skeletons through the thinning algorithm; and 3) pruning unnecessary branches based on shrinking ratios. The proposed method is less sensitive to noise on the surface of models and can generate smoother skeletons. In addition, our shrinking algorithm requires little computation, since the optimization system can be factorized and stored in the pre-computational step. We demonstrate several extracted skeletons that help evaluate our algorithm. We also experimentally compare the proposed method with other well-known methods. Experimental results show advantages when using our method over other techniques.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>JournalArticle</b:SourceType>
<b:Tag>Bergh2009</b:Tag>
<b:Title>Real-Time Body Pose Recognition Using 2D or 3D Haarlets</b:Title>
<b:Year>2009</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Bergh</b:Last>
<b:First>Michael</b:First>
</b:Person>
<b:Person>
<b:Last>Koller-Meier</b:Last>
<b:First>Esther</b:First>
</b:Person>
<b:Person>
<b:Last>Gool</b:Last>
<b:First>Luc</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>72-84</b:Pages>
<b:Volume>83</b:Volume>
<b:StandardNumber> ISSN: 0920-5691 DOI: http://dx.doi.org/10.1007/s11263-009-0218-0</b:StandardNumber>
<b:Publisher>Kluwer Academic Publishers</b:Publisher>
<b:City>Hingham, MA, USA</b:City>
<b:JournalName>Int. J. Comput. Vision</b:JournalName>
<b:Issue>1</b:Issue>
<b:BIBTEX_Abstract>This article presents a novel approach to markerless real-time pose recognition in a multicamera setup. Body pose is retrieved using example-based classification based on Haar wavelet-like features to allow for real-time pose recognition. Average Neighborhood Margin Maximization (ANMM) is introduced as a powerful new technique to train Haar-like features. The rotation invariant approach is implemented for both 2D classification based on silhouettes, and 3D classification based on visual hulls.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Starck2005</b:Tag>
<b:Title>Video-based character animation</b:Title>
<b:Year>2005</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Starck</b:Last>
<b:First>J.</b:First>
</b:Person>
<b:Person>
<b:Last>Miller</b:Last>
<b:First>G.</b:First>
</b:Person>
<b:Person>
<b:Last>Hilton</b:Last>
<b:First>A.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>49-58</b:Pages>
<b:StandardNumber> ISBN: 1-7695-2270-X DOI: http://doi.acm.org/10.1145/1073368.1073375</b:StandardNumber>
<b:Publisher>ACM</b:Publisher>
<b:City>New York, NY, USA</b:City>
<b:BookTitle>SCA '05: Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation</b:BookTitle>
<b:ConferenceName>SCA '05: Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation</b:ConferenceName>
<b:BIBTEX_Abstract>In this paper we introduce a video-based representation for free viewpoint visualization and motion control of 3D character models created from multiple view video sequences of real people. Previous approaches to video-based rendering provide no control of scene dynamics to manipulate, retarget, and create new 3D content from captured scenes. Here we contribute a new approach, combining image based reconstruction and video-based animation to allow controlled animation of people from captured multiple view video sequences. We represent a character as a motion graph of free viewpoint video motions for animation control. We introduce the use of geometry videos to represent reconstructed scenes of people for free viewpoint video rendering. We describe a novel spherical matching algorithm to derive global surface to surface correspondence in spherical geometry images for motion blending and the construction of seamless transitions between motion sequences. Finally, we demonstrate interactive video-based character animation with real-time rendering and free viewpoint visualization. This approach synthesizes highly realistic character animations with dynamic surface shape and appearance captured from multiple view video of people.</b:BIBTEX_Abstract>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Franco2006</b:Tag>
<b:Title>Visual Shapes of Silhouette Sets</b:Title>
<b:Year>2006</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Franco</b:Last>
<b:First>J.-S.</b:First>
</b:Person>
<b:Person>
<b:Last>Lapierre</b:Last>
<b:First>M.</b:First>
</b:Person>
<b:Person>
<b:Last>Boyer</b:Last>
<b:First>E.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>397-404</b:Pages>
<b:StandardNumber> DOI: 10.1109/3DPVT.2006.148</b:StandardNumber>
<b:BookTitle>3D Data Processing</b:BookTitle>
<b:JournalName>3D Data Processing, Visualization, and Transmission, Third International Symposium on</b:JournalName>
<b:ConferenceName>3D Data Processing</b:ConferenceName>
<b:Month>June</b:Month>
<b:BIBTEX_Abstract>Shape from silhouette methods are extensively used to model dynamic and non-rigid objects using binary foreground-background images. Since the problem of reconstructing shapes from silhouettes is ambiguous, a number of solutions exist and several approaches only consider the one with a maximal volume, called the visual hull. However, the visual hull is not always a good approximation of shapes, in particular when observing smooth surfaces with few cameras. In this paper, we consider instead a class of solutions to the silhouette reconstruction problem that we call visual shapes. Such a class includes the visual hull, but also better approximations of the observed shapes which can take into account local assumptions such as smoothness, among others. Our contributions with respect to existing works is first to identify silhouette consistent shapes different from the visual hull, and second to give a practical way to estimate such shapes in real time. Experiments on various sets of data including human body silhouettes are shown to illustrate the principle and the interests of visual shapes.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image reconstruction3D model, binary foreground-background image, image representation, image texture, shape reconstruction, silhouette method, silhouette reconstruction problem, visual hull, visual shapes</b:BIBTEX_KeyWords>
</b:Source>
<b:Source>
<b:SourceType>ConferenceProceedings</b:SourceType>
<b:BIBTEX_Entry>inproceedings</b:BIBTEX_Entry>
<b:Tag>Li2007</b:Tag>
<b:Title>3D object recognition from range images using pyramid matching</b:Title>
<b:Year>2007</b:Year>
<b:Author>
<b:Author>
<b:NameList>
<b:Person>
<b:Last>Li</b:Last>
<b:First>Xinju</b:First>
</b:Person>
<b:Person>
<b:Last>Guskov</b:Last>
<b:First>I.</b:First>
</b:Person>
</b:NameList>
</b:Author>
</b:Author>
<b:Pages>1-6</b:Pages>
<b:StandardNumber> ISSN: 1550-5499 DOI: 10.1109/ICCV.2007.4408829</b:StandardNumber>
<b:BookTitle>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:BookTitle>
<b:JournalName>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:JournalName>
<b:ConferenceName>Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on</b:ConferenceName>
<b:Month>Oct.</b:Month>
<b:BIBTEX_Abstract>Recognition of 3D objects from different viewpoints is a difficult problem. In this paper, we propose a new method to recognize 3D range images by matching local surface descriptors. The input 3D surfaces are first converted into a set of local shape descriptors computed on surface patches defined by detected salient features. We compute the similarities between input 3D images by matching their descriptors with a pyramid kernel function. The similarity matrix of the images is used to train for classification using SVM, and new images can be recognized by comparing with the training set. The approach is evaluated on both synthetic and real 3D data with complex shapes.</b:BIBTEX_Abstract>
<b:BIBTEX_KeyWords>image matching, learning (artificial intelligence), object recognition, support vector machines3D object recognition, 3D range images, SVM, local shape descriptors, pyramid kernel function, training set</b:BIBTEX_KeyWords>
</b:Source>
</b:Sources>
